[{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://fabern.github.io/rsofun/dev/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"BiomeE LULUC","text":"BiomeE dynamic vegetation demography simulation engine capable predicting evolution vegetation tile characterized static parameters (species, soil parameters, initial vegetation, etc) subject environmental forcing. learn , please refer vignette(\"BiomeE usage\"). Starting v5.1, BiomeE capable simulating land use land-use change (LULUC) evolving multiple vegetation tiles, different vegetation types /different land-use practices. section presents overview concepts methods.","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"fractional-tiles","dir":"Articles","previous_headings":"Overview","what":"Fractional tiles","title":"BiomeE LULUC","text":"Conceptually, BiomeE simulates grid cell area 1 (arbitrary unit) divided several land units (LU). fraction cell occupied LU varies time driven land-use change (LUC) forcing. LU implemented vegetation tile associated scalar fraction (indicating fraction occupied LU).","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"lu-transitions","dir":"Articles","previous_headings":"Overview","what":"LU transitions","title":"BiomeE LULUC","text":"square transition matrix TT encodes exogenous yearly land-use change: Ti,jT_{,j} fraction LU ii transitioning LU jj January 1st (start year). LUC transition modelled clear-cut fraction Ti,jT_{,j} LU ii transfer corresponding area LU jj, along soil organic pools, water, belowground biomass converted litter. aboveground biomass sent 3 product pools e-folding times 0, 2 20 years respectively. transition found matrix evaluated turn, transfer matter destination LU accounted throughout update process, ultimately added appropriate LUs. gross transition heuristic provides better accuracy compared strategy net transitions considered (thereby transitions ii jj cancels others ).","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"clear-cut-and-wood-harvest","dir":"Articles","previous_headings":"Overview","what":"Clear-cut and wood harvest","title":"BiomeE LULUC","text":"diagonal transition matrix contains self transitions Ti,iT_{,}, fraction LU ii clear-cut, without transfer area, water soil organic matter. aboveground biomass exported product pools, belowground biomass converted litter remains place. effect, models forestry practice clear-cutting. Note: crop harvest uses different mechanism (direct litter oxidation). Self-transitions therefore used wood harvest exclusively.","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"other-land-management-practices","dir":"Articles","previous_headings":"Overview","what":"Other land management practices","title":"BiomeE LULUC","text":"LUs can furthermore tailored model broad categories land management: species grow LU (none case urban area), fixed addition nitrogen (N fertilization) extra soil turnover rate (ex: tillage) direct oxidation litter (crop grass harvest)","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"output","dir":"Articles","previous_headings":"Overview","what":"Output","title":"BiomeE LULUC","text":"output contains cohorts tile annual diagnostics LU, well virtual tile aggregating LUs grid cell. example output available package:","code":"library(rsofun)  # Output obtained from simulating biomee_p_model_luluc_drivers biomee_p_model_luluc_output"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"BiomeE LULUC","text":"section demonstrates simulate LULUC BiomeE.","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"setup","dir":"Articles","previous_headings":"Getting started","what":"Setup","title":"BiomeE LULUC","text":"package contains example driver Swiss CH-LAE fluxnet site, using environmental data year 2009, 40% initial primary forest clear-cut convert secondary (yet unmanaged) forest. default setting simulate 1 year transient data 250 years spin-. Let us increase transient period 300 years: Let us glance LU settings: two LU defined: primary: initial fraction 1 secondary: initial fraction 0 spin-use initial fractions without applying land-use change. Note names LUs arbitrary: BiomeE infer anything names. Let us now turn attention transition matrix: 3-dimensional matrix. first two dimensions represent square matrix size 2x2 (defined 2 LUs), third dimension represents years, starting first transient year. case one year, meaning one LU change beginning year 1, simulation proceeds without LU change remaining simulation.","code":"library(rsofun)  biomee_p_model_luluc_drivers df_drivers <- biomee_p_model_luluc_drivers df_drivers$params_siml[[1]]$nyeartrend <- 300 df_drivers$init_lu[[1]] #> # A tibble: 2 × 2 #>   name      fraction #>   <chr>        <dbl> #> 1 primary          1 #> 2 secondary        0 df_drivers$luc_forcing[[1]] #> , , 1 #>  #>      [,1] [,2] #> [1,]    0  0.4 #> [2,]    0  0.0"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"simulation","dir":"Articles","previous_headings":"Getting started","what":"Simulation","title":"BiomeE LULUC","text":"Let us run simulation: Next, define convenience functions displaying plots: finally plot, LU aggregated tile, GPP, litter carbon (fastSOM), LU fraction:  Looking GPP (first row), primary forest (left column) spins-steady state year 250 marks start transient period. sharp drop corresponds loss 40% area (see third row). pattern corresponding steady-state continues scaled . observe similar behavior litter (second row). secondary forest (second column) data year 250 initial fraction 0. GPP increases reaching steady-state expected. Since species used LU, GPP stabilizes level (proportionally LU fraction). litter follows different pattern: year 250, inherits lot biomass primary forest. amount litter drops sharply due natural processes replenishment low initial productivity LU. productivity increases (see GPP), amount litter finally increases stabilizes level proportional fraction. third column displays aggregated tile, summing LU relative fraction. GPP shows sharp drop recovery. Litter shows sharp increase (due ground biomass converted litter) followed drop (mineralization) recovery. Finally, expected, fraction aggregated tile remains constant throughout simulation. conclude demonstration, let us plot product pools:  expected, product pools get filled wood harvest decay respective e-folding times.","code":"out_sim_1 <- runread_biomee_f(df_drivers) library(cowplot) library(purrr)  plot1 <- function(lu_name, variable, out, y_limit=NA, yr_start=1, yr_label_offset=0) {   tile <- out[[lu_name]][[1]]   if(lu_name != 'aggregated'){     tile <- tile$output_annual_tile   } else {     tile <- tile$output_annual_cell   }              if (variable != 'lu_fraction') {     res <- tile %>%           ggplot() +           geom_line(aes(x = year + yr_label_offset,                         y = get(variable) * lu_fraction)) +           coord_cartesian(xlim = c(yr_start, NA),                           ylim = c(0, y_limit)) +           theme_classic() +           labs(x = \"Year\", y = paste(variable, \"(\", lu_name, \")\"))   } else {     stopifnot(variable == 'lu_fraction')     res <- tile %>%           ggplot() +           geom_line(aes(x = year + yr_label_offset,                         y = get(variable))) +           coord_cartesian(xlim = c(yr_start, NA),                           ylim = c(0, y_limit)) +           theme_classic() +           labs(x = \"Year\", y = paste(variable, \"(\", lu_name, \")\"))   }    return(res) }  plot_variable <- function(variable, out, yr_start=1, yr_label_offset=0) {   agg <- out[['aggregated']][[1]]$output_annual_cell   y_limit <- max(agg[variable] * agg$lu_fraction) * 1.01    # We remove sitename and aggregated   tile_names <- names(out)[3:length(names(out))]    names <- c(tile_names, 'aggregated')    names |> lmap(\\(x) list(plot1(x, variable, out, y_limit, yr_start, yr_label_offset))) }  plot_variables <- function(variables, out, yr_start=1, yr_label_offset=0) {    plots <- variables |> lmap(\\(x) plot_variable(x, out, yr_start, yr_label_offset))   cowplot::plot_grid(plotlist = plots, ncol = length(variables)) } plot_variables(c('GPP', 'fastSOM', 'lu_fraction'), out_sim_1) p1 <- out_sim_1$aggregated[[1]]$output_annual_cell %>%         ggplot() +         geom_line(aes(x = year, y = prod_pool_1_C)) +         theme_classic() +         labs(x = \"Year\", y = paste(\"Prod. pools C (2 years)\"))  p2 <- out_sim_1$aggregated[[1]]$output_annual_cell %>%         ggplot() +         geom_line(aes(x = year, y = prod_pool_2_C)) +         theme_classic() +         labs(x = \"Year\", y = paste(\"Prod. pools C (20 years)\")) cowplot::plot_grid(p1, p2, nrow = 1)"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"wood-harvest-and-urbanism","dir":"Articles","previous_headings":"","what":"Wood harvest and urbanism","title":"BiomeE LULUC","text":"now implement complex scenario. addition one time transition primary secondary forest: year, one thousands primary forest converted urban area, every 40 years, one quarter secondary forest clear-cut (wood harvest), area remains tile. Furthermore, species planted secondary forest different occurring naturally primary forest. Let us configure requirements: can now run simulation display outputs:  expected GPP null urban tile (vegetation). Note litter tile zero, small seen scale. , can also look product pools:","code":"df_drivers <- biomee_p_model_luluc_drivers  # We extend the transient period to 300 years n_trans <- 300 df_drivers$params_siml[[1]]$nyeartrend <- n_trans  lu_defs <- tibble(         name      = c('primary', 'secondary', 'urban'),         fraction  = c(1.0, 0.0, 0.0),         # We defined which LU can accept vegetation cohorts         # Technically, this was not necessary since no 'lu_index' (see below) points to the third LU         # (but it is a good idea to enforce this anyways)         vegetated = c(TRUE, TRUE, FALSE)         # Equivalently, presets could have been used instead:         #preset = c('unmanaged', 'unmanaged', 'urban') ) n_lu <- length(lu_defs$name)  # Initial transition # 3 LUs, so each year land-use change is represented by 3x3 transitions. # The first 3 numbers are the transitions from each LU to the first LU, # the following three numbers are the transitions from each LU to the second LU, and so on. initial_transition <- c(0, 0, 0, 0.4, 0, 0, 0, 0, 0)  # Harvest pattern: clear-cut secondary forest every 40 years by an area  # corresponding to 10% of the tile (0.1). That corresponds to a fourth of the area  # of secondary forest (0.4/4 = 0.1). # Clear-cuts are represented by self-transitions of LU 2, of area 0.1. harvest_pattern <- c(         rep(rep(0, 9), 39), # null pattern         c(0, 0, 0, 0, 0.1, 0, 0, 0, 0) ) # We repeat the harvest pattern enough times harvest_transitions <- rep(harvest_pattern, 10)  # We define a transition from primary to urban repeated every year urban_transition <- rep(c(0, 0, 0, 0, 0, 0, 0.0006, 0, 0), n_trans)  # We add all the transition matrix transitions_matrix <- build_luc_matrix(list(initial_transition, harvest_transitions, urban_transition), n_lu, n_trans)  # We set the LU definitions and transition forcing in the driver: df_drivers$init_lu[[1]] <- lu_defs df_drivers$luc_forcing[[1]]  <- transitions_matrix  # Finally, we configure two cohorts with two different species (see 'init_cohort_species'): one for tile 1 and one for tile 2 (see 'lu_index'). # LU 3 is an urban tile: it does not accept any cohort. df_drivers$init_cohort[[1]] <- tibble(         init_cohort_species = c(2, 3),      # species         init_cohort_nindivs = rep(0.05, 2), # initial individual density, individual/m2 ! 1 indiv/m2 = 10.000 indiv/ha         init_cohort_bl      = rep(0.0,  2), # initial biomass of leaves, kg C/individual         init_cohort_br      = rep(0.0,  2), # initial biomass of fine roots, kg C/individual         init_cohort_bsw     = rep(0.05, 2), # initial biomass of sapwood, kg C/individual         init_cohort_bHW     = rep(0.0,  2), # initial biomass of heartwood, kg C/tree         init_cohort_seedC   = rep(0.0,  2), # initial biomass of seeds, kg C/individual         init_cohort_nsc     = rep(0.05, 2), # initial non-structural biomass         lu_index            = c(1, 2)       # index land use (LU) containing this cohort. 0 (default) means any vegetated tile will contain a copy. ) out_sim_2 <- runread_biomee_f(df_drivers) plot_variables(c('GPP', 'fastSOM', 'lu_fraction'), out_sim_2) p1 <- out_sim_2$aggregated[[1]]$output_annual_cell %>%         ggplot() +         geom_line(aes(x = year, y = prod_pool_1_C)) +         theme_classic() +         labs(x = \"Year\", y = paste(\"Prod. pools C (2 years)\"))  p2 <- out_sim_2$aggregated[[1]]$output_annual_cell %>%         ggplot() +         geom_line(aes(x = year, y = prod_pool_2_C)) +         theme_classic() +         labs(x = \"Year\", y = paste(\"Prod. pools C (20 years)\"))  cowplot::plot_grid(p1, p2, nrow = 1)"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"crop-rotation-and-land-management","dir":"Articles","previous_headings":"","what":"Crop rotation and land management","title":"BiomeE LULUC","text":"now model crop rotation management practices. primary forest initially clear-cut cultivate crop. every two years one third land left unmanaged (fallow.) Let us configure requirements: can now run simulation . Notes: Crop harvesting already included land management (via oxidized_litter_fraction), require self-transitions wood harvesting. example uses dummy C4 grass setup (species 1) expected yield meaningful results. accurate simulations, please provide values params_species crop simulate.","code":"df_drivers <- biomee_p_model_luluc_drivers  # We extend the transient period to 300 years n_trans <- 300 df_drivers$params_siml[[1]]$nyeartrend <- n_trans  lu_defs <- tibble(         name      = c('primary', 'crop', 'fallow'),         fraction  = c(1.0, 0.0, 0.0),         # Here we use presets to easily configure some parameters for the cropland         # ('extra_N_input', 'extra_turnover_rate', 'oxidized_litter_fraction')         # preset 'unmanaged' sets all these parameters to 0         preset = c('unmanaged', 'cropland', 'unmanaged') ) n_lu <- length(lu_defs$name)  # Initial transition # 3 LUs, so each year land-use change is represented by 3x3 transitions. # The first 3 numbers are the transitions from each LU to the first LU, # the following three numbers are the transitions from each LU to the second LU, and so on. initial_transition <- c(0, 0, 0, 0.66, 0, 0, 0.34, 0, 0)  # Fallow pattern: fallow_pattern <- c(         c(0, 0, 0, 0, 0, 0.33, 0, 0.33, 0),         rep(0, 9) # null pattern ) # We repeat the harvest pattern enough times fallow_transitions <- rep(harvest_pattern, 150)  # We add all the transition matrix transitions_matrix <- build_luc_matrix(list(initial_transition, fallow_transitions), n_lu, n_trans)  # We set the LU definitions and transition forcing in the driver: df_drivers$init_lu[[1]] <- lu_defs df_drivers$luc_forcing[[1]]  <- transitions_matrix  # We configure three cohorts df_drivers$init_cohort[[1]] <- tibble(         init_cohort_species = c(2, 1, 2),      # species         init_cohort_nindivs = rep(0.05, 3), # initial individual density, individual/m2 ! 1 indiv/m2 = 10.000 indiv/ha         init_cohort_bl      = rep(0.0,  3), # initial biomass of leaves, kg C/individual         init_cohort_br      = rep(0.0,  3), # initial biomass of fine roots, kg C/individual         init_cohort_bsw     = rep(0.05, 3), # initial biomass of sapwood, kg C/individual         init_cohort_bHW     = rep(0.0,  3), # initial biomass of heartwood, kg C/tree         init_cohort_seedC   = rep(0.0,  3), # initial biomass of seeds, kg C/individual         init_cohort_nsc     = rep(0.05, 3), # initial non-structural biomass         lu_index            = c(1, 2, 3)    # index land use (LU) containing this cohort. 0 (default) means any vegetated tile will contain a copy. )"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_luluc.html","id":"luh2-integration","dir":"Articles","previous_headings":"","what":"LUH2 integration","title":"BiomeE LULUC","text":"BiomeE integrates seamlessly LUH2 v2 data (https://web.archive.org/web/20250101000000/https://luh.umd.edu/data.shtml). preprocess LUH2 data use BiomeE can use separate package luhrsofun available (https://github.com/geco-bern/luhrsofun). function luhrsofun::parse_luh2() can used parse LUH2 manually set necessary data driver object running BiomeE. workflow illustrated vignettes luhrsofun package.","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_use.html","id":"demo-data","dir":"Articles","previous_headings":"","what":"Demo data","title":"BiomeE usage","text":"package includes two demo datasets run simulations site CH-LAE either P-model Leuning photosynthesis models. See ‘Two model approaches’ brief description differences. demo files can directly loaded workspace typing: real data Swiss CH-LAE fluxnet site. can use data run model, together observations GPP can also parameterize biomee parameters.","code":"library(rsofun)  biomee_gs_leuning_drivers biomee_p_model_drivers biomee_validation"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_use.html","id":"two-model-approaches","dir":"Articles","previous_headings":"","what":"Two model approaches","title":"BiomeE usage","text":"BiomeE cohort-based vegetation model simulates vegetation dynamics biogeochemical processes (Weng et al., 2015). model able link photosynthesis standard models (Farquhar et al., 1980) tree allometry. formulation retain original model structure standard photosynthesis formulation (.e. “gs_leuning”) well alternative “p-model” approach. model structures operate different time scales, original input hourly time step alternative p-model approach uses daily time step. Hence, two different datasets driver data (BiomeE p-model input aggregate high resolution hourly data).","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_use.html","id":"running-the-biomee-model-with-standard-photosynthesis","dir":"Articles","previous_headings":"Two model approaches","what":"Running the BiomeE model with standard photosynthesis","title":"BiomeE usage","text":"data prepared can run model using runread_biomee_f(). function takes nested data structure runs model site site, returning nested model output results matching input drivers. case one site evaluated.","code":"# print parameter settings biomee_gs_leuning_drivers$params_siml #> [[1]] #> # A tibble: 1 × 10 #>   spinupyears recycle firstyeartrend nyeartrend steps_per_day #>         <dbl>   <dbl>          <dbl>      <dbl>         <dbl> #> 1         250       1           2009          1            24 #> # ℹ 5 more variables: do_U_shaped_mortality <lgl>, #> #   do_closedN_run <lgl>, method_photosynth <chr>, #> #   method_mortality <chr>, do_daily_diagnostics <lgl>  # print forcing head(biomee_gs_leuning_drivers$forcing) #> [[1]] #> # A tibble: 8,760 × 9 #>    date         hod   temp      rain   vpd      ppfd   patm  wind   co2 #>    <date>     <dbl>  <dbl>     <dbl> <dbl>     <dbl>  <dbl> <dbl> <dbl> #>  1 2009-01-01     0 0.728  0.0000184  54.4   3.19e-7 93216.  3.56  388. #>  2 2009-01-01     1 0.780  0.0000116  54.9   3.22e-7 93189.  3.37  388. #>  3 2009-01-01     2 0.519  0.0000116  42.9   3.30e-7 93184.  3.01  388. #>  4 2009-01-01     3 0.476  0.0000116  47.3   3.11e-7 93166.  3.31  388. #>  5 2009-01-01     4 0.336  0.0000140  44.3   3.22e-7 93143.  3.23  388. #>  6 2009-01-01     5 0.278  0.0000140  38.4   3.29e-7 93124.  2.94  388. #>  7 2009-01-01     6 0.0966 0.0000140  28.5   3.29e-7 93114.  2.98  388. #>  8 2009-01-01     7 0.172  0.0000211  28.4   3.35e-7 93111.  3.46  388. #>  9 2009-01-01     8 0.236  0.0000211  30.1   1.79e-5 93118.  3.31  388. #> 10 2009-01-01     9 0.152  0.0000211  24.1   7.89e-5 93132.  3.27  388. #> # ℹ 8,750 more rows set.seed(2023)  # run the model out <- runread_biomee_f(      biomee_gs_leuning_drivers,      makecheck = TRUE,      parallel = FALSE      ) # split out the annual data biomee_gs_leuning_output_annual_tile <- out$data[[1]]$output_annual_tile biomee_gs_leuning_output_annual_cohorts <- out$data[[1]]$output_annual_cohorts"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_use.html","id":"plotting-output","dir":"Articles","previous_headings":"Two model approaches > Running the BiomeE model with standard photosynthesis","what":"Plotting output","title":"BiomeE usage","text":"can now visualize model output.","code":"# we only have one site so we'll unnest # the main model output biomee_gs_leuning_output_annual_tile |>   ggplot() +   geom_line(aes(x = year, y = GPP)) +   theme_classic()+labs(x = \"Year\", y = \"GPP\") biomee_gs_leuning_output_annual_tile |>   ggplot() +   geom_line(aes(x = year, y = plantC)) +   theme_classic()+labs(x = \"Year\", y = \"plantC\")"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_use.html","id":"running-the-biomeep-model","dir":"Articles","previous_headings":"Two model approaches","what":"Running the BiomeEP model","title":"BiomeE usage","text":"Running BiomeE P-model photosynthesis.","code":"# print parameter settings biomee_p_model_drivers$params_siml #> [[1]] #> # A tibble: 1 × 10 #>   spinupyears recycle firstyeartrend nyeartrend steps_per_day #>         <dbl>   <dbl>          <dbl>      <dbl>         <dbl> #> 1         250       1           2009          1             1 #> # ℹ 5 more variables: do_U_shaped_mortality <lgl>, #> #   do_closedN_run <lgl>, method_photosynth <chr>, #> #   method_mortality <chr>, do_daily_diagnostics <lgl>  # print forcing for P-model head(biomee_p_model_drivers$forcing) #> [[1]] #> # A tibble: 365 × 9 #>    date         hod    temp       rain   vpd    ppfd   patm  wind   co2 #>    <date>     <dbl>   <dbl>      <dbl> <dbl>   <dbl>  <dbl> <dbl> <dbl> #>  1 2009-01-01  11.5  0.384  0.0000166   39.5 5.71e-5 93092.  3.00  388. #>  2 2009-01-02  11.5 -1.64   0.0000232   40.5 4.99e-5 93248.  2.97  388. #>  3 2009-01-03  11.5 -2.51   0.00000371  75.9 9.49e-5 93684.  2.84  388. #>  4 2009-01-04  11.5 -1.82   0.0000130   88.0 7.06e-5 93435.  2.67  388. #>  5 2009-01-05  11.5 -1.34   0.0000223   67.8 7.39e-5 93175.  3.21  388. #>  6 2009-01-06  11.5 -0.450  0.0000219   54.0 5.28e-5 93282.  3.03  388. #>  7 2009-01-07  11.5  0.266  0.0000136   64.1 7.11e-5 93511.  2.64  388. #>  8 2009-01-08  11.5  0.504  0.0000113   88.2 9.05e-5 93443.  2.68  388. #>  9 2009-01-09  11.5  0.0869 0.0000186   59.9 5.16e-5 93447.  2.74  388. #> 10 2009-01-10  11.5 -0.404  0.0000125   58.6 8.27e-5 93633.  2.17  388. #> # ℹ 355 more rows # run the model out2 <- runread_biomee_f(      biomee_p_model_drivers,      makecheck = TRUE,      parallel = FALSE      ) # split out the annual data for visuals biomee_p_model_output_annual_tile <- out2$data[[1]]$output_annual_tile biomee_p_model_output_annual_cohorts <- out2$data[[1]]$output_annual_cohorts"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_use.html","id":"plotting-output-1","dir":"Articles","previous_headings":"Two model approaches > Running the BiomeEP model","what":"Plotting output","title":"BiomeE usage","text":"can now visualize model output.","code":"# we only have one site so we'll unnest # the main model output biomee_p_model_output_annual_tile %>%   ggplot() +   geom_line(aes(x = year, y = GPP)) +   theme_classic() +   labs(x = \"Year\", y = \"GPP\") biomee_p_model_output_annual_tile %>%   ggplot() +   geom_line(aes(x = year, y = plantC)) +   theme_classic() +   labs(x = \"Year\", y = \"plantC\") biomee_p_model_output_annual_cohorts %>%    group_by(cID,year) %>%   summarise(dbh = mean(DBH),              npp_per_m2=sum(NPP*density/10000), .groups = \"keep\") %>%    ggplot(aes(x=dbh,y=npp_per_m2,fill=as.factor(year))) +   geom_bar(stat=\"identity\") +   theme_classic()+labs(x = \"Cohort DBH (cm)\", y = \"NPP (kg C m-2)\", fill=\"Year\") +   scale_fill_manual(values = c(\"grey50\")) +   theme(legend.position = c(1.0,1.0), legend.justification = c(1.0,1.0))"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_use.html","id":"calibrating-model-parameters","dir":"Articles","previous_headings":"Two model approaches","what":"Calibrating model parameters","title":"BiomeE usage","text":"optimize new parameters based upon driver data validation dataset must first specify optimization strategy settings, well parameter ranges. example, use cost root mean squared error (RMSE) simulated observed targets (GPP, LAI, Density Biomass) minimize using GenSA optimizer. Using calibrated parameter values, can run BiomeE simulations. Finally, can visually compare two model runs. plot original model run black run using calibrated parameters grey. dashed line represents validation data, .e. observed GPP Biomass.","code":"# Mortality as DBH settings <- list(   method = \"GenSA\",   metric = cost_rmse_biomee,   control = list(     maxit = 10,     verbose = TRUE   ),   par = list(       phiRL     = list(lower=0.5, upper=5,   init=3.5),       LAI_light = list(lower=2,   upper=8,   init=3.5),       tf_base   = list(lower=0.5, upper=1.5, init=1),       par_mort  = list(lower=0.005, upper=4,   init=0.5)) )  # Using BiomeEP (with P-model for photosynthesis) pars_all <- calib_sofun(   drivers = biomee_p_model_drivers,   obs = biomee_validation,   settings = settings ) pars <- pars_all[\"par\"] # replace parameter values by calibration output drivers <- biomee_p_model_drivers drivers$params_species[[1]]$phiRL[]  <- pars$par[1] drivers$params_species[[1]]$LAI_light[]  <- pars$par[2] drivers$params_tile[[1]]$tf_base <- pars$par[3] drivers$params_tile[[1]]$par_mort <- pars$par[4]  drivers$params_siml[[1]]$spinupyears <- 600  # run the model with new parameter values calibrated_out <- runread_biomee_f(      drivers,      makecheck = TRUE,      parallel = FALSE      )  # split out the annual data biomee_p_model_calibratedOutput_annual_tile <- calibrated_out$data[[1]]$output_annual_tile # unnest model output for our single site GPP_target <- biomee_validation$data[[1]] |>    dplyr::filter(variables==\"GPP\") |>    magrittr::extract2(\"targets_obs\") plantC_target <- biomee_validation$data[[1]] |>    dplyr::filter(variables==\"Biomass\") |>    magrittr::extract2(\"targets_obs\")  ggplot() +   geom_line(data = biomee_p_model_output_annual_tile,             aes(x = year, y = GPP)) +   geom_line(data = biomee_p_model_calibratedOutput_annual_tile,             aes(x = year, y = GPP),             color = \"grey50\") +   geom_hline(yintercept = GPP_target,               linetype = \"dashed\",              color = \"grey50\") +   theme_classic() +    labs(x = \"Year\", y = \"GPP\") ggplot() +   geom_line(data = biomee_p_model_output_annual_tile,             aes(x = year, y = plantC)) +   geom_line(data = biomee_p_model_calibratedOutput_annual_tile,             aes(x = year, y = plantC),             color = \"grey50\") +   geom_hline(yintercept = plantC_target,               linetype = \"dashed\",               color = \"grey50\") +   theme_classic() +    labs(x = \"Year\", y = \"plantC\")"},{"path":"https://fabern.github.io/rsofun/dev/articles/biomee_use.html","id":"validating-model-output","dir":"Articles","previous_headings":"Two model approaches","what":"Validating model output","title":"BiomeE usage","text":"ensure behavior calibrated model expected output validated different consistency checks. One possible check ensure reached expected steady state conditions trend present total carbon. Note vegetation C pool reaches steady state relatively fast, soil C pool takes time:   Note carbon cycle steady state assumption appears good. However, nitrogen cycle see . analysis relies nitrogen steady-state spinupyears might need increased.","code":"pl1 <- biomee_p_model_calibratedOutput_annual_tile %>%   ggplot(aes(x = year)) +   geom_line(aes(y = plantC+soilC, color = \"total C\", linetype = \"total C\")) +   geom_line(aes(y = soilC,        color = \"soil C\",  linetype = \"soil C\")) +   geom_line(aes(y = plantC,       color = \"plant C\", linetype = \"plant C\")) +   # geom_hline(yintercept = plantC_target, linetype = \"solid\", color = \"grey50\") +   theme_classic() +   scale_color_manual(values = c(\"total C\"=\"black\",                                 \"soil C\" =\"darkred\",                                 \"plant C\"=\"darkgreen\")) +   scale_linetype_manual(values = c(\"total C\"=3,                                    \"soil C\" =2,                                    \"plant C\"=1)) +   labs(x = \"Year\", y = \"kg C m-2\", linetype = NULL, color = NULL) +    theme(legend.position = c(1,0.5), legend.justification = c(1,0.5))  pl2 <- biomee_p_model_calibratedOutput_annual_tile %>%   ggplot(aes(x = year)) +   # geom_line(aes(y = NPP,          color = \"plant: NPP\", linetype = \"plant: NPP\")) +   geom_line(aes(y = GPP,          color = \"plant: GPP\",           linetype = \"plant: GPP\")) +   geom_line(aes(y = GPP-Rauto,    color = \"plant: NPP=GPP-Rauto\", linetype = \"plant: NPP=GPP-Rauto\")) +   geom_line(aes(y = Rh,           color = \"soil: Rh\",             linetype = \"soil: Rh\")) +   geom_line(aes(y = NPP-Rh,       color = \"total: NEE=NPP-Rh\",    linetype = \"total: NEE=NPP-Rh\")) +   # geom_hline(yintercept = GPP_target, linetype = \"solid\", color = \"grey50\") +   theme_classic() +   scale_color_manual(values = c(\"total: NEE=NPP-Rh\"   =\"black\",                                 \"soil: Rh\"           =\"darkred\",                                 \"plant: GPP\"          =\"darkgreen\",                                 \"plant: NPP\"          =\"darkgreen\",                                 \"plant: NPP=GPP-Rauto\"=\"darkgreen\")) +     scale_linetype_manual(values = c(\"total: NEE=NPP-Rh\"   =3,                                      \"soil: Rh\"           =2,                                      \"plant: GPP\"          =1,                                      \"plant: NPP\"          =2,                                      \"plant: NPP=GPP-Rauto\"=2)) +   labs(x = \"Year\", y = \"kg C m-2 yr-1\", linetype = NULL, color = NULL) +    theme(legend.position = c(1,0.5), legend.justification = c(1,0.5)) pl1 pl2 pl3 <- biomee_p_model_calibratedOutput_annual_tile %>%   ggplot(aes(x = year)) +   geom_line(aes(y = plantN+soilN, color = \"total N\", linetype = \"total N\")) +   geom_line(aes(y = soilN,        color = \"soil N\",  linetype = \"soil N\")) +   geom_line(aes(y = plantN,       color = \"plant N\", linetype = \"plant N\")) +   theme_classic() +   scale_color_manual(values = c(\"total N\"=\"black\",                                 \"soil N\" =\"darkred\",                                 \"plant N\"=\"darkgreen\")) +   scale_linetype_manual(values = c(\"total N\"=3,                                    \"soil N\" =2,                                    \"plant N\"=1)) +   labs(x = \"Year\", y = \"kg N m-2\", linetype = NULL, color = NULL) +    theme(legend.position = c(1,0.5), legend.justification = c(1,0.5))  pl3"},{"path":"https://fabern.github.io/rsofun/dev/articles/data_format.html","id":"philosophy","dir":"Articles","previous_headings":"","what":"Philosophy","title":"Data format","text":"Overall, package uses {tidyverse} data paradigm (Wickham, 2017), using nested data frames (tibbles) store model input output, validation data. possible package uses consistent ontogeny terms variables data structures used.","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/data_format.html","id":"drivers-data-inputs","dir":"Articles","previous_headings":"","what":"Drivers data (inputs)","title":"Data format","text":"drivers object used unique input models, consisting list sites. site (.e. row) contains following data: - sitename: site name - site_info: location specific site information (nested tibble) - params_siml: simulation parameter settings (nested tibble) - forcing: environmental forcing data (nested tibble) provided demo drivers contain one sample site: Nested data structures can accessed like :","code":"# call to the included p-model demo drivers rsofun::p_model_drivers #> # A tibble: 1 × 4 #>   sitename params_siml       site_info        forcing               #>   <chr>    <list>            <list>           <list>                #> 1 FR-Pue   <tibble [1 × 11]> <tibble [1 × 4]> <tibble [2,190 × 13]>  # call to the included BiomeE (p-model) demo drivers rsofun::biomee_p_model_drivers #> # A tibble: 1 × 8 #>   sitename site_info params_siml params_tile params_species init_cohort #>   <chr>    <list>    <list>      <list>      <list>         <list>      #> 1 CH-Lae   <tibble>  <tibble>    <tibble>    <tibble>       <tibble>    #> # ℹ 2 more variables: init_soil <list>, forcing <list>  # call to the included BiomeE (gs leuning) demo drivers rsofun::biomee_gs_leuning_drivers #> # A tibble: 1 × 8 #>   sitename site_info params_siml params_tile params_species init_cohort #>   <chr>    <list>    <list>      <list>      <list>         <list>      #> 1 CH-Lae   <tibble>  <tibble>    <tibble>    <tibble>       <tibble>    #> # ℹ 2 more variables: init_soil <list>, forcing <list> # Accessing the site information for the first site rsofun::biomee_gs_leuning_drivers$site_info[[1]] #> # A tibble: 1 × 10 #>     lon   lat   elv year_start year_end c4    igbp_land_use #>   <dbl> <dbl> <dbl>      <dbl>    <dbl> <lgl> <chr>         #> 1  8.36  47.5   700       2004     2014 FALSE Mixed Forests #> # ℹ 3 more variables: plant_functional_type <chr>, date_start <date>, #> #   date_end <date>"},{"path":"https://fabern.github.io/rsofun/dev/articles/data_format.html","id":"specific-data-for-each-model","dir":"Articles","previous_headings":"Drivers data (inputs)","what":"Specific data for each model","title":"Data format","text":"model specificities comes set simulation parameters forcing data. Please refer documentation model exhaustive list parameters data required model. P-model: ?run_pmodel_f_bysite BiomeE: ?run_biomee_f_bysite","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/data_format.html","id":"forcing-data","dir":"Articles","previous_headings":"Drivers data (inputs)","what":"Forcing data","title":"Data format","text":"forcing data contains environmental variables commonly available fluxnet (reference) ICOS atmospheric gas exchange measurement locations gathered various gridded re-analysis sources. Forcing data expected sequences complete years (starting January 1st ending december 31st), leap days excluded (February 29th present). model specific forcing data resolution: - P-model: daily - BiomeE (p-model): daily - BiomeE (gs leuning): hourly Forcing data present demo drivers can used examples:","code":"# Detailed look at the forcing data for the P-model rsofun::p_model_drivers$forcing[[1]] #> # A tibble: 2,190 × 13 #>    date        temp   vpd      ppfd netrad    patm  snow     rain  tmin #>    <date>     <dbl> <dbl>     <dbl>  <dbl>   <dbl> <dbl>    <dbl> <dbl> #>  1 2007-01-01 10.0  183.  0.000106    4.17  99944.     0  2.55e-5  7.12 #>  2 2007-01-02  8.42 417.  0.000192  -22.2   99992.     0  6.94e-6  6.79 #>  3 2007-01-03  9.13 566.  0.000187  -16.6  100075      0  0        4.21 #>  4 2007-01-04 10.1  375.  0.0000828 -16.8   99338.     0  0        3.96 #>  5 2007-01-05 10.7  508.  0.000183   -6.60  99419.     0  0        9.26 #>  6 2007-01-06 13.6  656.  0.000188  -11.2   99467.     0  0        8.96 #>  7 2007-01-07 13.7  567.  0.000155    7.32  99252.     0  0        9.55 #>  8 2007-01-08 10.7  273.  0.0000717  -3.00  98871.     0  0        7.04 #>  9 2007-01-09 16.4  682.  0.000188    9.94  99067.     0  0        9.46 #> 10 2007-01-10 11.4   26.0 0.0000277  -6.41  99444.     0  0        8.98 #> # ℹ 2,180 more rows #> # ℹ 4 more variables: tmax <dbl>, fapar <dbl>, co2 <dbl>, ccov <dbl>"},{"path":"https://fabern.github.io/rsofun/dev/articles/data_format.html","id":"output-data","dir":"Articles","previous_headings":"","what":"Output data","title":"Data format","text":"output model contains one line per site found drivers: - sitename: site name - data: output data site (nested tibble) data structure output data specific model.","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/data_format.html","id":"p-model","dir":"Articles","previous_headings":"Output data","what":"P-model","title":"Data format","text":"detailed information content data, see ?run_pmodel_f_bysite.","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/data_format.html","id":"biomee","dir":"Articles","previous_headings":"Output data","what":"BiomeE","title":"Data format","text":"data contains following tables: - output_daily_tile: Daily output simulated period - output_annual_cohorts: Annual output cohort level simulated period - output_annual_tile: Yearly output spin-simulated periods. detailed information table, see ?run_biomee_f_bysite.","code":""},{"path":"https://fabern.github.io/rsofun/dev/articles/new_cost_function.html","id":"calibration-to-gpp-using-rmse-and-gensa-optimizer","dir":"Articles","previous_headings":"","what":"Calibration to GPP using RMSE and GenSA optimizer","title":"Parameter calibration and cost functions","text":"simple approach parameter calibration find parameter values lead best prediction performance, terms RMSE (root mean squared error). function cost_rmse_pmodel() runs P-model internally calculate RMSE predicted target values (case GPP) corresponding observations. implementations cost_rmse_pmodel() calib_sofun() allows flexibility various ways. can simultaneously calibrate subset model parameters also replicate different calibration setups Stocker et al., 2020 GMD, simply providing appropriate inputs settings, par_fixed targets calib_sofun(). Since P-model run internally make predictions, must always specify values model parameters aren’t calibrated (via argument par_fixed). example, following ORG setup, parameter kphio calibrated code: output calib_sofun() list containing calibrated parameter values (element par) raw optimization output optimizer (element mod; GenSA , see next, BayesianTools::runMCMC). Note standard cost functions allow calibrate several targets (fluxes leaf traits predicted P-model) simultaneously parallelize simulations.","code":"# Define calibration settings and parameter ranges from previous work settings_rmse <- list(   method = 'GenSA',                   # minimizes the RMSE   metric = cost_rmse_pmodel,          # our cost function returning the RMSE   control = list(                     # control parameters for optimizer GenSA     maxit = 100),                        par = list(                         # bounds for the parameter space     kphio = list(lower=0.02, upper=0.2, init=0.05)   ) )  # Calibrate the model and optimize the free parameters using # demo datasets pars_calib_rmse <- calib_sofun(   # calib_sofun arguments:   drivers = p_model_drivers,     obs = p_model_validation,   settings = settings_rmse,   # extra arguments passed to the cost function:   par_fixed = list(         # fix all other parameters     kphio_par_a        = 0.0,        # set to zero to disable temperature-dependence                                       # of kphio, setup ORG     kphio_par_b        = 1.0,     soilm_thetastar    = 0.6 * 240,  # to recover paper setup with soil moisture stress     soilm_betao        = 0.0,     beta_unitcostratio = 146.0,     rd_to_vcmax        = 0.014,      # value from Atkin et al. 2015 for C3 herbaceous     tau_acclim         = 30.0,     kc_jmax            = 0.41   ),   targets = \"gpp\"           # define target variable GPP ) pars_calib_rmse #> $par #>      kphio  #> 0.03580938  #>  #> $mod #> $mod$value #> [1] 1.20014 #>  #> $mod$par #>      kphio  #> 0.03580938  #>  #> $mod$trace.mat #>      nb.steps temperature function.value current.minimum #> [1,]        1        5230       4.241255         1.20014 #>  #> $mod$counts #> [1] 286"},{"path":"https://fabern.github.io/rsofun/dev/articles/new_cost_function.html","id":"calibration-to-gpp-using-a-simple-likelihood-function-and-bayesiantools","dir":"Articles","previous_headings":"","what":"Calibration to GPP using a simple likelihood function and BayesianTools","title":"Parameter calibration and cost functions","text":"Let’s calibrate parameters involved temperature dependency quantum yield efficiency, kphio, kphio_par_a kphio_par_b. Taking Bayesian calibration approach, need define likelihood cost function (’ll use cost_likelihood_pmodel()). assume target variable ('gpp') follows normal distribution centered observations unknown standard deviation ('err_gpp'), need add calibratable parameters. also assume uniform prior distribution calibratable parameters. maximizing log-likelihood, MAP (maximum posteriori) estimators 4 parameters computed. functions cost_likelihood_pmodel() calib_sofun(), can easily perform type calibration: Furthermore, equivalent cost functions available BiomeE model. Check reference pages details use cost_likelihood_biomee() cost_rmse_biomee().","code":"# Define calibration settings settings_likelihood <- list(   method = 'BayesianTools',   metric = cost_likelihood_pmodel,            # our cost function   control = list(                             # optimization control settings for      sampler = 'DEzs',                           # BayesianTools::runMCMC     settings = list(       burnin = 1500,       iterations = 3000     )),   par = list(     kphio = list(lower = 0, upper = 0.2, init = 0.05),     kphio_par_a = list(lower = -0.5, upper = 0.5, init = -0.1),     kphio_par_b = list(lower = 10, upper = 40, init =25),     err_gpp = list(lower = 0.1, upper = 4, init = 0.8)   ) )  # Calibrate the model and optimize the free parameters using # demo datasets pars_calib_likelihood <- calib_sofun(   # calib_sofun arguments:   drivers = p_model_drivers,   obs = p_model_validation,   settings = settings_likelihood,   # extra arguments passed ot the cost function:   par_fixed = list(         # fix all other parameters     soilm_thetastar    = 0.6 * 240,  # to recover paper setup with soil moisture stress     soilm_betao        = 0.0,     beta_unitcostratio = 146.0,     rd_to_vcmax        = 0.014,      # value from Atkin et al. 2015 for C3 herbaceous     tau_acclim         = 30.0,     kc_jmax            = 0.41   ),   targets = \"gpp\" ) pars_calib_likelihood #> $par #>        kphio  kphio_par_a  kphio_par_b      err_gpp  #>  0.036462810 -0.001859453 14.614170205  1.209760614  #>  #> $mod #> [1] \"mcmcSampler - you can use the following methods to summarize, plot or reduce this class:\" #> [1] plot    print   summary #> see '?methods' for accessing help and source code"},{"path":"https://fabern.github.io/rsofun/dev/articles/new_cost_function.html","id":"calibration-to-gpp-and-vcmax25-using-the-joint-log-likelihood-and-bayesiantools","dir":"Articles","previous_headings":"","what":"Calibration to GPP and Vcmax25 using the joint log-likelihood and BayesianTools","title":"Parameter calibration and cost functions","text":"may interested calibrating model different target variables simultaneously, like flux leaf trait measurements. present example, use cost_likelihood_pmodel() compute joint likelihood targets specified (, summing log-likelihoods GPP Vcmax25) ultimately calibrate kc_jmax parameter. possible follow workflow several-target calibration also RMSE optimization metric, using cost_rmse_pmodel() GenSA optimization. Note GPP predictions directly compared GPP observations day, Vcmax25 predicted P-model (leaf trait) averaged growing season compared single Vcmax25 observation taken per site. cost functions provided package tell apart fluxes leaf traits presence \"date\" column nested validation data frames p_model_validation p_model_validation_vcmax25.","code":"# Define calibration settings for two targets settings_joint_likelihood <- list(   method = \"BayesianTools\",   metric = cost_likelihood_pmodel,   control = list(     sampler = \"DEzs\",     settings = list(       burnin = 1500,             # kept artificially low       iterations = 3000     )),   par = list(kc_jmax = list(lower = 0.2, upper = 0.8, init = 0.41),  # uniform priors              err_gpp = list(lower = 0.001, upper = 4, init = 1),              err_vcmax25 = list(lower = 0.000001, upper = 0.0001, init = 0.00001)) )  # Run the calibration on the concatenated data par_calib_join <- calib_sofun(   drivers = rbind(p_model_drivers,                   p_model_drivers_vcmax25),    obs = rbind(p_model_validation,               p_model_validation_vcmax25),       settings = settings_joint_likelihood,   # arguments for the cost function   par_fixed = list(         # fix parameter value from previous calibration     kphio              = 0.041,     kphio_par_a        = 0.0,     kphio_par_b        = 16,     soilm_thetastar    = 0.6 * 240,  # to recover paper setup with soil moisture stress     soilm_betao        = 0.0,     beta_unitcostratio = 146.0,     rd_to_vcmax        = 0.014,      # value from Atkin et al. 2015 for C3 herbaceous     tau_acclim         = 30.0   ),       targets = c('gpp', 'vcmax25') ) par_calib_join #> $par #>      kc_jmax      err_gpp  err_vcmax25  #> 4.824008e-01 1.189628e+00 3.289346e-05  #>  #> $mod #> [1] \"mcmcSampler - you can use the following methods to summarize, plot or reduce this class:\" #> [1] plot    print   summary #> see '?methods' for accessing help and source code"},{"path":"https://fabern.github.io/rsofun/dev/articles/new_cost_function.html","id":"write-your-custom-cost-function","dir":"Articles","previous_headings":"","what":"Write your custom cost function","title":"Parameter calibration and cost functions","text":"RMSE log-likelihood (one several targets) cost functions provide fit use case, can easily write custom one. section, drive main ideas example. run calibration, can still use calib_sofun() combination custom cost function. routine calib_sofun() requires drivers, obs settings mandatory arguments. provide data.frames driver observational data, well settings calibration. optional argument optim_out defines raw optimization output returned. (optional) arguments calib_sofun() passed cost function (e.g. par_fixed example). can used freely inside custom cost function, e.g. control simulation setup processing. top optional arguments, also possible extend drivers obs data.frames additional columns can used freely fine-grained control within custom cost function. cost functions must take least three arguments: par: named vector calibratable model parameters. iteration optimization, new set values par used run model compute cost. obs: data frame observations, compare simulation results. drivers: data frame driver data, used run simulations. Additional optional arguments can used, example model parameter values fixed across simulations, etc. ’ll walk definition custom cost function. example, ’ll calibrate soil moisture stress parameters use mean absolute error (MAE) custom cost function. Since calibrating parameters based model outputs, cost function eventually need run P-model compare output observed validation data. get started suggest write dummy cost function use together calib_sofun() shown . Note one way developing cost function use browser() statement development. allows explore variables access within cost function. optimization procedure, cost function receives argument suggestion parameters par. might just subset needed parameters (defined via settings$par). Thus call runread_pmodel_f() within cost function, full set model parameters needed. , ’ll hardcode parameters aren’t calibrated inside cost function. (Note, examples passed additional argument par_fixed). following chunk defines final function. clean observations model output align data according site date, compute mean absolute error (MAE) GPP. Finally, function return scalar value, case MAE, want minimize. Keep mind GenSA optimization minimize cost, BayesianTools method cost (.e. likelihood) always maximized. last step, let’s verify calibration procedure runs using cost function.","code":"# Define the custom cost function to be used cost_mae <- function(par, obs, drivers, my_own_message){   # Your code   browser() # can facilitate the development, remove afterwards }  # Define calibration settings and parameter ranges settings_mae <- list(   method = 'GenSA',   metric = cost_mae, # directly uses the custom cost function   control = list(     maxit = 100   ),   par = list(     soilm_thetastar = list(lower=0.0, upper=3000, init=0.6*240),     soilm_betao = list(lower=0, upper=1, init=0.2)   ) )  # Calibrate the model and optimize the free parameters pars_calib_mae <- calib_sofun(   drivers = p_model_drivers,   obs = p_model_validation,   settings = settings_mae,   # optional arguments if needed in the cost function   my_own_message = \"Hi from inside the cost_mae function.\" ) cost_mae <- function(par, obs, drivers, my_own_message){      # Set values for the list of calibrated and non-calibrated model parameters   params_modl <- list(     kphio              = 0.09423773,     kphio_par_a        = 0.0,     kphio_par_b        = 25,     soilm_thetastar    = par[[\"soilm_thetastar\"]],     soilm_betao        = par[[\"soilm_betao\"]],     beta_unitcostratio = 146.0,     rd_to_vcmax        = 0.014,     tau_acclim         = 30.0,     kc_jmax            = 0.41   )      # Run the model   df <- runread_pmodel_f(     drivers,     par = params_modl,     makecheck = TRUE,     parallel = FALSE   )      # Your code to compute the cost   print(my_own_message) # useless, but showcases how to use additional arguments   browser() # can facilitate the development, remove afterwards } cost_mae <- function(par, obs, drivers){    # Set values for the list of calibrated and non-calibrated model parameters   params_modl <- list(     kphio              = 0.09423773,     kphio_par_a        = 0.0,     kphio_par_b        = 25,     soilm_thetastar    = par[[\"soilm_thetastar\"]],     soilm_betao        = par[[\"soilm_betao\"]],     beta_unitcostratio = 146.0,     rd_to_vcmax        = 0.014,     tau_acclim         = 30.0,     kc_jmax            = 0.41   ) # Set values for the list of calibrated and non-calibrated model parameters         # Run the model   df <- runread_pmodel_f(     drivers = drivers,     par = params_modl,     makecheck = FALSE,     parallel = FALSE   )      # Clean model output to compute cost   df <- df %>%     dplyr::select(sitename, data) %>%     tidyr::unnest(data)        # Clean validation data to compute cost   obs <- obs %>%     dplyr::select(sitename, data) %>%     tidyr::unnest(data) %>%     dplyr::rename('gpp_obs' = 'gpp') # rename for later        # Left join model output with observations by site and date   df <- dplyr::left_join(df, obs, by = c('sitename', 'date'))      # Compute mean absolute error   cost <- mean(abs(df$gpp - df$gpp_obs), na.rm = TRUE)      # Return the computed cost   return(cost)   # browser() # can facilitate the development, remove afterwards } # Define calibration settings and parameter ranges settings_mae <- list(   method = 'GenSA',   metric = cost_mae, # our cost function   control = list(     maxit = 100),   par = list(     soilm_thetastar = list(lower=0.0, upper=3000, init=0.6*240),     soilm_betao = list(lower=0, upper=1, init=0.2)   ) )  # Calibrate the model and optimize the free parameters pars_calib_mae <- calib_sofun(   drivers = p_model_drivers,   obs = p_model_validation,   settings = settings_mae ) pars_calib_mae #> $par #> soilm_thetastar     soilm_betao  #>    2942.7566560       0.2649316  #>  #> $mod #> $mod$value #> [1] 1.072192 #>  #> $mod$par #> soilm_thetastar     soilm_betao  #>    2942.7566560       0.2649316  #>  #> $mod$trace.mat #>      nb.steps temperature function.value current.minimum #> [1,]        1  5230.00000       3.918748        1.078549 #> [2,]       37    30.00603       1.072921        1.072192 #>  #> $mod$counts #> [1] 742"},{"path":"https://fabern.github.io/rsofun/dev/articles/param_calib_multitarget.html","id":"calibrating-one-gpp-and-one-d13c-site","dir":"Articles","previous_headings":"","what":"Calibrating one GPP and one D13C site","title":"Parameter calibration (P-Model) to multiple targets (GPP, bigD13C) QUARTO","text":"section present example, use cost_likelihood_pmodel() compute joint likelihood targets specified (, summing log-likelihoods GPP bigD13C) ultimately calibrate beta_unitcostratio parameter. section , calibrate another example multiple sites. Calibration calib_sofun returns object contains maximum--posteriori (MAP) estimates parameters par full distribution parameters MCMC chains mod. Besides also reports additional information. Note GPP predictions directly compared GPP observations day, leaf trait bigD13C predicted P-model “onestep” prediction average conditions growing season compared (multiple) bigD13C observations taken across trees per site. specified arguments drivers obs. Namely, specified column params_siml$onestep within drivers, can FALSE (daily simulation) TRUE (onestep acclimation), corresponding column forcing containing daily average conditions, column targets specified simulation site (.e. row drivers obs). details, unfold code check documentation pmodel_drivers pmodel_validation.","code":"# Define calibration settings for two targets params_to_estimate <- list(   beta_unitcostratio = list(lower = 14.6,  upper = 440, init = 146.0),  # uniform priors   kc_jmax            = list(lower = 0.2,   upper = 0.8, init = 0.41),   # uniform priors   err_gpp            = list(lower = 0.001, upper = 4,   init = 1),   err_bigD13C        = list(lower = 0.01,  upper = 3,   init = 0.8))  params_fixed <- list( # fix parameter value from previous calibration   kphio              = 0.041,   kphio_par_a        = 0.0,   kphio_par_b        = 16,   soilm_thetastar    = 0.6 * 240,  # to recover paper setup with soil moisture stress   soilm_betao        = 0.01,   rd_to_vcmax        = 0.014,      # value from Atkin et al. 2015 for C3 herbaceous   tau_acclim         = 30.0)  settings_joint_likelihood <- list(   method = \"BayesianTools\",   metric  = rsofun::cost_likelihood_pmodel,   control = list(     sampler_runMCMC = \"DREAMzs\",     settings_runMCMC = list(       # burnin = 1500,             # kept artificially low       # iterations = 3000,       burnin = 0,       iterations = 50,   # kept artificially low       nrChains   = 1     ),     # optional parallelization     n_parallel_nrChains = 1  # 2, this can be parallelized   ),   # parameters   par = params_to_estimate )  # Run the calibration on the observational data of two sites drivers <- pmodel_drivers    |>   dplyr::filter(sitename %in% c(\"FR-Pue\", \"lon_+146.13_lat_-032.97\")) obs <- pmodel_validation |>   dplyr::filter(sitename %in% c(\"FR-Pue\", \"lon_+146.13_lat_-032.97\"))  par_calib_join <- calib_sofun(   drivers  = drivers,   obs      = obs,   settings_calib = settings_joint_likelihood,   # arguments for the cost function   par_fixed = params_fixed ) par_calib_join #> $par #> beta_unitcostratio            kc_jmax            err_gpp        err_bigD13C  #>        338.8871156          0.3435334          1.4141445          1.8159620  #>  #> $mod #> [1] \"mcmcSamplerList - you can use the following methods to summarize, plot or reduce this class:\" #> [1] plot    print   summary #> see '?methods' for accessing help and source code #>  #> $name #> [1] \"out_calib_my_calibration_name.rds.log.txt\" #>  #> $logpath #> [1] \"\" #>  #> $walltime #> Time difference of 1.476193 secs # Note the columns: 'targets', and 'data' (containing observations) # TODO: reactivate pmodel_validation |> tidyr::unnest_wider(targets, names_sep = \"_\") # TODO: reactivate pmodel_validation |> dplyr::filter(grepl(\"lon\", sitename)) |>  tidyr::unnest(data) # TODO: reactivate pmodel_validation |> dplyr::filter(grepl(\"^[A-Z]\", sitename)) |> tidyr::unnest(data) # TODO: reactivate  # TODO: reactivate pmodel_drivers |> dplyr::filter(grepl(\"lon\", sitename)) |>  tidyr::unnest(forcing) # TODO: reactivate pmodel_drivers |> dplyr::filter(grepl(\"^[A-Z]\", sitename)) |> tidyr::unnest(forcing) # TODO: reactivate  # TODO: reactivate pmodel_drivers |> dplyr::filter(grepl(\"lon\", sitename)) |>  tidyr::unnest(params_siml) # TODO: reactivate pmodel_drivers |> dplyr::filter(grepl(\"^[A-Z]\", sitename)) |> tidyr::unnest(params_siml)"},{"path":"https://fabern.github.io/rsofun/dev/articles/param_calib_multitarget.html","id":"calibrating-multiple-gpp-and-d13c-sites","dir":"Articles","previous_headings":"","what":"Calibrating multiple GPP and D13C sites","title":"Parameter calibration (P-Model) to multiple targets (GPP, bigD13C) QUARTO","text":"define helper functions facilitate model calibration different target variables, resulting thus different calibration setups. helper functions simplify use parallel execution avoid code repetition. , showcase two different setups. first setup uses D13C target variable (corresponds Setup S1 documentation paper). second setup uses D13C GPP calibration targets (truncated) normal priors parameters (Setup S6). code, define first two different calibration setups specifying function setup_rsofun_calibration(), returns object necessary specifications. specifications can differ selection calibration parameters priors, data used potentially test-train split. , setups uniquely identified numeric identifer. code defines setup_rsofun_calibration() setups 226 231. also define function run Markov Chain Monte Carlo (MCMC) sampling run_mcmc_rsofun(). function reads unique setup identifier uses function setup_rsofun_calibration() get necessary definitions. code can easily parallelized multiple jobs. additionally showcase parallelize multiple chains different cores (n_parallel_independent = 8) thus significantly speed long-running calibration tasks. long-running calibrations can also useful able continue existing sampling chain continue_mcmc_rsofun(). shown vignette, code available Zenodo (10.5281/zenodo.17204361). helper functions specified, can run two calibration setups. sampled MCMC chains stored specified path can easily loaded later time separate R session. , second setup run second time making use parallel sampling independent chains. make use arguments user-defined function run_mcmc_rsofun() allow us specify calibration setup, MCMC setup, parallelization strategy. Note parallelized version reduced walltime 4x. additional independent MCMC chains (e.g. rsofun documentation paper used 8 chains), can become important. Since MCMC sampling can long running tasks, resulting MCMC sampling chains stored disk, can easily recovered later R session analysis similar one . paralell MCMC sampling workers don’t send output console. logfile created progress can checked . example resulted common log file eight workers: MCMC sampling (potentially new R script), load sampled chains analyse chain convergence posterior distribution. load previous results RDS files: define labelling changes obtain nicer looking plots. define function plot_mcmc_trace() plot trace plot MCMC sampling including Gelman-Rubin statistics easily assess convergence two calibration setups. vignette examples run MCMC long enough see converging trace plots. real application, one need increase number iterations. can see number chains, 8 independent chains, consisting 3 internal chains total 24 traces plots. Note 3 internal chains also reduce length iterations specified 600 200.   illustrate posterior (derived unconverged example MCMC chains) defining function plot_prior_posterior_density() shows prior posterior distributions. can clearly distinguish different priors used two setups, calibration constrains posteriors different parameter values.  joint prior distributions parameters can assessed correlation parameters, indicating compensating effects often also called equifinality - model output different parameter sets.  Eventually, want use calibrated model predictions also check agreement observations used calibration. define another helper function run_prediction_rsofun(), samples parameter sets MCMC chain make predictions. second function samples errors identified structural uncertainty (error model) combines predictions. use helper functions (setup_rsofun_calibration(), apply_bias_correction_and_sample_error(), predict_sofun_parallelized()). functions can generate predictions using e.g. Maximum--Posteriori (MAP) parameters well n=20 samples posterior. function plot_predobs_gpp_timeseries3() analyse_modobs3(), model output observations can compared either time series plots scatter plots. plot time series comparing predictions observations, can distinguish parametric uncertainty (‘Posterior’) related width posterior distribtution parameters structural uncertainty (model uncertainty) includes samples error model.  show density scatter plot comparing predictions observations. Since use MAP values predictions, uncertainty parameters taken account. plots useful detect model biases specific target variables specific ranges target variables.  vignette hopefully gives first glimpse realistic workflow calibrates rsofun multiple sites multiple targets. details refer model documentation paper (Paredes et al. 2025) code referred therein.","code":"# TODO reactivate: set eval to TRUE #| code-fold: true  #    226: Setup c)      Delta^'13 C*',VJ #    231: Setup h)      Delta^'13 C*',VJ, GPP  setup_rsofun_calibration <- function(scenario) {   ## Load forcing and targets data from disk (here now from package) ----   bigD13C_vj_gpp_drivers <- rsofun::pmodel_drivers   bigD13C_vj_gpp_obs     <- rsofun::pmodel_validation    # ## Read test-train split from disk ----   # read_csv(here::here(\"data/01_test_train_split.csv\"))   # Not needed here for vignette    ## Preprocess observation data (gpp) ----   ## # no additinal QC needed    ## Apply test-train split to data ----   train_drivers <- bigD13C_vj_gpp_drivers   train_obs     <- bigD13C_vj_gpp_obs    test_drivers <- bigD13C_vj_gpp_drivers |> slice(0)   test_obs     <- bigD13C_vj_gpp_obs     |> slice(0)    ## Setup the settings for the different calibration scenarios ----   ## Define default parameter   default_par_fixed <- list( # fix parameter value from previous calibration     kphio              = 0.04998,    # value from Stocker et al. 2020     kphio_par_a        = 0.0,        # 0 corresponds to no temperature dependency of kphio (ORG setup in Stocker et al. 2020)     kphio_par_b        = 1.0,        #     soilm_thetastar    = 0.6 * 240,  # to recover paper setup with soil moisture stress     soilm_betao        = 0.01,       # 1 corresponds to no reduction, 0 to full reduction at theta==0     beta_unitcostratio = 146.0,      # value from Stocker et al. 2020     rd_to_vcmax        = 0.014,      # value from Atkin et al. 2015 for C3 herbaceous     tau_acclim         = 14.0,       # value from Liu et al. 2024     kc_jmax            = 0.41        # value from Stocker et al. 2024 (citing Wang et al. 2017)   )    ## Define parameters to estimate and their priors   if (scenario %in% c(223, 226, 231)) { # 231 is like 223 but using posteriors from 226     par_to_estimate <- list(       kphio           = list(lower = 0.02, upper = 0.15, init = 0.05),       kphio_par_a     = list(lower = -0.004, upper = -0.001, init = -0.0025),       kphio_par_b     = list(lower = 10, upper = 30, init = 20),       soilm_thetastar = list(lower = 1, upper = 250, init = 40),       beta_unitcostratio = as.list(c(lower = 0.1, upper = 3.0, init = 1.0) * 146.0),       # truncated normal, with ~14 days as mean, taken from Liu et al.       # 2024, Nat.Plants and Mäkelä et al. 2004, Tree Phys.       tau_acclim      = list(mean = 14, sd = 8, lower = 0.01, upper = 40),       kc_jmax         = as.list(0.41 * c(lower = 0.1, upper = 3.0, init = 1.0)),       err_gpp         = list(lower = 0.01, upper = 3, init = 0.8),       err_bigD13C     = list(lower = 0.01, upper = 3, init = 0.8)     )     if (scenario %in% c(223, 226, 231)) {       par_to_estimate$err_bigD13C     <- list(lower = 0.01, upper = 15, init = 0.8)     }   } else {     stop(sprintf(\"Unsupported scenario: %d\", scenario))   }    if (scenario %in% c(231)) {   # 231 is like 223 but using posteriors from 226     # for beta_unitcostratio and kc_jmax as priors     # Below was done iteratively     # calib_scen226 <- readr::read_rds(file.path(rsofun_doc_output_path, \"data\",\"calibrations\",\"out_calib__scen226_DREAMzs-100000-0iter_8x3chains_on_CPU8x1_continued.rds\"))     # # i) extract samples as a data.frame     # burnins_scen226 <- 30000     # samples_scen226 <- getSample(calib_scen226$mod, thin = 1, start = burnins_scen226) %>% as.data.frame()     #     # # ii) fit normal and lognormal distributions for each parameter     # param_normals_scen226 <- lapply(setNames(names(samples_scen226), names(samples_scen226)), function(p) {     #   list(mean = mean(samples_scen226[[p]]),     #       sd   = sd(  samples_scen226[[p]]))     # })[c('beta_unitcostratio', 'kc_jmax')] # only keep these     #     # # then pass on these as prior for these     # par_to_estimate$beta_unitcostratio <- param_normals_scen226$beta_unitcostratio     # par_to_estimate$kc_jmax            <- param_normals_scen226$kc_jmax      par_to_estimate$beta_unitcostratio <- list(mean    = 207.86, sd    = 6.79)     par_to_estimate$kc_jmax            <- list(mean    = 0.4244, sd    = 0.0217)     if (scenario %in% c(231)) {       # truncated normal:       par_to_estimate$beta_unitcostratio <- list(mean    = 207.86, sd    = 6.79,         lower = 207.86 - 3 * 6.79,         upper = 207.86 + 3 * 6.79)       # normal:       par_to_estimate$kc_jmax            <- list(mean    = 0.4244, sd    = 0.0217)     }   }   # Remove parameters that are defined to be estimated from default_par_fixed   par_to_fix <- default_par_fixed[!(names(default_par_fixed) %in% names(par_to_estimate))]    ## Setup the data (drivers and obs) for the three calibration scenarios ----    # Subset different combination sites to dfeine target variables.   # For easier handling do this in combined drivobs-object.   drivobs_train_bigD13C_vj_gpp <- dplyr::inner_join(     train_drivers,     train_obs,     by = join_by(sitename))    drivobs_test_bigD13C_vj_gpp <- dplyr::inner_join(     test_drivers,     test_obs,     by = join_by(sitename))    all_potential_targets <- unique(unlist(drivobs_train_bigD13C_vj_gpp$targets))   if (scenario %in% c(223, 224, 225, 229, 230, 231)) { # GPP and traits data     targets_to_keep <- c(\"gpp\", \"bigD13C\")   } else if (scenario %in% c(226)) {       # only traits data, either both, or vj only, or bigD13C only     targets_to_keep <- c(\"bigD13C\")     # } else if (scenario %in% c(220)) {  # only GPP data from FR-Pue     #   targets_to_keep <- c(\"gpp\")     #   sites_to_keep <- \"FR-Pue\"   } else {     stop(sprintf(\"Unsupported scenario: %d\", scenario))   }   stopifnot(all(targets_to_keep %in% all_potential_targets))    drivobs_train <- drivobs_train_bigD13C_vj_gpp |>     # keep only sites with targets we want     dplyr::rowwise() |> dplyr::filter(any(targets_to_keep %in% .data$targets)) |> dplyr::ungroup() |>     # remove other unwanted target specifications from sites we keep (e.g. ET observations for a site with GPP and ET)     dplyr::mutate(targets = list(intersect(targets, targets_to_keep))) |> dplyr::ungroup()    drivobs_test <- drivobs_test_bigD13C_vj_gpp ## for the test data set keep all    ## return ---   return(list(     drivobs_train = drivobs_train,     drivobs_test = drivobs_test,     par_fixed = par_to_fix,     par = par_to_estimate   )) }   setup_rsofun_calibration(226) setup_rsofun_calibration(226)$drivobs_train setup_rsofun_calibration(231) setup_rsofun_calibration(231)$drivobs_train run_mcmc_rsofun <- function(     curr_calibration_scenario,     # MCMC setup:     iterations = 6,     burnin = 0,     n_chains_independent    = 3, # number of independent chains (called 'nrChains' in runMCMC)     n_chains_within_sampler = 3, # number of internal chains to be sampled (called 'startValue' in runMCMC, at least 2 for DEzs)      # parallelization:     n_parallel_independent  = 3, # number of cores for parallelization of independent chains     https://cran.r-project.org/web/packages/BayesianTools/vignettes/InterfacingAModel.html#running-several-mcmcs-in-parallel     outpath = \"data\",     suffix_str = \"\",     sampler_runMCMC = \"DREAMzs\"     ) {   # Setup simulation model   res <- setup_rsofun_calibration(scenario = curr_calibration_scenario)   # res$drivobs_train   # res$drivobs_test   # res$par_fixed   # res$par    # Load loglikelihood (e.g. if using a tailor-made one, instead of package-provided):   # source(\"R/calibration_helpers.R\", echo = FALSE)   # source(\"R/cost_likelihood_pmodel.R\", echo = FALSE)    # Setup MCMC          # uses drivobs_train, not drivobs_test   driver_to_use_for_mcmc <- select(res$drivobs_train, sitename, params_siml, site_info, forcing)   obs_to_use_for_mcmc    <- select(res$drivobs_train, sitename, targets, data)    calib_sofun_settings <- list(     method = \"BayesianTools\",     metric = rsofun::cost_likelihood_pmodel,     control = list(       sampler_runMCMC = sampler,       settings_runMCMC = list(         burnin     = burnin,                 # 10000,         iterations = iterations,             # 50000,         nrChains   = n_chains_independent,   # number of independent chains to be sampled         startValue = n_chains_within_sampler # number of internal chains to be sampled       ),       n_parallel_nrChains = n_parallel_independent     ),     par = res$par   )    # setup output directories for parallel calibration   logpath <- file.path(outpath, \"calibrations\", paste0(\"out_calib_\", suffix_str, \".rds.log.txt\"))   rds_path <- gsub(\".log.txt\", \"\", logpath)   dir.create(path = dirname(logpath), showWarnings = FALSE)    # Run calibration in parallel   cat(paste0(Sys.time(), \": start sampling of \", paste0(\"out_calib_\", suffix_str, \".rds\")))   out_calib <- calib_sofun(     drivers   = driver_to_use_for_mcmc,     obs       = obs_to_use_for_mcmc,     settings_calib = calib_sofun_settings,     logpath   = logpath,     # other arguments for the cost function     par_fixed = res$par_fixed   )   ## Store result object to file: ----   ## This enables easy continuation of MCMC sampling   saveRDS(out_calib, file = rds_path, compress = \"xz\")   cat(paste0(Sys.time(), \": end   sampling of \", out_calib$name,     \". \\nWritten *.rds-output to: \", rds_path))    # return only performance results as tibble   timings <- tibble(     setup       = curr_calibration_scenario,     name        = gsub(\".rds.log.txt\", \"\", out_calib$name),     # sampling options:     sampler        = calib_sofun_settings$control$sampler_runMCMC,     burnin         = burnin,     iterations     = iterations,     n_chains       = n_chains_independent,     n_chains_inner = n_chains_within_sampler,     # performance results:     cores          = n_parallel_independent,     walltime       = out_calib$walltime # ,     # logfile        = out_calib$logpath   )   return(timings) } dir.create(\"vignettes/files/param_calib_multitarget/\", showWarnings = FALSE)  df_timings226 <- run_mcmc_rsofun(226, suffix_str = \"setup_226\",   outpath = \"vignettes/files/param_calib_multitarget/\",   # mcmc setup:   sampler = \"DREAMzs\",   iterations = 600,   burnin = 0,   n_chains_independent      = 8,   n_chains_within_sampler   = 3,   # parallelization   n_parallel_independent    = 1 ) # 2025-12-16 10:49:52.217434: start sampling of out_calib_setup_226.rds # runMCMC terminated after 4.39500000000407seconds00 . Current logp  -389.1087 -421.1468 -396.6275 Please wait! # runMCMC terminated after 3.95499999998719seconds00 . Current logp  -377.7371 -379.5134 -377.3347 Please wait! # ... # runMCMC terminated after 4.23500000000058seconds00 . Current logp  -397.9886 -379.6501 -382.6354 Please wait!  df_timings231 <- run_mcmc_rsofun(231, suffix_str = \"setup_231\",   outpath = \"vignettes/files/param_calib_multitarget/\",   # mcmc setup:   sampler = \"DREAMzs\",   iterations = 600,   burnin = 0,   n_chains_independent      = 8,   n_chains_within_sampler   = 3,   # parallelization   n_parallel_independent    = 1 ) # 2025-12-16 10:51:14.211219: start sampling of out_calib_setup_231.rds # Running DREAM-MCMC, chain  1 iteration 300 of 600 . Current logp  -14645.97 -14571.83 -15471.88 Please wait! # runMCMC terminated after 16.8090000000084seconds00 . Current logp  -14616.55 -14462.62 -14529.8 Please wait! # Running DREAM-MCMC, chain  2 iteration 300 of 600 . Current logp  -16760.01 -15828.73 -14948.44 Please wait! # runMCMC terminated after 16.4020000000019seconds00 . Current logp  -14955.26 -14941.47 -14441.98 Please wait! # ... # runMCMC terminated after 17.8410000000003seconds00 . Current logp  -15023.04 -14854.75 -14265.61 Please wait!  df_timings231p <- run_mcmc_rsofun(231, suffix_str = \"setup_231_parallel\",   outpath = \"vignettes/files/param_calib_multitarget/\",   # mcmc setup:   sampler = \"DREAMzs\",   iterations = 600,   burnin = 0,   n_chains_independent      = 8,   n_chains_within_sampler   = 3,   # parallelization   n_parallel_independent    = 8     # here now we parallelize the 8 chains to 8 cores ) # 2025-12-16 10:52:17.880666: start sampling of out_calib_setup_231_parallel.rds # Writing MCMC sampling log to: files/param_calib_multitarget//calibrations/out_calib_setup_231_parallel.rds.log.txt # ... # 2025-12-16 10:55:56.813577: end   sampling of out_calib_setup_231_parallel.rds.log.txt. # Written *.rds-output to: files/param_calib_multitarget//calibrations/out_calib_setup_231_parallel.rds # calib_timings <- bind_rows( #   df_timings226, #   df_timings231, #   df_timings231p) knitr::kable(calib_timings |>   dplyr::mutate(name = gsub(\".rds.log.txt\", \"\", name)) |>   dplyr::mutate(resultfile = gsub(\"vignettes/\", \"\", resultfile)) ) starting worker pid=43576 on localhost:11353 at 11:15:05.976 starting worker pid=43589 on localhost:11353 at 11:15:06.058 starting worker pid=43602 on localhost:11353 at 11:15:06.142 starting worker pid=43615 on localhost:11353 at 11:15:06.224 starting worker pid=43628 on localhost:11353 at 11:15:06.306 starting worker pid=43641 on localhost:11353 at 11:15:06.389 starting worker pid=43654 on localhost:11353 at 11:15:06.476 starting worker pid=43668 on localhost:11353 at 11:15:06.570 Loading required package: rsofun loaded rsofun and set parent environment ...  Running DREAM-MCMC, chain  1 iteration 300 of 600 . Current logp  -15821.4 ... Please wait!  Running DREAM-MCMC, chain  1 iteration 300 of 600 . Current logp  -15415.3 ... Please wait!  Running DREAM-MCMC, chain  1 iteration 300 of 600 . Current logp  -14739.4 ... Please wait! ...  Running DREAM-MCMC, chain  1 iteration 600 of 600 . Current logp  -14654.7 ... Please wait! runMCMC terminated after 36.634seconds  Running DREAM-MCMC, chain  1 iteration 600 of 600 . Current logp  -14927.0 ... Please wait! runMCMC terminated after 40.068seconds # This loads MCMC chains that might have been generated with a separate R script out_calib_226 <- readRDS(\"files/param_calib_multitarget/calibrations/out_calib_setup_226.rds\") out_calib_231p <- readRDS(\"files/param_calib_multitarget/calibrations/out_calib_setup_231_parallel.rds\") rsofun_symbol_parname_description <- dplyr::tribble(   ~variable,            ~label,                                                      ~Symbol_R,   \"kphio\",              \"italic(phi)[0]^'*'*' (mol mol-\\u00B9)'\",               \"italic(phi)[0]^'*'\",   \"kphio_par_a\",        \"italic(a)[italic(phi)]*' (\\u00B0C-\\u00B2)'\",           \"italic(a)[italic(phi)]\",   \"kphio_par_b\",        \"italic(b)[italic(phi)]*' (\\u00B0C)'\",                       \"italic(b)[italic(phi)]\",   \"soilm_thetastar\",    \"italic(theta)^'*'*' ('*'mm'*')'\",                           \"italic(theta)^'*'\",   \"soilm_betao\",        \"italic(beta)[0]*' (-)'\",                                    \"italic(beta)[0]\",   \"beta_unitcostratio\", \"italic(beta)*' (-)'\",                                       \"italic(beta)\",   \"rd_to_vcmax\",        \"italic(b)[0]*' (-)'\",                                       \"italic(b)[0]\",   \"tau_acclim\",         \"italic(tau)*' (days)'\",                                     \"italic(tau)\",   \"kc_jmax\",            \"italic(c)^'*'*' (-)'\",                                      \"italic(c)^'*'\",   \"err_gpp\",            \"italic(sigma)['GPP']*' (gC m -\\u00B2 s-\\u00B9)'\", \"italic(sigma)['GPP']\",   \"err_bigD13C\",        \"italic(sigma)[Delta]*' ('*'\\u2030'*')'\",                    \"italic(sigma)[Delta]\" ) label_vec_short <- setNames(rsofun_symbol_parname_description$Symbol_R, rsofun_symbol_parname_description$variable) custom_labeller_variable <- function(labels, multi_line = TRUE) { # adapted from label_parsed   replaced_labels <- left_join(     select(labels, variable), # NOTE: this has variable hardcoded     select(rsofun_symbol_parname_description, variable, label),     by = join_by(variable))   # print(tibble(replaced_labels))   replaced_labels <- replaced_labels |> select(-variable)   replaced_labels <- label_value(replaced_labels, multi_line = multi_line)   # print(replaced_labels)   lapply(unname(replaced_labels), lapply, function(values) {     c(parse(text = as.character(values)))   }) } # Define plotting function plot_mcmc_trace <- function(out_calib, nr_internal_chains, burnin_to_skip, burnin_to_skip_gelman = burnin_to_skip, dont_thin = FALSE, end = NULL) {   x <- out_calib$mod   title <- basename(out_calib$name)    curr_iter <- x[[1]]$settings$iterations   if (dont_thin || curr_iter < 10000) {     curr_thin <- 1   } else {     curr_thin <- floor(curr_iter / 10000)   }    xsample <- BayesianTools::getSample(x, coda = T, thin = curr_thin, start = burnin_to_skip, end = end)    # nr_internal_chains will have same color   dat_to_plot <- lapply(xsample, function(single_chain) {     as_tibble(single_chain) |> mutate(iteration = burnin_to_skip + curr_thin * (1:n()))   }) |>     dplyr::bind_rows(.id = \"chain_id\") |>     tidyr::pivot_longer(-c(iteration, chain_id), names_to = \"variable\") |>     # mark inner and outer chains (assumes DEzs or DREAMzs):     mutate(outerChain = as.factor(ceiling(as.numeric(chain_id) / 3)),       innerChain = (as.numeric(chain_id) + 2) %% 3 + 1,       innerChain_str = letters[innerChain],       chain_id_str = paste0(outerChain, letters[innerChain])) #|>   # fix order: in order of appearance   # mutate(variable = forcats::as_factor(variable))    pl <- ggplot(dat_to_plot,     aes(x = iteration, y = value, color = outerChain, linetype = innerChain_str)) + geom_line() +     # geom_rug(sides = \"r\") +     theme_classic() +     # scale_x_continuous(labels = scales::label_number(scale_cut = scales::cut_short_scale())) +     facet_wrap(~variable,  nrow = 2, scales = \"free_y\", labeller = custom_labeller_variable) +     theme(       legend.position = \"bottom\", strip.text = element_text(size = 12)     ) +     labs(y = \"\", color = \"chain\", linetype = \"internal\\nchains\")    # add Gelman Diagnostics   get_gelman_diag <- function(mcmc, burnin_to_skip, end) {     gelman_df <- BayesianTools::gelmanDiagnostics(mcmc, start = burnin_to_skip, end = end)     psrf_values <- gelman_df$psrf[, \"Point est.\"]     # psrf_strings <- paste0(substr(names(psrf_values),1,5), \"..=\", sprintf(\"%.2f\", psrf_values))     psrf_strings <- paste0(\"'*\", unname(label_vec_short[names(psrf_values)]), \"*'=\", sprintf(\"%.2f\", psrf_values))     psrf_string <- paste0(psrf_strings, collapse = \", \")      subtitle <- sprintf(\"'GelmanDiagnostics: mpsrf=%.1f; psrf:%s'\",       gelman_df$mpsrf,       psrf_string)   }   subtitle <- tryCatch(get_gelman_diag(x, burnin_to_skip_gelman + 1, end = end), error = function(e) {     e   }) # unsure why min burnin of 1 is needed   pl <- pl + ggtitle(title, subtitle = parse(text = subtitle))    pl <- pl + geom_vline(xintercept = burnin_to_skip_gelman, color = \"red\", linetype = \"dashed\")    return(pl) } plot_mcmc_trace(out_calib_226, nr_internal_chains = 3, burnin_to_skip = 0, burnin_to_skip_gelman = 150) plot_mcmc_trace(out_calib_231p, nr_internal_chains = 3, burnin_to_skip = 0, burnin_to_skip_gelman = 150) plot_prior_posterior_density <- function(x, burnin_to_skip) {   require(BayesianTools)   require(dplyr)   require(tidyr)   require(ggplot2)    # Get matrices of prior and posterior samples   posteriorMat <- BayesianTools::getSample(x, parametersOnly = TRUE, start = burnin_to_skip)   priorMat <-  BayesianTools:::getSetup(x)$prior$sampler(10000) # nPriorDraws = 10000    # Parameter names   parNames <- colnames(posteriorMat)   # rename columns priorMat   colnames(priorMat) <- parNames    # Create data frame for plotting   df_plot <- rbind(     data.frame(priorMat,     par_estimation = \"prior\"),     data.frame(posteriorMat, par_estimation = \"posterior\")   ) |>     # dplyr::mutate(par_estimation = forcats::fct_inorder(par_estimation)) |> # order by appearance     tibble()   levels(df_plot$par_estimation)   # Plot with facet wrap   gg <- df_plot |>     tidyr::pivot_longer(-c(par_estimation), names_to = \"variable\") |>     # dplyr::mutate(variable = forcats::fct_inorder(variable)) |> # order by appearance     ggplot(       aes(x = value, fill = par_estimation)     ) +     geom_density(alpha = 0.8) +     theme_classic() +     facet_wrap(~variable,  nrow = 2, scales = \"free\", labeller = custom_labeller_variable) +     # facet_wrap( ~ variable , nrow = 2, scales = \"free\") +     theme(       legend.position = \"bottom\",       axis.title.x = element_text(\"\"),       axis.ticks.y = element_blank(),       axis.text.y = element_blank(),     ) +     scale_fill_manual(NULL, values = c(\"posterior\" = \"#29a274ff\",       \"prior\" = \"#777055ff\")) # GECO colors    return(gg) } library(cowplot) p1 <- plot_prior_posterior_density(out_calib_226$mod,  burnin_to_skip = 200) +  ggtitle(out_calib_226$name) #> Loading required package: BayesianTools #> Loading required package: tidyr p2 <- plot_prior_posterior_density(out_calib_231p$mod, burnin_to_skip = 20) +  ggtitle(out_calib_231p$name) cowplot::plot_grid(p1, p2, ncol = 1) BayesianTools::correlationPlot(out_calib_231p$mod) # Samples posterior parameters (MAP or N=n_samples) and runs # model predictions # # This allows to do two things: # A) make predictions at sites/dates/... where we have observations # B) make predictions also  on dates/... where we have no observations, e.g. for continuous time series # we do B) once {by setting `return_continuous_timeseries = TRUE`} and then derive A) from it. run_prediction_rsofun <- function(     mcmc_posterior,     prediction = c(\"both\", \"test\", \"train\"),     burnin_to_skip = 0,     n_samples = 100,      # if n_samples == 1, use MAP     n_cores = NULL) {    if (length(prediction) == 1 && (prediction %in% c(\"both\", \"test\", \"train\"))) {     # as expected   } else {     stop(\"Provide prediction as either: 'both', 'test' or 'train'\")   }   n_cores <- ifelse(is.null(n_cores), 1, n_cores)   stopifnot(is(mcmc_posterior$mod, \"mcmcSamplerList\"))    curr_calibration_scenario <- as.integer(gsub(     \".*_setup_([0-9]*)_.*\",  # NOTE: hardcoded expected format of filename     \"\\\\1\",     mcmc_posterior$name))   stopifnot(!is.na(curr_calibration_scenario)) # Catches if expected format is inaccurate    # Setup simulation model   res <- setup_rsofun_calibration(scenario = curr_calibration_scenario)    # Set random seed for reproducibility   set.seed(2023)    # Sample parameters from MCMC posterior   # Evaluation of the uncertainty coming from the model parameters' uncertainty   if (n_samples > 1) {     samples_par <- getSample(       mcmc_posterior$mod,       thin = 1,       start = burnin_to_skip, numSamples = n_samples     ) |>       as.data.frame() |>       # Add sample IDs       dplyr::mutate(posterior_sample_id = 1:n()) |>       tidyr::nest(.by = posterior_sample_id, .key = \"pars\")   } else {     # mcmc_posterior$par # these are already precomputed...     # but more robust to recompute:     samples_par <- BayesianTools::MAP(mcmc_posterior$mod)$parametersMAP |>       as.list() |> as_tibble() |>       # Add sample IDs       dplyr::mutate(posterior_sample_id = 0L) |> # posterior_sample_id == 0 means MAP       tidyr::nest(.by = posterior_sample_id, .key = \"pars\")   }    # Setup prediction   predict_sofun_settings <- list(n_cores = n_cores)    if (prediction == \"both\") {     curr_driver <- bind_rows(res$drivobs_train, res$drivobs_test) |>       select(sitename, params_siml, site_info, forcing)     curr_obs    <- bind_rows(res$drivobs_train, res$drivobs_test) |>       select(sitename, targets, data)   } else if (prediction == \"train\") {     curr_driver <- select(res$drivobs_train, sitename, params_siml, site_info, forcing)     curr_obs    <- select(res$drivobs_train, sitename, targets, data)   } else if (prediction == \"test\") {     curr_driver <- select(res$drivobs_test, sitename, params_siml, site_info, forcing)     curr_obs    <- select(res$drivobs_test, sitename, targets, data)     stopifnot(nrow(curr_obs) > 0)   }    # Run prediction   df_pred_vs_obs <- predict_sofun_parallelized(     drivers     = curr_driver,     obs         = curr_obs,     settings    = predict_sofun_settings,     par         = samples_par,     par_fixed   = res$par_fixed   )    return(df_pred_vs_obs) }  # Runs the requested model predictions and returns results # Requested model predictions are defined by data.frame `par_df` containing # model parameter sets predict_sofun_parallelized <- function(     drivers,     obs,     settings,     par_fixed,     par_df = NULL) {   # Set number of cores if not specified   if (is.null(settings$n_cores)) {     settings$n_cores <- min(detectCores() - 1, 20) # at most 20   }   # ensure not more than needed   settings$n_cores <- min(nrow(par_df), settings$n_cores)    # Function to run prediction for a single parameter set   run_pmodel_single_prediction <- function(par, par_fixed, drivers, obs) {     # Function that runs the P-model for a sample of parameters     # but does not add the observation error      # Taken from cost_likelihood_pmodel()     stopifnot(nrow(obs) > 0)     # ensure some observation data are provided     stopifnot(nrow(drivers) > 0) # ensure some driver data are provided      # A) Include current parameters ----     stopifnot(length(intersect(names(par), names(par_fixed))) == 0) # no overlap     params_modl <- c(par, par_fixed)      # B,C) Run model and bring together with observed ----     df_pred_vs_obs <- rsofun:::get_mod_obs_pmodel(       drivers,       obs,       params_modl,       parallel = FALSE,       ncores = 1,       return_continuous_timeseries = TRUE)      # D) (DON'T) Sample error model ----     # NOTE: sampling is not done here, but can optionally be done before plotting     #       Here we rename to clarify that no error model has yet been applied.     df_pred_vs_obs <- df_pred_vs_obs |>       # clarify name of model output (containing not yet any error model term)       rename(mod_no_err = mod) |>       relocate(c(mod_no_err, err_par_sd), .after = last_col())      return(df_pred_vs_obs)   }    # Run the P-model predictions for each set of parameters   ## Prepare parallelization:   parallel_flag <- (settings$n_cores > 1 && nrow(par_df) > 1)   # setup helpers for conditional parallelization   do_if <- function(df, cond, f) { # enable conditional lines in dplyr piping     if (cond) f(df) else df   }   cl <- if (parallel_flag) {     multidplyr::new_cluster(settings$n_cores) |>       multidplyr::cluster_library(         packages = c(\"dplyr\", \"tidyr\", \"purrr\", \"rsofun\")       )   }   ## Run predictions:   df_model_predictions <- par_df |>     do_if(parallel_flag, function(df) multidplyr::partition(df, cl)) %>%     dplyr::mutate(\"sim\" = purrr::map(       pars,       ~ run_pmodel_single_prediction(         par = .x,         par_fixed,         drivers,         obs       )     )) |>     do_if(parallel_flag, function(df) dplyr::collect(df))    return(df_model_predictions) }  apply_bias_correction_and_sample_error <- function(df_pred, N_sample_error) {   set.seed(1982)   df_pred |>     # lazy_dt() |>   # if needed, uses lazy data.table and dtplyr for speed     # a) repeat lines: once for each sampled error     # following line is basically a cross_join: with     slice(rep(1:n(), each = N_sample_error)) |>     mutate(error_sample_id = as.integer(rep(1:N_sample_error, n() / N_sample_error))) |>     arrange(posterior_sample_id) |>     # b) sample the error:     group_by(err_par_sd, err_par_bias) |>     mutate(err_sample                = rnorm(n(),   sd = err_par_sd),       mod_biasremoved_no_err    = mod_no_err - err_par_bias,       mod_biasremoved_with_err  = mod_no_err - err_par_bias + err_sample) |>     ungroup() |>     as_tibble() |> # to access results of lazy dtplyr-computation as normal tibble()     # keep output light: i.e. remove unneded columns:     select(-err_sample) |>     mutate(across(where(is.character), as.factor)) } # get MAP and run model for MAP parameter set df_predict_MAP_train_231p <- run_prediction_rsofun(   mcmc_posterior = out_calib_231p,   prediction     = \"train\",   burnin_to_skip = 200,   n_samples      = 1, # n_samples == 1, requests MAP   n_cores        = 1) # this could be increased e.g. to 4  # get parameter samples and run model for thes parameter sets df_predict_train_231p <- run_prediction_rsofun(   mcmc_posterior = out_calib_231p,   prediction     = \"train\",   burnin_to_skip = 200,   n_samples      = 20,   n_cores        = 1) # this could be increased e.g. to 4  df_predict <- bind_rows(   # df_predict_test      |> mutate(is_train0_test1 = 1L, is_MAP = FALSE),   df_predict_train_231p     |> mutate(is_train0_test1 = 0L, is_MAP = FALSE),   # df_predict_MAP_test  |> mutate(is_train0_test1 = 1L, is_MAP = TRUE),   df_predict_MAP_train_231p |> mutate(is_train0_test1 = 0L, is_MAP = TRUE) )  # Free memory: # rm(df_predict_train_231p, #    df_predict_MAP_train_231p)  # df_predict_params<- df_predict |> select(posterior_sample_id, is_train0_test1, is_MAP, pars) |> unnest(pars) df_predict_gpp     <- df_predict |> select(posterior_sample_id, is_train0_test1, is_MAP, sim)  |> unnest(sim) |> filter(target == \"gpp\")     |> unnest(obs_metadata) df_predict_bigD13C <- df_predict |> select(posterior_sample_id, is_train0_test1, is_MAP, sim)  |> unnest(sim) |> filter(target == \"bigD13C\") |> unnest(obs_metadata)  # apply bias-correction and simulate structural error N_sample_error <- 3 df_predict_231p_gpp_sampled <- apply_bias_correction_and_sample_error(   df_predict_gpp,   N_sample_error = N_sample_error) df_predict_231p_bigD13C_sampled <- apply_bias_correction_and_sample_error(   df_predict_bigD13C,   N_sample_error = N_sample_error) # Save predictions to plot with separate script: # FOR STORAGE REASONS unnest the obs_metadata and save different targets separately: # out_prediction_template <- file.path(\"files/param_calib_multitarget/\", #                                       \"predictions\", \"pred_231p_XXX.rds\") # dir.create(dirname(out_prediction_template), showWarnings = FALSE) # fname_out_gpp     <- gsub(\"_XXX\", #                           paste0(    \"_gpp_sampled_N\", N_sample_error, \"errors\"), #                           out_prediction_template) # fname_out_bigD13C <- gsub(\"_XXX\", #                           paste0(\"_bigD13C_sampled_N\", N_sample_error, \"errors\"), #                           out_prediction_template) # df_predict_231p_gpp_sampled     |> #   select(posterior_sample_id,error_sample_id,is_train0_test1,is_MAP,sitename,target,obs,   date,err_par_bias,err_par_sd,mod_no_err,mod_biasremoved_no_err,mod_biasremoved_with_err) |> #   saveRDS(fname_out_gpp,     compress = \"xz\") # df_predict_231p_bigD13C_sampled |> #   select(posterior_sample_id,error_sample_id,is_train0_test1,is_MAP,sitename,target,obs,id,     err_par_bias,err_par_sd,mod_no_err,mod_biasremoved_no_err,mod_biasremoved_with_err) |> #   saveRDS(fname_out_bigD13C, compress = \"xz\")  # Load predictions for plotting with separate script: # df_predict_231p_gpp_sampled     <- readRDS(\"files/param_calib_multitarget//predictions/pred_231p_gpp_sampled_N3errors.rds\") # df_predict_231p_bigD13C_sampled <- readRDS(\"files/param_calib_multitarget//predictions/pred_231p_bigD13C_sampled_N3errors.rds\") # df_predict_231p_bigD13C_sampled <- readr::read_rds(paste0(\"/storage/scratch/giub_geco/fbernhard/rsofun_doc_outputs/data/predictions/out_predict_\",n_post,\"_30000burnin__out_calib__scen222_DREAMzs-100000-0iter_8x3chains_on_CPU8x1_continued.rds_vj_sampled\",n_err,\".rds\")) # df_predict_231p_gpp_sampled     <- readr::read_rds(paste0(\"/storage/scratch/giub_geco/fbernhard/rsofun_doc_outputs/data/predictions/out_predict_\",n_post,\"_30000burnin__out_calib__scen222_DREAMzs-100000-0iter_8x3chains_on_CPU8x1_continued.rds_gpp_sampled\",n_err,\".rds\")) # add transparency to colors t_col <- function(color, percent = 50, name = NULL) {   #      color = color name   #    percent = % transparency   #       name = an optional name for the color   rgb.val <- col2rgb(color) # Get RGB values for named color   ## Make new color using input color as base and alpha set by transparency   t.col <- rgb(     rgb.val[1], rgb.val[2], rgb.val[3],     max = 255,     alpha = (100 - percent) * 255 / 100,     names = name)   invisible(t.col) ## Save the color }  ## copied from sofunCalVal package (and adapted to analyse_modobs3) analyse_modobs3 <- function(df,                             mod,                             obs,                             type = \"points\",                             filnam = NA,                             relative = FALSE,                             lower_xlim = 0,                             use_factor = NULL,                             shortsubtitle = FALSE,                             plot_subtitle = TRUE,                             plot_linmod = TRUE,                             pal = \"batlowW\",                             ...) {   require(ggplot2)   require(dplyr)    # if (identical(filnam, NA)) filnam <- \"analyse_modobs.pdf\"    ## rename to 'mod' and 'obs' and remove rows with NA in mod or obs   df <- df %>%     as_tibble() %>%     ungroup() %>%     dplyr::select(dplyr::all_of(c(mod = mod, obs = obs))) %>%     tidyr::drop_na(mod, obs)    ## get linear regression (coefficients)   linmod <- lm(obs ~ mod, data = df)    ## construct metrics table using the 'yardstick' library   df_metrics <- df %>%     yardstick::metrics(obs, mod) %>%     dplyr::bind_rows(tibble(.metric = \"n\", .estimator = \"standard\", .estimate = summarise(df, numb = n()) %>% unlist())) %>%     dplyr::bind_rows(tibble(.metric = \"slope\", .estimator = \"standard\", .estimate = coef(linmod)[2])) %>%     # dplyr::bind_rows( tibble( .metric = \"nse\",      .estimator = \"standard\", .estimate = hydroGOF::NSE( obs, mod, na.rm=TRUE ) ) ) %>%     dplyr::bind_rows(tibble(.metric = \"mean_obs\", .estimator = \"standard\", .estimate = summarise(df, mean = mean(obs, na.rm = TRUE)) %>% unlist())) %>%     dplyr::bind_rows(tibble(       .metric = \"prmse\", .estimator = \"standard\",       .estimate = dplyr::filter(., .metric == \"rmse\") %>% dplyr::select(.estimate) %>% unlist() /         dplyr::filter(., .metric == \"mean_obs\") %>%           dplyr::select(.estimate) %>%           unlist()     )) %>%     dplyr::bind_rows(tibble(       .metric = \"pmae\", .estimator = \"standard\",       .estimate = dplyr::filter(., .metric == \"mae\") %>% dplyr::select(.estimate) %>% unlist() /         dplyr::filter(., .metric == \"mean_obs\") %>%           dplyr::select(.estimate) %>%           unlist()     )) %>%     dplyr::bind_rows(tibble(.metric = \"bias\", .estimator = \"standard\", .estimate = dplyr::summarise(df, mean((mod - obs), na.rm = TRUE)) %>% unlist())) %>%     dplyr::bind_rows(tibble(.metric = \"pbias\", .estimator = \"standard\", .estimate = dplyr::summarise(df, mean((mod - obs) / obs, na.rm = TRUE)) %>% unlist()))    rsq_val <- df_metrics %>%     dplyr::filter(.metric == \"rsq\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   rmse_val <- df_metrics %>%     dplyr::filter(.metric == \"rmse\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   mae_val <- df_metrics %>%     dplyr::filter(.metric == \"mae\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   bias_val <- df_metrics %>%     dplyr::filter(.metric == \"bias\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   slope_val <- df_metrics %>%     dplyr::filter(.metric == \"slope\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   n_val <- df_metrics %>%     dplyr::filter(.metric == \"n\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()    if (relative) {     rmse_val <- rmse_val / mean(df$obs, na.rm = TRUE)     bias_val <- bias_val / mean(df$obs, na.rm = TRUE)   }    rsq_lab <- format(rsq_val, digits = 2)   rmse_lab <- format(rmse_val, digits = 3)   mae_lab <- format(mae_val, digits = 3)   bias_lab <- format(bias_val, digits = 3)   slope_lab <- format(slope_val, digits = 3)   n_lab <- format(n_val, digits = 3)    results <- tibble(rsq = rsq_val, rmse = rmse_val, mae = mae_val, bias = bias_val, slope = slope_val, n = n_val)    if (shortsubtitle) {     subtitle <- bquote(italic(R)^2 == .(rsq_lab) ~ ~       RMSE == .(rmse_lab))   } else {     subtitle <- bquote(italic(R)^2 == .(rsq_lab) ~ ~       RMSE == .(rmse_lab) ~ ~       bias == .(bias_lab) ~ ~       slope == .(slope_lab) ~ ~       italic(N) == .(n_lab))   }    if (type == \"hex\") {      upper_xlim <- round(max(quantile(df$mod, 0.9999), quantile(df$obs, 0.9999)))     stopifnot(is.null(lower_xlim) || (is.numeric(lower_xlim) && length(lower_xlim) == 1))     lower_xlim <- ifelse(is.null(lower_xlim),       round(min(quantile(df$mod, 0.0001), quantile(df$obs, 0.0001))),       lower_xlim)      ## ggplot hexbin     gg <- df %>%       ggplot2::ggplot(aes(x = mod, y = obs)) +       geom_hex(bins = 50, show.legend = FALSE) +       geom_abline(intercept = 0, slope = 1, linetype = \"dotted\") +       # geom_hline(yintercept = 0, linetype = \"dotted\") +       # geom_vline(xintercept = 0, linetype = \"dotted\") +       coord_fixed() +       xlim(lower_xlim, upper_xlim) +       ylim(lower_xlim, upper_xlim) +       theme_classic() +       labs(x = mod, y = obs)      if (pal == \"batlowW\") {       gg <- gg + khroma::scale_fill_batlowW(trans = \"log\", reverse = TRUE)     } else if (pal == \"davos\") {       gg <- gg + khroma::scale_fill_davos(trans = \"log\", reverse = TRUE)     }      if (plot_subtitle) gg <- gg + labs(subtitle = subtitle)     if (plot_linmod) gg <- gg + geom_smooth(method = \"lm\", color = \"red\", linewidth = 0.5, se = FALSE)      if (!identical(filnam, NA)) {       ggsave(filnam, width = 5, height = 5)     }   }    return(list(df_metrics = df_metrics, gg = gg, linmod = linmod, results = results)) }  plot_predobs_gpp_timeseries3 <- function(ts_to_plot) {   # separate obs   df_tsplot_gpp_obs <- ts_to_plot |>     select(sitename, target, date, obs, Scenario, dataset) |>     distinct()    # compute stats of sampled distributions before plotting them   tibble_to_plot <- ts_to_plot |>     filter(target == \"gpp\") |>     # dtplyr::lazy_dt() |> # THIS WAS NEEDED FOR THE FULL DATA.FRAME     group_by(Scenario, dataset, parameters, sitename, target, date, model_output_type, y_facet) |>     summarise( # mod_no_err_p50 = quantile(mod_no_err, 0.5),       modelled_p50 = quantile(modelled, 0.5),       modelled_p95 = quantile(modelled, 0.95),       modelled_p05 = quantile(modelled, 0.05)     ) |>     as_tibble() |>     # and bind back obsevations     left_join(       df_tsplot_gpp_obs,       by = join_by(sitename, target, date, Scenario, dataset))    n_sites <- tibble_to_plot$sitename |> unique() |> length()    pl_timeseries_gpp <- ggplot(     data = tibble_to_plot,     mapping = aes(x = date, y = modelled_p50)) +     # Observations underneath (following Cameron 2022)     geom_point(       data = function(df) df |> select(-parameters, -model_output_type, -y_facet, -starts_with(\"modelled\")) |> distinct(),       # data = df_tsplot_gpp_obs, # variant 1, but does not allow %+%-replacement of underlying data       mapping = aes(y = obs), color = \"black\", shape = 4, alpha = 0.5, size = 0.5) +     # Structural uncertainty (including error model), a.k.a prediction band     geom_ribbon(       alpha = 0.5,       data = function(df) df |> filter(model_output_type == \"with struct. uncert.\"),       mapping = aes(ymin = modelled_p05, ymax = modelled_p95, fill = \"Post.+Error\")) +     # Parametric uncertainty (without error model, only parameter sampling), a.k.a confidence band     geom_ribbon(       alpha = 0.5,       data = function(df) df |> filter(model_output_type == \"rsofun\"),       mapping = aes(ymin = modelled_p05, ymax = modelled_p95, fill = \"Posterior\")) +     geom_line(       data = function(df) df |> filter(model_output_type == \"rsofun\"),       mapping = aes(y = modelled_p50, color = \"Posterior\")) +     # layout     facet_wrap(~sitename, scales = \"free_x\") +     theme_classic() + theme(legend.position = \"bottom\") +     labs(       x = NULL, #' Date',       y = expression(paste(\"GPP (g C m\"^-2, \"s\"^-1, \")\"))     ) +     scale_fill_manual(NULL, aesthetics = c(\"colour\", \"fill\"),       breaks = c(\"Post.+Error\",         \"Posterior\"),       values = c(\"Posterior\"   = t_col(\"#29a274ff\"),         \"Post.+Error\" = t_col(\"#777055ff\"))     ) +     scale_x_date(date_breaks = \"12 months\", date_labels = \"%Y-%m\") } # Time series of GPP (Figure C5) dflong_gpp_train <- df_predict_231p_gpp_sampled |>   mutate(Scenario = \"231\") |>   # select only training sites   filter(is_train0_test1 == 0) |>   select(posterior_sample_id, error_sample_id, Scenario, is_train0_test1, is_MAP, sitename, target,     obs,                 date, # these are target specific observation_metadata     mod_no_err, mod_biasremoved_no_err, mod_biasremoved_with_err) |>   # pivot the model_output_types to long   tidyr::pivot_longer(c(mod_no_err, mod_biasremoved_no_err, mod_biasremoved_with_err),     names_to = \"model_output_type\", values_to = \"modelled\") |>   mutate(model_output_type = factor(     model_output_type,     levels = c(\"mod_no_err\", \"mod_biasremoved_no_err\", \"mod_biasremoved_with_err\"),     labels = c(\"rsofun\",    \"bias-corrected\",        \"with struct. uncert.\"))) |>   # derive column `parameters` (\"MAP\" or \"Posterior\") from `is_MAP`   mutate(is_MAP = factor(ifelse(is_MAP, \"MAP\", \"Posterior\"))) |>   rename(parameters = is_MAP) |>   # derive column `dataset` (\"train\" or \"test\") from column `is_train0_test1`   mutate(is_train0_test1 = factor(ifelse(is_train0_test1 == 1, \"test\", \"train\"))) |>   rename(dataset = is_train0_test1)  df_B3_timeseries <- dflong_gpp_train |>   # remove the bias-corrected values for gpp since we did not fit a bias   filter(!(model_output_type %in% c(\"bias-corrected\"))) |>   # select what to plot and how to name it   mutate(y_facet = case_when(     Scenario == \"231\" & model_output_type == \"rsofun\" &               parameters == \"MAP\"       ~ \"MAP\",     Scenario == \"231\" & model_output_type == \"rsofun\" &               parameters == \"Posterior\" ~ \"Posterior\",     Scenario == \"231\" & model_output_type == \"with struct. uncert.\" & parameters == \"Posterior\" ~ \"Post.+Error\",     # all else is not plotted     TRUE ~ \"remove\") |> factor(levels = c(\"MAP\", \"Posterior\", \"Post.+Error\"))) |>   filter(y_facet != \"remove\")  # Plot raw predictions pl_timeseries_gpp <- plot_predobs_gpp_timeseries3(df_B3_timeseries) pl_timeseries_gpp # fake output since prediction was run previous to vignette rendering knitr::include_graphics(\"files/param_calib_multitarget/predictions/pl_timeseries_gpp.png\",   dpi = 100) gpp_labs <- function(xNULL = FALSE) {   list(labs(x = ifelse(xNULL, \" \", \"Predicted GPP (g C m-\\u00B2 s-\\u00B9)\"),     y = \"Observed GPP (g C m-\\u00B2 s-\\u00B9)\")) } bigD13C_labs <- function(xNULL = FALSE) {   list(labs(x = ifelse(xNULL, \" \", \"Predicted Δ (\\u2030)\"),     y = \"Observed Δ (\\u2030)\")) }  # compute scatters (and skills) for MAP of test set: list_of_scenarios_to_loop_over <- list(   s231 = list(\"bigD13C\" = df_predict_231p_bigD13C_sampled,  \"gpp\" = df_predict_231p_gpp_sampled) )  parameter_set <- \"MAP\" list_of_scatters <- lapply(list_of_scenarios_to_loop_over, function(list_of_targets) {   lapply(list_of_targets, function(df_target_prediction) {     curr_target <- first(df_target_prediction$target)      # (MAP, Posterior, Posterior+Error)     # MAP:             is posterior_sample_id==0     #                  e.g. filter(df_gpp, is_train0_test1 == 1,     is_MAP, error_sample_id==1)     # Posterior:       just take one error sampling, but all (~25 posterior samples)     #                  e.g. filter(df_gpp, is_train0_test1 == 1,             error_sample_id==1),     # Posterior+Error: take all errors     #                  e.g. filter(df_gpp, is_train0_test1 == 1,             error_sample_id>=1)     df <- df_target_prediction %>%       {         if (parameter_set == \"MAP\") filter(., is_MAP) else .       } %>% filter(error_sample_id == 1) # , is_train0_test1 == 1 # TODO: why was this removed?     mod <- \"mod_biasremoved_no_err\"     lower_xlim <- ifelse(curr_target == \"gpp\", list(0), list(NULL))[[1]]      if (nrow(df) == 0) {       return(list(gg = ggplot() + theme_void()))     } else {       return(analyse_modobs3(df, mod = mod, obs = \"obs\", type = \"hex\"))     }   }) })  ### single comparison plot: ---- mark_as_target <- theme(panel.background = element_rect(fill = t_col(\"darkgreen\", 80))) pl_scatter_comparison <- cowplot::plot_grid(   list_of_scatters$s231$bigD13C$gg + mark_as_target + bigD13C_labs(),   list_of_scatters$s231$gpp$gg     + mark_as_target + gpp_labs() ) pl_scatter_comparison # fake output since prediction was run previous to vignette rendering knitr::include_graphics(\"files/param_calib_multitarget/predictions/pl_scatter_comparison.png\",   dpi = 150)"},{"path":"https://fabern.github.io/rsofun/dev/articles/param_calib_multitarget.html","id":"some-helper-functions-for-calibration","dir":"Articles","previous_headings":"","what":"Some helper functions for calibration","title":"Parameter calibration (P-Model) to multiple targets (GPP, bigD13C) QUARTO","text":"define helper functions facilitate model calibration different target variables, resulting thus different calibration setups. helper functions simplify use parallel execution avoid code repetition. , showcase two different setups. first setup uses D13C target variable (corresponds Setup S1 documentation paper). second setup uses D13C GPP calibration targets (truncated) normal priors parameters (Setup S6). code, define first two different calibration setups specifying function setup_rsofun_calibration(), returns object necessary specifications. specifications can differ selection calibration parameters priors, data used potentially test-train split. , setups uniquely identified numeric identifer. code defines setup_rsofun_calibration() setups 226 231. also define function run Markov Chain Monte Carlo (MCMC) sampling run_mcmc_rsofun(). function reads unique setup identifier uses function setup_rsofun_calibration() get necessary definitions. code can easily parallelized multiple jobs. additionally showcase parallelize multiple chains different cores (n_parallel_independent = 8) thus significantly speed long-running calibration tasks. long-running calibrations can also useful able continue existing sampling chain continue_mcmc_rsofun(). shown vignette, code available Zenodo (10.5281/zenodo.17204361).","code":"# TODO reactivate: set eval to TRUE #| code-fold: true  #    226: Setup c)      Delta^'13 C*',VJ #    231: Setup h)      Delta^'13 C*',VJ, GPP  setup_rsofun_calibration <- function(scenario) {   ## Load forcing and targets data from disk (here now from package) ----   bigD13C_vj_gpp_drivers <- rsofun::pmodel_drivers   bigD13C_vj_gpp_obs     <- rsofun::pmodel_validation    # ## Read test-train split from disk ----   # read_csv(here::here(\"data/01_test_train_split.csv\"))   # Not needed here for vignette    ## Preprocess observation data (gpp) ----   ## # no additinal QC needed    ## Apply test-train split to data ----   train_drivers <- bigD13C_vj_gpp_drivers   train_obs     <- bigD13C_vj_gpp_obs    test_drivers <- bigD13C_vj_gpp_drivers |> slice(0)   test_obs     <- bigD13C_vj_gpp_obs     |> slice(0)    ## Setup the settings for the different calibration scenarios ----   ## Define default parameter   default_par_fixed <- list( # fix parameter value from previous calibration     kphio              = 0.04998,    # value from Stocker et al. 2020     kphio_par_a        = 0.0,        # 0 corresponds to no temperature dependency of kphio (ORG setup in Stocker et al. 2020)     kphio_par_b        = 1.0,        #     soilm_thetastar    = 0.6 * 240,  # to recover paper setup with soil moisture stress     soilm_betao        = 0.01,       # 1 corresponds to no reduction, 0 to full reduction at theta==0     beta_unitcostratio = 146.0,      # value from Stocker et al. 2020     rd_to_vcmax        = 0.014,      # value from Atkin et al. 2015 for C3 herbaceous     tau_acclim         = 14.0,       # value from Liu et al. 2024     kc_jmax            = 0.41        # value from Stocker et al. 2024 (citing Wang et al. 2017)   )    ## Define parameters to estimate and their priors   if (scenario %in% c(223, 226, 231)) { # 231 is like 223 but using posteriors from 226     par_to_estimate <- list(       kphio           = list(lower = 0.02, upper = 0.15, init = 0.05),       kphio_par_a     = list(lower = -0.004, upper = -0.001, init = -0.0025),       kphio_par_b     = list(lower = 10, upper = 30, init = 20),       soilm_thetastar = list(lower = 1, upper = 250, init = 40),       beta_unitcostratio = as.list(c(lower = 0.1, upper = 3.0, init = 1.0) * 146.0),       # truncated normal, with ~14 days as mean, taken from Liu et al.       # 2024, Nat.Plants and Mäkelä et al. 2004, Tree Phys.       tau_acclim      = list(mean = 14, sd = 8, lower = 0.01, upper = 40),       kc_jmax         = as.list(0.41 * c(lower = 0.1, upper = 3.0, init = 1.0)),       err_gpp         = list(lower = 0.01, upper = 3, init = 0.8),       err_bigD13C     = list(lower = 0.01, upper = 3, init = 0.8)     )     if (scenario %in% c(223, 226, 231)) {       par_to_estimate$err_bigD13C     <- list(lower = 0.01, upper = 15, init = 0.8)     }   } else {     stop(sprintf(\"Unsupported scenario: %d\", scenario))   }    if (scenario %in% c(231)) {   # 231 is like 223 but using posteriors from 226     # for beta_unitcostratio and kc_jmax as priors     # Below was done iteratively     # calib_scen226 <- readr::read_rds(file.path(rsofun_doc_output_path, \"data\",\"calibrations\",\"out_calib__scen226_DREAMzs-100000-0iter_8x3chains_on_CPU8x1_continued.rds\"))     # # i) extract samples as a data.frame     # burnins_scen226 <- 30000     # samples_scen226 <- getSample(calib_scen226$mod, thin = 1, start = burnins_scen226) %>% as.data.frame()     #     # # ii) fit normal and lognormal distributions for each parameter     # param_normals_scen226 <- lapply(setNames(names(samples_scen226), names(samples_scen226)), function(p) {     #   list(mean = mean(samples_scen226[[p]]),     #       sd   = sd(  samples_scen226[[p]]))     # })[c('beta_unitcostratio', 'kc_jmax')] # only keep these     #     # # then pass on these as prior for these     # par_to_estimate$beta_unitcostratio <- param_normals_scen226$beta_unitcostratio     # par_to_estimate$kc_jmax            <- param_normals_scen226$kc_jmax      par_to_estimate$beta_unitcostratio <- list(mean    = 207.86, sd    = 6.79)     par_to_estimate$kc_jmax            <- list(mean    = 0.4244, sd    = 0.0217)     if (scenario %in% c(231)) {       # truncated normal:       par_to_estimate$beta_unitcostratio <- list(mean    = 207.86, sd    = 6.79,         lower = 207.86 - 3 * 6.79,         upper = 207.86 + 3 * 6.79)       # normal:       par_to_estimate$kc_jmax            <- list(mean    = 0.4244, sd    = 0.0217)     }   }   # Remove parameters that are defined to be estimated from default_par_fixed   par_to_fix <- default_par_fixed[!(names(default_par_fixed) %in% names(par_to_estimate))]    ## Setup the data (drivers and obs) for the three calibration scenarios ----    # Subset different combination sites to dfeine target variables.   # For easier handling do this in combined drivobs-object.   drivobs_train_bigD13C_vj_gpp <- dplyr::inner_join(     train_drivers,     train_obs,     by = join_by(sitename))    drivobs_test_bigD13C_vj_gpp <- dplyr::inner_join(     test_drivers,     test_obs,     by = join_by(sitename))    all_potential_targets <- unique(unlist(drivobs_train_bigD13C_vj_gpp$targets))   if (scenario %in% c(223, 224, 225, 229, 230, 231)) { # GPP and traits data     targets_to_keep <- c(\"gpp\", \"bigD13C\")   } else if (scenario %in% c(226)) {       # only traits data, either both, or vj only, or bigD13C only     targets_to_keep <- c(\"bigD13C\")     # } else if (scenario %in% c(220)) {  # only GPP data from FR-Pue     #   targets_to_keep <- c(\"gpp\")     #   sites_to_keep <- \"FR-Pue\"   } else {     stop(sprintf(\"Unsupported scenario: %d\", scenario))   }   stopifnot(all(targets_to_keep %in% all_potential_targets))    drivobs_train <- drivobs_train_bigD13C_vj_gpp |>     # keep only sites with targets we want     dplyr::rowwise() |> dplyr::filter(any(targets_to_keep %in% .data$targets)) |> dplyr::ungroup() |>     # remove other unwanted target specifications from sites we keep (e.g. ET observations for a site with GPP and ET)     dplyr::mutate(targets = list(intersect(targets, targets_to_keep))) |> dplyr::ungroup()    drivobs_test <- drivobs_test_bigD13C_vj_gpp ## for the test data set keep all    ## return ---   return(list(     drivobs_train = drivobs_train,     drivobs_test = drivobs_test,     par_fixed = par_to_fix,     par = par_to_estimate   )) }   setup_rsofun_calibration(226) setup_rsofun_calibration(226)$drivobs_train setup_rsofun_calibration(231) setup_rsofun_calibration(231)$drivobs_train run_mcmc_rsofun <- function(     curr_calibration_scenario,     # MCMC setup:     iterations = 6,     burnin = 0,     n_chains_independent    = 3, # number of independent chains (called 'nrChains' in runMCMC)     n_chains_within_sampler = 3, # number of internal chains to be sampled (called 'startValue' in runMCMC, at least 2 for DEzs)      # parallelization:     n_parallel_independent  = 3, # number of cores for parallelization of independent chains     https://cran.r-project.org/web/packages/BayesianTools/vignettes/InterfacingAModel.html#running-several-mcmcs-in-parallel     outpath = \"data\",     suffix_str = \"\",     sampler_runMCMC = \"DREAMzs\"     ) {   # Setup simulation model   res <- setup_rsofun_calibration(scenario = curr_calibration_scenario)   # res$drivobs_train   # res$drivobs_test   # res$par_fixed   # res$par    # Load loglikelihood (e.g. if using a tailor-made one, instead of package-provided):   # source(\"R/calibration_helpers.R\", echo = FALSE)   # source(\"R/cost_likelihood_pmodel.R\", echo = FALSE)    # Setup MCMC          # uses drivobs_train, not drivobs_test   driver_to_use_for_mcmc <- select(res$drivobs_train, sitename, params_siml, site_info, forcing)   obs_to_use_for_mcmc    <- select(res$drivobs_train, sitename, targets, data)    calib_sofun_settings <- list(     method = \"BayesianTools\",     metric = rsofun::cost_likelihood_pmodel,     control = list(       sampler_runMCMC = sampler,       settings_runMCMC = list(         burnin     = burnin,                 # 10000,         iterations = iterations,             # 50000,         nrChains   = n_chains_independent,   # number of independent chains to be sampled         startValue = n_chains_within_sampler # number of internal chains to be sampled       ),       n_parallel_nrChains = n_parallel_independent     ),     par = res$par   )    # setup output directories for parallel calibration   logpath <- file.path(outpath, \"calibrations\", paste0(\"out_calib_\", suffix_str, \".rds.log.txt\"))   rds_path <- gsub(\".log.txt\", \"\", logpath)   dir.create(path = dirname(logpath), showWarnings = FALSE)    # Run calibration in parallel   cat(paste0(Sys.time(), \": start sampling of \", paste0(\"out_calib_\", suffix_str, \".rds\")))   out_calib <- calib_sofun(     drivers   = driver_to_use_for_mcmc,     obs       = obs_to_use_for_mcmc,     settings_calib = calib_sofun_settings,     logpath   = logpath,     # other arguments for the cost function     par_fixed = res$par_fixed   )   ## Store result object to file: ----   ## This enables easy continuation of MCMC sampling   saveRDS(out_calib, file = rds_path, compress = \"xz\")   cat(paste0(Sys.time(), \": end   sampling of \", out_calib$name,     \". \\nWritten *.rds-output to: \", rds_path))    # return only performance results as tibble   timings <- tibble(     setup       = curr_calibration_scenario,     name        = gsub(\".rds.log.txt\", \"\", out_calib$name),     # sampling options:     sampler        = calib_sofun_settings$control$sampler_runMCMC,     burnin         = burnin,     iterations     = iterations,     n_chains       = n_chains_independent,     n_chains_inner = n_chains_within_sampler,     # performance results:     cores          = n_parallel_independent,     walltime       = out_calib$walltime # ,     # logfile        = out_calib$logpath   )   return(timings) }"},{"path":"https://fabern.github.io/rsofun/dev/articles/param_calib_multitarget.html","id":"run-calibration","dir":"Articles","previous_headings":"","what":"Run calibration","title":"Parameter calibration (P-Model) to multiple targets (GPP, bigD13C) QUARTO","text":"helper functions specified, can run two calibration setups. sampled MCMC chains stored specified path can easily loaded later time separate R session. , second setup run second time making use parallel sampling independent chains. make use arguments user-defined function run_mcmc_rsofun() allow us specify calibration setup, MCMC setup, parallelization strategy. Note parallelized version reduced walltime 4x. additional independent MCMC chains (e.g. rsofun documentation paper used 8 chains), can become important. Since MCMC sampling can long running tasks, resulting MCMC sampling chains stored disk, can easily recovered later R session analysis similar one . paralell MCMC sampling workers don’t send output console. logfile created progress can checked . example resulted common log file eight workers:","code":"dir.create(\"vignettes/files/param_calib_multitarget/\", showWarnings = FALSE)  df_timings226 <- run_mcmc_rsofun(226, suffix_str = \"setup_226\",   outpath = \"vignettes/files/param_calib_multitarget/\",   # mcmc setup:   sampler = \"DREAMzs\",   iterations = 600,   burnin = 0,   n_chains_independent      = 8,   n_chains_within_sampler   = 3,   # parallelization   n_parallel_independent    = 1 ) # 2025-12-16 10:49:52.217434: start sampling of out_calib_setup_226.rds # runMCMC terminated after 4.39500000000407seconds00 . Current logp  -389.1087 -421.1468 -396.6275 Please wait! # runMCMC terminated after 3.95499999998719seconds00 . Current logp  -377.7371 -379.5134 -377.3347 Please wait! # ... # runMCMC terminated after 4.23500000000058seconds00 . Current logp  -397.9886 -379.6501 -382.6354 Please wait!  df_timings231 <- run_mcmc_rsofun(231, suffix_str = \"setup_231\",   outpath = \"vignettes/files/param_calib_multitarget/\",   # mcmc setup:   sampler = \"DREAMzs\",   iterations = 600,   burnin = 0,   n_chains_independent      = 8,   n_chains_within_sampler   = 3,   # parallelization   n_parallel_independent    = 1 ) # 2025-12-16 10:51:14.211219: start sampling of out_calib_setup_231.rds # Running DREAM-MCMC, chain  1 iteration 300 of 600 . Current logp  -14645.97 -14571.83 -15471.88 Please wait! # runMCMC terminated after 16.8090000000084seconds00 . Current logp  -14616.55 -14462.62 -14529.8 Please wait! # Running DREAM-MCMC, chain  2 iteration 300 of 600 . Current logp  -16760.01 -15828.73 -14948.44 Please wait! # runMCMC terminated after 16.4020000000019seconds00 . Current logp  -14955.26 -14941.47 -14441.98 Please wait! # ... # runMCMC terminated after 17.8410000000003seconds00 . Current logp  -15023.04 -14854.75 -14265.61 Please wait!  df_timings231p <- run_mcmc_rsofun(231, suffix_str = \"setup_231_parallel\",   outpath = \"vignettes/files/param_calib_multitarget/\",   # mcmc setup:   sampler = \"DREAMzs\",   iterations = 600,   burnin = 0,   n_chains_independent      = 8,   n_chains_within_sampler   = 3,   # parallelization   n_parallel_independent    = 8     # here now we parallelize the 8 chains to 8 cores ) # 2025-12-16 10:52:17.880666: start sampling of out_calib_setup_231_parallel.rds # Writing MCMC sampling log to: files/param_calib_multitarget//calibrations/out_calib_setup_231_parallel.rds.log.txt # ... # 2025-12-16 10:55:56.813577: end   sampling of out_calib_setup_231_parallel.rds.log.txt. # Written *.rds-output to: files/param_calib_multitarget//calibrations/out_calib_setup_231_parallel.rds # calib_timings <- bind_rows( #   df_timings226, #   df_timings231, #   df_timings231p) knitr::kable(calib_timings |>   dplyr::mutate(name = gsub(\".rds.log.txt\", \"\", name)) |>   dplyr::mutate(resultfile = gsub(\"vignettes/\", \"\", resultfile)) ) starting worker pid=43576 on localhost:11353 at 11:15:05.976 starting worker pid=43589 on localhost:11353 at 11:15:06.058 starting worker pid=43602 on localhost:11353 at 11:15:06.142 starting worker pid=43615 on localhost:11353 at 11:15:06.224 starting worker pid=43628 on localhost:11353 at 11:15:06.306 starting worker pid=43641 on localhost:11353 at 11:15:06.389 starting worker pid=43654 on localhost:11353 at 11:15:06.476 starting worker pid=43668 on localhost:11353 at 11:15:06.570 Loading required package: rsofun loaded rsofun and set parent environment ...  Running DREAM-MCMC, chain  1 iteration 300 of 600 . Current logp  -15821.4 ... Please wait!  Running DREAM-MCMC, chain  1 iteration 300 of 600 . Current logp  -15415.3 ... Please wait!  Running DREAM-MCMC, chain  1 iteration 300 of 600 . Current logp  -14739.4 ... Please wait! ...  Running DREAM-MCMC, chain  1 iteration 600 of 600 . Current logp  -14654.7 ... Please wait! runMCMC terminated after 36.634seconds  Running DREAM-MCMC, chain  1 iteration 600 of 600 . Current logp  -14927.0 ... Please wait! runMCMC terminated after 40.068seconds"},{"path":"https://fabern.github.io/rsofun/dev/articles/param_calib_multitarget.html","id":"analyze-model-calibration","dir":"Articles","previous_headings":"","what":"Analyze model calibration","title":"Parameter calibration (P-Model) to multiple targets (GPP, bigD13C) QUARTO","text":"MCMC sampling (potentially new R script), load sampled chains analyse chain convergence posterior distribution. load previous results RDS files: define labelling changes obtain nicer looking plots. define function plot_mcmc_trace() plot trace plot MCMC sampling including Gelman-Rubin statistics easily assess convergence two calibration setups. vignette examples run MCMC long enough see converging trace plots. real application, one need increase number iterations. can see number chains, 8 independent chains, consisting 3 internal chains total 24 traces plots. Note 3 internal chains also reduce length iterations specified 600 200.   illustrate posterior (derived unconverged example MCMC chains) defining function plot_prior_posterior_density() shows prior posterior distributions. can clearly distinguish different priors used two setups, calibration constrains posteriors different parameter values.  joint prior distributions parameters can assessed correlation parameters, indicating compensating effects often also called equifinality - model output different parameter sets.","code":"# This loads MCMC chains that might have been generated with a separate R script out_calib_226 <- readRDS(\"files/param_calib_multitarget/calibrations/out_calib_setup_226.rds\") out_calib_231p <- readRDS(\"files/param_calib_multitarget/calibrations/out_calib_setup_231_parallel.rds\") rsofun_symbol_parname_description <- dplyr::tribble(   ~variable,            ~label,                                                      ~Symbol_R,   \"kphio\",              \"italic(phi)[0]^'*'*' (mol mol-\\u00B9)'\",               \"italic(phi)[0]^'*'\",   \"kphio_par_a\",        \"italic(a)[italic(phi)]*' (\\u00B0C-\\u00B2)'\",           \"italic(a)[italic(phi)]\",   \"kphio_par_b\",        \"italic(b)[italic(phi)]*' (\\u00B0C)'\",                       \"italic(b)[italic(phi)]\",   \"soilm_thetastar\",    \"italic(theta)^'*'*' ('*'mm'*')'\",                           \"italic(theta)^'*'\",   \"soilm_betao\",        \"italic(beta)[0]*' (-)'\",                                    \"italic(beta)[0]\",   \"beta_unitcostratio\", \"italic(beta)*' (-)'\",                                       \"italic(beta)\",   \"rd_to_vcmax\",        \"italic(b)[0]*' (-)'\",                                       \"italic(b)[0]\",   \"tau_acclim\",         \"italic(tau)*' (days)'\",                                     \"italic(tau)\",   \"kc_jmax\",            \"italic(c)^'*'*' (-)'\",                                      \"italic(c)^'*'\",   \"err_gpp\",            \"italic(sigma)['GPP']*' (gC m -\\u00B2 s-\\u00B9)'\", \"italic(sigma)['GPP']\",   \"err_bigD13C\",        \"italic(sigma)[Delta]*' ('*'\\u2030'*')'\",                    \"italic(sigma)[Delta]\" ) label_vec_short <- setNames(rsofun_symbol_parname_description$Symbol_R, rsofun_symbol_parname_description$variable) custom_labeller_variable <- function(labels, multi_line = TRUE) { # adapted from label_parsed   replaced_labels <- left_join(     select(labels, variable), # NOTE: this has variable hardcoded     select(rsofun_symbol_parname_description, variable, label),     by = join_by(variable))   # print(tibble(replaced_labels))   replaced_labels <- replaced_labels |> select(-variable)   replaced_labels <- label_value(replaced_labels, multi_line = multi_line)   # print(replaced_labels)   lapply(unname(replaced_labels), lapply, function(values) {     c(parse(text = as.character(values)))   }) } # Define plotting function plot_mcmc_trace <- function(out_calib, nr_internal_chains, burnin_to_skip, burnin_to_skip_gelman = burnin_to_skip, dont_thin = FALSE, end = NULL) {   x <- out_calib$mod   title <- basename(out_calib$name)    curr_iter <- x[[1]]$settings$iterations   if (dont_thin || curr_iter < 10000) {     curr_thin <- 1   } else {     curr_thin <- floor(curr_iter / 10000)   }    xsample <- BayesianTools::getSample(x, coda = T, thin = curr_thin, start = burnin_to_skip, end = end)    # nr_internal_chains will have same color   dat_to_plot <- lapply(xsample, function(single_chain) {     as_tibble(single_chain) |> mutate(iteration = burnin_to_skip + curr_thin * (1:n()))   }) |>     dplyr::bind_rows(.id = \"chain_id\") |>     tidyr::pivot_longer(-c(iteration, chain_id), names_to = \"variable\") |>     # mark inner and outer chains (assumes DEzs or DREAMzs):     mutate(outerChain = as.factor(ceiling(as.numeric(chain_id) / 3)),       innerChain = (as.numeric(chain_id) + 2) %% 3 + 1,       innerChain_str = letters[innerChain],       chain_id_str = paste0(outerChain, letters[innerChain])) #|>   # fix order: in order of appearance   # mutate(variable = forcats::as_factor(variable))    pl <- ggplot(dat_to_plot,     aes(x = iteration, y = value, color = outerChain, linetype = innerChain_str)) + geom_line() +     # geom_rug(sides = \"r\") +     theme_classic() +     # scale_x_continuous(labels = scales::label_number(scale_cut = scales::cut_short_scale())) +     facet_wrap(~variable,  nrow = 2, scales = \"free_y\", labeller = custom_labeller_variable) +     theme(       legend.position = \"bottom\", strip.text = element_text(size = 12)     ) +     labs(y = \"\", color = \"chain\", linetype = \"internal\\nchains\")    # add Gelman Diagnostics   get_gelman_diag <- function(mcmc, burnin_to_skip, end) {     gelman_df <- BayesianTools::gelmanDiagnostics(mcmc, start = burnin_to_skip, end = end)     psrf_values <- gelman_df$psrf[, \"Point est.\"]     # psrf_strings <- paste0(substr(names(psrf_values),1,5), \"..=\", sprintf(\"%.2f\", psrf_values))     psrf_strings <- paste0(\"'*\", unname(label_vec_short[names(psrf_values)]), \"*'=\", sprintf(\"%.2f\", psrf_values))     psrf_string <- paste0(psrf_strings, collapse = \", \")      subtitle <- sprintf(\"'GelmanDiagnostics: mpsrf=%.1f; psrf:%s'\",       gelman_df$mpsrf,       psrf_string)   }   subtitle <- tryCatch(get_gelman_diag(x, burnin_to_skip_gelman + 1, end = end), error = function(e) {     e   }) # unsure why min burnin of 1 is needed   pl <- pl + ggtitle(title, subtitle = parse(text = subtitle))    pl <- pl + geom_vline(xintercept = burnin_to_skip_gelman, color = \"red\", linetype = \"dashed\")    return(pl) } plot_mcmc_trace(out_calib_226, nr_internal_chains = 3, burnin_to_skip = 0, burnin_to_skip_gelman = 150) plot_mcmc_trace(out_calib_231p, nr_internal_chains = 3, burnin_to_skip = 0, burnin_to_skip_gelman = 150) plot_prior_posterior_density <- function(x, burnin_to_skip) {   require(BayesianTools)   require(dplyr)   require(tidyr)   require(ggplot2)    # Get matrices of prior and posterior samples   posteriorMat <- BayesianTools::getSample(x, parametersOnly = TRUE, start = burnin_to_skip)   priorMat <-  BayesianTools:::getSetup(x)$prior$sampler(10000) # nPriorDraws = 10000    # Parameter names   parNames <- colnames(posteriorMat)   # rename columns priorMat   colnames(priorMat) <- parNames    # Create data frame for plotting   df_plot <- rbind(     data.frame(priorMat,     par_estimation = \"prior\"),     data.frame(posteriorMat, par_estimation = \"posterior\")   ) |>     # dplyr::mutate(par_estimation = forcats::fct_inorder(par_estimation)) |> # order by appearance     tibble()   levels(df_plot$par_estimation)   # Plot with facet wrap   gg <- df_plot |>     tidyr::pivot_longer(-c(par_estimation), names_to = \"variable\") |>     # dplyr::mutate(variable = forcats::fct_inorder(variable)) |> # order by appearance     ggplot(       aes(x = value, fill = par_estimation)     ) +     geom_density(alpha = 0.8) +     theme_classic() +     facet_wrap(~variable,  nrow = 2, scales = \"free\", labeller = custom_labeller_variable) +     # facet_wrap( ~ variable , nrow = 2, scales = \"free\") +     theme(       legend.position = \"bottom\",       axis.title.x = element_text(\"\"),       axis.ticks.y = element_blank(),       axis.text.y = element_blank(),     ) +     scale_fill_manual(NULL, values = c(\"posterior\" = \"#29a274ff\",       \"prior\" = \"#777055ff\")) # GECO colors    return(gg) } library(cowplot) p1 <- plot_prior_posterior_density(out_calib_226$mod,  burnin_to_skip = 200) +  ggtitle(out_calib_226$name) #> Loading required package: BayesianTools #> Loading required package: tidyr p2 <- plot_prior_posterior_density(out_calib_231p$mod, burnin_to_skip = 20) +  ggtitle(out_calib_231p$name) cowplot::plot_grid(p1, p2, ncol = 1) BayesianTools::correlationPlot(out_calib_231p$mod)"},{"path":"https://fabern.github.io/rsofun/dev/articles/param_calib_multitarget.html","id":"compare-predictions-of-the-calibrated-model-with-observations","dir":"Articles","previous_headings":"","what":"Compare predictions of the calibrated model with observations","title":"Parameter calibration (P-Model) to multiple targets (GPP, bigD13C) QUARTO","text":"Eventually, want use calibrated model predictions also check agreement observations used calibration. define another helper function run_prediction_rsofun(), samples parameter sets MCMC chain make predictions. second function samples errors identified structural uncertainty (error model) combines predictions. use helper functions (setup_rsofun_calibration(), apply_bias_correction_and_sample_error(), predict_sofun_parallelized()). functions can generate predictions using e.g. Maximum--Posteriori (MAP) parameters well n=20 samples posterior. function plot_predobs_gpp_timeseries3() analyse_modobs3(), model output observations can compared either time series plots scatter plots. plot time series comparing predictions observations, can distinguish parametric uncertainty (‘Posterior’) related width posterior distribtution parameters structural uncertainty (model uncertainty) includes samples error model.  show density scatter plot comparing predictions observations. Since use MAP values predictions, uncertainty parameters taken account. plots useful detect model biases specific target variables specific ranges target variables.  vignette hopefully gives first glimpse realistic workflow calibrates rsofun multiple sites multiple targets. details refer model documentation paper (Paredes et al. 2025) code referred therein.","code":"# Samples posterior parameters (MAP or N=n_samples) and runs # model predictions # # This allows to do two things: # A) make predictions at sites/dates/... where we have observations # B) make predictions also  on dates/... where we have no observations, e.g. for continuous time series # we do B) once {by setting `return_continuous_timeseries = TRUE`} and then derive A) from it. run_prediction_rsofun <- function(     mcmc_posterior,     prediction = c(\"both\", \"test\", \"train\"),     burnin_to_skip = 0,     n_samples = 100,      # if n_samples == 1, use MAP     n_cores = NULL) {    if (length(prediction) == 1 && (prediction %in% c(\"both\", \"test\", \"train\"))) {     # as expected   } else {     stop(\"Provide prediction as either: 'both', 'test' or 'train'\")   }   n_cores <- ifelse(is.null(n_cores), 1, n_cores)   stopifnot(is(mcmc_posterior$mod, \"mcmcSamplerList\"))    curr_calibration_scenario <- as.integer(gsub(     \".*_setup_([0-9]*)_.*\",  # NOTE: hardcoded expected format of filename     \"\\\\1\",     mcmc_posterior$name))   stopifnot(!is.na(curr_calibration_scenario)) # Catches if expected format is inaccurate    # Setup simulation model   res <- setup_rsofun_calibration(scenario = curr_calibration_scenario)    # Set random seed for reproducibility   set.seed(2023)    # Sample parameters from MCMC posterior   # Evaluation of the uncertainty coming from the model parameters' uncertainty   if (n_samples > 1) {     samples_par <- getSample(       mcmc_posterior$mod,       thin = 1,       start = burnin_to_skip, numSamples = n_samples     ) |>       as.data.frame() |>       # Add sample IDs       dplyr::mutate(posterior_sample_id = 1:n()) |>       tidyr::nest(.by = posterior_sample_id, .key = \"pars\")   } else {     # mcmc_posterior$par # these are already precomputed...     # but more robust to recompute:     samples_par <- BayesianTools::MAP(mcmc_posterior$mod)$parametersMAP |>       as.list() |> as_tibble() |>       # Add sample IDs       dplyr::mutate(posterior_sample_id = 0L) |> # posterior_sample_id == 0 means MAP       tidyr::nest(.by = posterior_sample_id, .key = \"pars\")   }    # Setup prediction   predict_sofun_settings <- list(n_cores = n_cores)    if (prediction == \"both\") {     curr_driver <- bind_rows(res$drivobs_train, res$drivobs_test) |>       select(sitename, params_siml, site_info, forcing)     curr_obs    <- bind_rows(res$drivobs_train, res$drivobs_test) |>       select(sitename, targets, data)   } else if (prediction == \"train\") {     curr_driver <- select(res$drivobs_train, sitename, params_siml, site_info, forcing)     curr_obs    <- select(res$drivobs_train, sitename, targets, data)   } else if (prediction == \"test\") {     curr_driver <- select(res$drivobs_test, sitename, params_siml, site_info, forcing)     curr_obs    <- select(res$drivobs_test, sitename, targets, data)     stopifnot(nrow(curr_obs) > 0)   }    # Run prediction   df_pred_vs_obs <- predict_sofun_parallelized(     drivers     = curr_driver,     obs         = curr_obs,     settings    = predict_sofun_settings,     par         = samples_par,     par_fixed   = res$par_fixed   )    return(df_pred_vs_obs) }  # Runs the requested model predictions and returns results # Requested model predictions are defined by data.frame `par_df` containing # model parameter sets predict_sofun_parallelized <- function(     drivers,     obs,     settings,     par_fixed,     par_df = NULL) {   # Set number of cores if not specified   if (is.null(settings$n_cores)) {     settings$n_cores <- min(detectCores() - 1, 20) # at most 20   }   # ensure not more than needed   settings$n_cores <- min(nrow(par_df), settings$n_cores)    # Function to run prediction for a single parameter set   run_pmodel_single_prediction <- function(par, par_fixed, drivers, obs) {     # Function that runs the P-model for a sample of parameters     # but does not add the observation error      # Taken from cost_likelihood_pmodel()     stopifnot(nrow(obs) > 0)     # ensure some observation data are provided     stopifnot(nrow(drivers) > 0) # ensure some driver data are provided      # A) Include current parameters ----     stopifnot(length(intersect(names(par), names(par_fixed))) == 0) # no overlap     params_modl <- c(par, par_fixed)      # B,C) Run model and bring together with observed ----     df_pred_vs_obs <- rsofun:::get_mod_obs_pmodel(       drivers,       obs,       params_modl,       parallel = FALSE,       ncores = 1,       return_continuous_timeseries = TRUE)      # D) (DON'T) Sample error model ----     # NOTE: sampling is not done here, but can optionally be done before plotting     #       Here we rename to clarify that no error model has yet been applied.     df_pred_vs_obs <- df_pred_vs_obs |>       # clarify name of model output (containing not yet any error model term)       rename(mod_no_err = mod) |>       relocate(c(mod_no_err, err_par_sd), .after = last_col())      return(df_pred_vs_obs)   }    # Run the P-model predictions for each set of parameters   ## Prepare parallelization:   parallel_flag <- (settings$n_cores > 1 && nrow(par_df) > 1)   # setup helpers for conditional parallelization   do_if <- function(df, cond, f) { # enable conditional lines in dplyr piping     if (cond) f(df) else df   }   cl <- if (parallel_flag) {     multidplyr::new_cluster(settings$n_cores) |>       multidplyr::cluster_library(         packages = c(\"dplyr\", \"tidyr\", \"purrr\", \"rsofun\")       )   }   ## Run predictions:   df_model_predictions <- par_df |>     do_if(parallel_flag, function(df) multidplyr::partition(df, cl)) %>%     dplyr::mutate(\"sim\" = purrr::map(       pars,       ~ run_pmodel_single_prediction(         par = .x,         par_fixed,         drivers,         obs       )     )) |>     do_if(parallel_flag, function(df) dplyr::collect(df))    return(df_model_predictions) }  apply_bias_correction_and_sample_error <- function(df_pred, N_sample_error) {   set.seed(1982)   df_pred |>     # lazy_dt() |>   # if needed, uses lazy data.table and dtplyr for speed     # a) repeat lines: once for each sampled error     # following line is basically a cross_join: with     slice(rep(1:n(), each = N_sample_error)) |>     mutate(error_sample_id = as.integer(rep(1:N_sample_error, n() / N_sample_error))) |>     arrange(posterior_sample_id) |>     # b) sample the error:     group_by(err_par_sd, err_par_bias) |>     mutate(err_sample                = rnorm(n(),   sd = err_par_sd),       mod_biasremoved_no_err    = mod_no_err - err_par_bias,       mod_biasremoved_with_err  = mod_no_err - err_par_bias + err_sample) |>     ungroup() |>     as_tibble() |> # to access results of lazy dtplyr-computation as normal tibble()     # keep output light: i.e. remove unneded columns:     select(-err_sample) |>     mutate(across(where(is.character), as.factor)) } # get MAP and run model for MAP parameter set df_predict_MAP_train_231p <- run_prediction_rsofun(   mcmc_posterior = out_calib_231p,   prediction     = \"train\",   burnin_to_skip = 200,   n_samples      = 1, # n_samples == 1, requests MAP   n_cores        = 1) # this could be increased e.g. to 4  # get parameter samples and run model for thes parameter sets df_predict_train_231p <- run_prediction_rsofun(   mcmc_posterior = out_calib_231p,   prediction     = \"train\",   burnin_to_skip = 200,   n_samples      = 20,   n_cores        = 1) # this could be increased e.g. to 4  df_predict <- bind_rows(   # df_predict_test      |> mutate(is_train0_test1 = 1L, is_MAP = FALSE),   df_predict_train_231p     |> mutate(is_train0_test1 = 0L, is_MAP = FALSE),   # df_predict_MAP_test  |> mutate(is_train0_test1 = 1L, is_MAP = TRUE),   df_predict_MAP_train_231p |> mutate(is_train0_test1 = 0L, is_MAP = TRUE) )  # Free memory: # rm(df_predict_train_231p, #    df_predict_MAP_train_231p)  # df_predict_params<- df_predict |> select(posterior_sample_id, is_train0_test1, is_MAP, pars) |> unnest(pars) df_predict_gpp     <- df_predict |> select(posterior_sample_id, is_train0_test1, is_MAP, sim)  |> unnest(sim) |> filter(target == \"gpp\")     |> unnest(obs_metadata) df_predict_bigD13C <- df_predict |> select(posterior_sample_id, is_train0_test1, is_MAP, sim)  |> unnest(sim) |> filter(target == \"bigD13C\") |> unnest(obs_metadata)  # apply bias-correction and simulate structural error N_sample_error <- 3 df_predict_231p_gpp_sampled <- apply_bias_correction_and_sample_error(   df_predict_gpp,   N_sample_error = N_sample_error) df_predict_231p_bigD13C_sampled <- apply_bias_correction_and_sample_error(   df_predict_bigD13C,   N_sample_error = N_sample_error) # Save predictions to plot with separate script: # FOR STORAGE REASONS unnest the obs_metadata and save different targets separately: # out_prediction_template <- file.path(\"files/param_calib_multitarget/\", #                                       \"predictions\", \"pred_231p_XXX.rds\") # dir.create(dirname(out_prediction_template), showWarnings = FALSE) # fname_out_gpp     <- gsub(\"_XXX\", #                           paste0(    \"_gpp_sampled_N\", N_sample_error, \"errors\"), #                           out_prediction_template) # fname_out_bigD13C <- gsub(\"_XXX\", #                           paste0(\"_bigD13C_sampled_N\", N_sample_error, \"errors\"), #                           out_prediction_template) # df_predict_231p_gpp_sampled     |> #   select(posterior_sample_id,error_sample_id,is_train0_test1,is_MAP,sitename,target,obs,   date,err_par_bias,err_par_sd,mod_no_err,mod_biasremoved_no_err,mod_biasremoved_with_err) |> #   saveRDS(fname_out_gpp,     compress = \"xz\") # df_predict_231p_bigD13C_sampled |> #   select(posterior_sample_id,error_sample_id,is_train0_test1,is_MAP,sitename,target,obs,id,     err_par_bias,err_par_sd,mod_no_err,mod_biasremoved_no_err,mod_biasremoved_with_err) |> #   saveRDS(fname_out_bigD13C, compress = \"xz\")  # Load predictions for plotting with separate script: # df_predict_231p_gpp_sampled     <- readRDS(\"files/param_calib_multitarget//predictions/pred_231p_gpp_sampled_N3errors.rds\") # df_predict_231p_bigD13C_sampled <- readRDS(\"files/param_calib_multitarget//predictions/pred_231p_bigD13C_sampled_N3errors.rds\") # df_predict_231p_bigD13C_sampled <- readr::read_rds(paste0(\"/storage/scratch/giub_geco/fbernhard/rsofun_doc_outputs/data/predictions/out_predict_\",n_post,\"_30000burnin__out_calib__scen222_DREAMzs-100000-0iter_8x3chains_on_CPU8x1_continued.rds_vj_sampled\",n_err,\".rds\")) # df_predict_231p_gpp_sampled     <- readr::read_rds(paste0(\"/storage/scratch/giub_geco/fbernhard/rsofun_doc_outputs/data/predictions/out_predict_\",n_post,\"_30000burnin__out_calib__scen222_DREAMzs-100000-0iter_8x3chains_on_CPU8x1_continued.rds_gpp_sampled\",n_err,\".rds\")) # add transparency to colors t_col <- function(color, percent = 50, name = NULL) {   #      color = color name   #    percent = % transparency   #       name = an optional name for the color   rgb.val <- col2rgb(color) # Get RGB values for named color   ## Make new color using input color as base and alpha set by transparency   t.col <- rgb(     rgb.val[1], rgb.val[2], rgb.val[3],     max = 255,     alpha = (100 - percent) * 255 / 100,     names = name)   invisible(t.col) ## Save the color }  ## copied from sofunCalVal package (and adapted to analyse_modobs3) analyse_modobs3 <- function(df,                             mod,                             obs,                             type = \"points\",                             filnam = NA,                             relative = FALSE,                             lower_xlim = 0,                             use_factor = NULL,                             shortsubtitle = FALSE,                             plot_subtitle = TRUE,                             plot_linmod = TRUE,                             pal = \"batlowW\",                             ...) {   require(ggplot2)   require(dplyr)    # if (identical(filnam, NA)) filnam <- \"analyse_modobs.pdf\"    ## rename to 'mod' and 'obs' and remove rows with NA in mod or obs   df <- df %>%     as_tibble() %>%     ungroup() %>%     dplyr::select(dplyr::all_of(c(mod = mod, obs = obs))) %>%     tidyr::drop_na(mod, obs)    ## get linear regression (coefficients)   linmod <- lm(obs ~ mod, data = df)    ## construct metrics table using the 'yardstick' library   df_metrics <- df %>%     yardstick::metrics(obs, mod) %>%     dplyr::bind_rows(tibble(.metric = \"n\", .estimator = \"standard\", .estimate = summarise(df, numb = n()) %>% unlist())) %>%     dplyr::bind_rows(tibble(.metric = \"slope\", .estimator = \"standard\", .estimate = coef(linmod)[2])) %>%     # dplyr::bind_rows( tibble( .metric = \"nse\",      .estimator = \"standard\", .estimate = hydroGOF::NSE( obs, mod, na.rm=TRUE ) ) ) %>%     dplyr::bind_rows(tibble(.metric = \"mean_obs\", .estimator = \"standard\", .estimate = summarise(df, mean = mean(obs, na.rm = TRUE)) %>% unlist())) %>%     dplyr::bind_rows(tibble(       .metric = \"prmse\", .estimator = \"standard\",       .estimate = dplyr::filter(., .metric == \"rmse\") %>% dplyr::select(.estimate) %>% unlist() /         dplyr::filter(., .metric == \"mean_obs\") %>%           dplyr::select(.estimate) %>%           unlist()     )) %>%     dplyr::bind_rows(tibble(       .metric = \"pmae\", .estimator = \"standard\",       .estimate = dplyr::filter(., .metric == \"mae\") %>% dplyr::select(.estimate) %>% unlist() /         dplyr::filter(., .metric == \"mean_obs\") %>%           dplyr::select(.estimate) %>%           unlist()     )) %>%     dplyr::bind_rows(tibble(.metric = \"bias\", .estimator = \"standard\", .estimate = dplyr::summarise(df, mean((mod - obs), na.rm = TRUE)) %>% unlist())) %>%     dplyr::bind_rows(tibble(.metric = \"pbias\", .estimator = \"standard\", .estimate = dplyr::summarise(df, mean((mod - obs) / obs, na.rm = TRUE)) %>% unlist()))    rsq_val <- df_metrics %>%     dplyr::filter(.metric == \"rsq\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   rmse_val <- df_metrics %>%     dplyr::filter(.metric == \"rmse\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   mae_val <- df_metrics %>%     dplyr::filter(.metric == \"mae\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   bias_val <- df_metrics %>%     dplyr::filter(.metric == \"bias\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   slope_val <- df_metrics %>%     dplyr::filter(.metric == \"slope\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()   n_val <- df_metrics %>%     dplyr::filter(.metric == \"n\") %>%     dplyr::select(.estimate) %>%     unlist() %>%     unname()    if (relative) {     rmse_val <- rmse_val / mean(df$obs, na.rm = TRUE)     bias_val <- bias_val / mean(df$obs, na.rm = TRUE)   }    rsq_lab <- format(rsq_val, digits = 2)   rmse_lab <- format(rmse_val, digits = 3)   mae_lab <- format(mae_val, digits = 3)   bias_lab <- format(bias_val, digits = 3)   slope_lab <- format(slope_val, digits = 3)   n_lab <- format(n_val, digits = 3)    results <- tibble(rsq = rsq_val, rmse = rmse_val, mae = mae_val, bias = bias_val, slope = slope_val, n = n_val)    if (shortsubtitle) {     subtitle <- bquote(italic(R)^2 == .(rsq_lab) ~ ~       RMSE == .(rmse_lab))   } else {     subtitle <- bquote(italic(R)^2 == .(rsq_lab) ~ ~       RMSE == .(rmse_lab) ~ ~       bias == .(bias_lab) ~ ~       slope == .(slope_lab) ~ ~       italic(N) == .(n_lab))   }    if (type == \"hex\") {      upper_xlim <- round(max(quantile(df$mod, 0.9999), quantile(df$obs, 0.9999)))     stopifnot(is.null(lower_xlim) || (is.numeric(lower_xlim) && length(lower_xlim) == 1))     lower_xlim <- ifelse(is.null(lower_xlim),       round(min(quantile(df$mod, 0.0001), quantile(df$obs, 0.0001))),       lower_xlim)      ## ggplot hexbin     gg <- df %>%       ggplot2::ggplot(aes(x = mod, y = obs)) +       geom_hex(bins = 50, show.legend = FALSE) +       geom_abline(intercept = 0, slope = 1, linetype = \"dotted\") +       # geom_hline(yintercept = 0, linetype = \"dotted\") +       # geom_vline(xintercept = 0, linetype = \"dotted\") +       coord_fixed() +       xlim(lower_xlim, upper_xlim) +       ylim(lower_xlim, upper_xlim) +       theme_classic() +       labs(x = mod, y = obs)      if (pal == \"batlowW\") {       gg <- gg + khroma::scale_fill_batlowW(trans = \"log\", reverse = TRUE)     } else if (pal == \"davos\") {       gg <- gg + khroma::scale_fill_davos(trans = \"log\", reverse = TRUE)     }      if (plot_subtitle) gg <- gg + labs(subtitle = subtitle)     if (plot_linmod) gg <- gg + geom_smooth(method = \"lm\", color = \"red\", linewidth = 0.5, se = FALSE)      if (!identical(filnam, NA)) {       ggsave(filnam, width = 5, height = 5)     }   }    return(list(df_metrics = df_metrics, gg = gg, linmod = linmod, results = results)) }  plot_predobs_gpp_timeseries3 <- function(ts_to_plot) {   # separate obs   df_tsplot_gpp_obs <- ts_to_plot |>     select(sitename, target, date, obs, Scenario, dataset) |>     distinct()    # compute stats of sampled distributions before plotting them   tibble_to_plot <- ts_to_plot |>     filter(target == \"gpp\") |>     # dtplyr::lazy_dt() |> # THIS WAS NEEDED FOR THE FULL DATA.FRAME     group_by(Scenario, dataset, parameters, sitename, target, date, model_output_type, y_facet) |>     summarise( # mod_no_err_p50 = quantile(mod_no_err, 0.5),       modelled_p50 = quantile(modelled, 0.5),       modelled_p95 = quantile(modelled, 0.95),       modelled_p05 = quantile(modelled, 0.05)     ) |>     as_tibble() |>     # and bind back obsevations     left_join(       df_tsplot_gpp_obs,       by = join_by(sitename, target, date, Scenario, dataset))    n_sites <- tibble_to_plot$sitename |> unique() |> length()    pl_timeseries_gpp <- ggplot(     data = tibble_to_plot,     mapping = aes(x = date, y = modelled_p50)) +     # Observations underneath (following Cameron 2022)     geom_point(       data = function(df) df |> select(-parameters, -model_output_type, -y_facet, -starts_with(\"modelled\")) |> distinct(),       # data = df_tsplot_gpp_obs, # variant 1, but does not allow %+%-replacement of underlying data       mapping = aes(y = obs), color = \"black\", shape = 4, alpha = 0.5, size = 0.5) +     # Structural uncertainty (including error model), a.k.a prediction band     geom_ribbon(       alpha = 0.5,       data = function(df) df |> filter(model_output_type == \"with struct. uncert.\"),       mapping = aes(ymin = modelled_p05, ymax = modelled_p95, fill = \"Post.+Error\")) +     # Parametric uncertainty (without error model, only parameter sampling), a.k.a confidence band     geom_ribbon(       alpha = 0.5,       data = function(df) df |> filter(model_output_type == \"rsofun\"),       mapping = aes(ymin = modelled_p05, ymax = modelled_p95, fill = \"Posterior\")) +     geom_line(       data = function(df) df |> filter(model_output_type == \"rsofun\"),       mapping = aes(y = modelled_p50, color = \"Posterior\")) +     # layout     facet_wrap(~sitename, scales = \"free_x\") +     theme_classic() + theme(legend.position = \"bottom\") +     labs(       x = NULL, #' Date',       y = expression(paste(\"GPP (g C m\"^-2, \"s\"^-1, \")\"))     ) +     scale_fill_manual(NULL, aesthetics = c(\"colour\", \"fill\"),       breaks = c(\"Post.+Error\",         \"Posterior\"),       values = c(\"Posterior\"   = t_col(\"#29a274ff\"),         \"Post.+Error\" = t_col(\"#777055ff\"))     ) +     scale_x_date(date_breaks = \"12 months\", date_labels = \"%Y-%m\") } # Time series of GPP (Figure C5) dflong_gpp_train <- df_predict_231p_gpp_sampled |>   mutate(Scenario = \"231\") |>   # select only training sites   filter(is_train0_test1 == 0) |>   select(posterior_sample_id, error_sample_id, Scenario, is_train0_test1, is_MAP, sitename, target,     obs,                 date, # these are target specific observation_metadata     mod_no_err, mod_biasremoved_no_err, mod_biasremoved_with_err) |>   # pivot the model_output_types to long   tidyr::pivot_longer(c(mod_no_err, mod_biasremoved_no_err, mod_biasremoved_with_err),     names_to = \"model_output_type\", values_to = \"modelled\") |>   mutate(model_output_type = factor(     model_output_type,     levels = c(\"mod_no_err\", \"mod_biasremoved_no_err\", \"mod_biasremoved_with_err\"),     labels = c(\"rsofun\",    \"bias-corrected\",        \"with struct. uncert.\"))) |>   # derive column `parameters` (\"MAP\" or \"Posterior\") from `is_MAP`   mutate(is_MAP = factor(ifelse(is_MAP, \"MAP\", \"Posterior\"))) |>   rename(parameters = is_MAP) |>   # derive column `dataset` (\"train\" or \"test\") from column `is_train0_test1`   mutate(is_train0_test1 = factor(ifelse(is_train0_test1 == 1, \"test\", \"train\"))) |>   rename(dataset = is_train0_test1)  df_B3_timeseries <- dflong_gpp_train |>   # remove the bias-corrected values for gpp since we did not fit a bias   filter(!(model_output_type %in% c(\"bias-corrected\"))) |>   # select what to plot and how to name it   mutate(y_facet = case_when(     Scenario == \"231\" & model_output_type == \"rsofun\" &               parameters == \"MAP\"       ~ \"MAP\",     Scenario == \"231\" & model_output_type == \"rsofun\" &               parameters == \"Posterior\" ~ \"Posterior\",     Scenario == \"231\" & model_output_type == \"with struct. uncert.\" & parameters == \"Posterior\" ~ \"Post.+Error\",     # all else is not plotted     TRUE ~ \"remove\") |> factor(levels = c(\"MAP\", \"Posterior\", \"Post.+Error\"))) |>   filter(y_facet != \"remove\")  # Plot raw predictions pl_timeseries_gpp <- plot_predobs_gpp_timeseries3(df_B3_timeseries) pl_timeseries_gpp # fake output since prediction was run previous to vignette rendering knitr::include_graphics(\"files/param_calib_multitarget/predictions/pl_timeseries_gpp.png\",   dpi = 100) gpp_labs <- function(xNULL = FALSE) {   list(labs(x = ifelse(xNULL, \" \", \"Predicted GPP (g C m-\\u00B2 s-\\u00B9)\"),     y = \"Observed GPP (g C m-\\u00B2 s-\\u00B9)\")) } bigD13C_labs <- function(xNULL = FALSE) {   list(labs(x = ifelse(xNULL, \" \", \"Predicted Δ (\\u2030)\"),     y = \"Observed Δ (\\u2030)\")) }  # compute scatters (and skills) for MAP of test set: list_of_scenarios_to_loop_over <- list(   s231 = list(\"bigD13C\" = df_predict_231p_bigD13C_sampled,  \"gpp\" = df_predict_231p_gpp_sampled) )  parameter_set <- \"MAP\" list_of_scatters <- lapply(list_of_scenarios_to_loop_over, function(list_of_targets) {   lapply(list_of_targets, function(df_target_prediction) {     curr_target <- first(df_target_prediction$target)      # (MAP, Posterior, Posterior+Error)     # MAP:             is posterior_sample_id==0     #                  e.g. filter(df_gpp, is_train0_test1 == 1,     is_MAP, error_sample_id==1)     # Posterior:       just take one error sampling, but all (~25 posterior samples)     #                  e.g. filter(df_gpp, is_train0_test1 == 1,             error_sample_id==1),     # Posterior+Error: take all errors     #                  e.g. filter(df_gpp, is_train0_test1 == 1,             error_sample_id>=1)     df <- df_target_prediction %>%       {         if (parameter_set == \"MAP\") filter(., is_MAP) else .       } %>% filter(error_sample_id == 1) # , is_train0_test1 == 1 # TODO: why was this removed?     mod <- \"mod_biasremoved_no_err\"     lower_xlim <- ifelse(curr_target == \"gpp\", list(0), list(NULL))[[1]]      if (nrow(df) == 0) {       return(list(gg = ggplot() + theme_void()))     } else {       return(analyse_modobs3(df, mod = mod, obs = \"obs\", type = \"hex\"))     }   }) })  ### single comparison plot: ---- mark_as_target <- theme(panel.background = element_rect(fill = t_col(\"darkgreen\", 80))) pl_scatter_comparison <- cowplot::plot_grid(   list_of_scatters$s231$bigD13C$gg + mark_as_target + bigD13C_labs(),   list_of_scatters$s231$gpp$gg     + mark_as_target + gpp_labs() ) pl_scatter_comparison # fake output since prediction was run previous to vignette rendering knitr::include_graphics(\"files/param_calib_multitarget/predictions/pl_scatter_comparison.png\",   dpi = 150)"},{"path":"https://fabern.github.io/rsofun/dev/articles/pmodel_use.html","id":"demo-data","dir":"Articles","previous_headings":"","what":"Demo data","title":"P-model usage","text":"package includes two demo datasets run validate p-model output using GPP observations. files can directly loaded workspace typing: real data French FR-Pue fluxnet site. Information data structure, variable names, meaning units can found reference pages p_model_drivers p_model_validation. can use data run model, together observations GPP can also calibrate p-model parameters. Another two datasets provided example validate model leaf traits data, rather fluxes. Measurements Vcmax25 (aggregated species) subset 4 sites GlobResp database (Atkin et al., 2015) given p_model_validation_vcmax25 corresponding forcing P-model given p_model_drivers_vcmax25. Since leaf traits measured per site, forcing used single year average climate (average measurements 2001 2015 day year). remainder vignette, use GPP flux datasets. workflow exactly leaf traits data. get raw data structure used within rsofun, please see R packages ingestr FluxDataKit.","code":"library(rsofun)  # this is to deal with an error p_model_drivers.rds not being found  p_model_drivers #> # A tibble: 1 × 4 #>   sitename params_siml       site_info        forcing               #>   <chr>    <list>            <list>           <list>                #> 1 FR-Pue   <tibble [1 × 11]> <tibble [1 × 4]> <tibble [2,190 × 13]>  p_model_validation #> # A tibble: 1 × 2 #>   sitename data                 #>   <chr>    <list>               #> 1 FR-Pue   <tibble [2,190 × 3]> p_model_drivers_vcmax25 #> # A tibble: 4 × 4 #>   sitename             params_siml       site_info        forcing  #>   <chr>                <list>            <list>           <list>   #> 1 Reichetal_Colorado   <tibble [1 × 11]> <tibble [1 × 6]> <tibble> #> 2 Reichetal_New_Mexico <tibble [1 × 11]> <tibble [1 × 6]> <tibble> #> 3 Reichetal_Venezuela  <tibble [1 × 11]> <tibble [1 × 6]> <tibble> #> 4 Reichetal_Wisconsin  <tibble [1 × 11]> <tibble [1 × 6]> <tibble>  p_model_validation_vcmax25 #> # A tibble: 4 × 2 #> # Groups:   sitename [4] #>   sitename             data             #>   <chr>                <list>           #> 1 Reichetal_Colorado   <tibble [1 × 2]> #> 2 Reichetal_New_Mexico <tibble [1 × 2]> #> 3 Reichetal_Venezuela  <tibble [1 × 2]> #> 4 Reichetal_Wisconsin  <tibble [1 × 2]>"},{"path":"https://fabern.github.io/rsofun/dev/articles/pmodel_use.html","id":"running-model","dir":"Articles","previous_headings":"","what":"Running model","title":"P-model usage","text":"data prepared can run P-model using runread_pmodel_f(). function takes nested data structure runs model site site, returning nested model output results matching input drivers.","code":"# Define model parameter values. # Correspond to maximum a posteriori estimates from Bayesian calibration in # analysis/02-bayesian-calibration.R. params_modl <- list(   kphio              = 5.000000e-02, # chosen to be too high for demonstration   kphio_par_a        =-2.289344e-03,   kphio_par_b        = 1.525094e+01,   soilm_thetastar    = 1.577507e+02,   soilm_betao        = 1.169702e-04,   beta_unitcostratio = 146.0,   rd_to_vcmax        = 0.014,   tau_acclim         = 20.0,   kc_jmax            = 0.41   )  # Run the model for these parameters. output <- rsofun::runread_pmodel_f(   p_model_drivers,   par = params_modl   )"},{"path":"https://fabern.github.io/rsofun/dev/articles/pmodel_use.html","id":"plotting-output","dir":"Articles","previous_headings":"Running model","what":"Plotting output","title":"P-model usage","text":"can now visualize model output measured values together.","code":"# Load libraries for plotting library(dplyr) library(tidyr) library(ggplot2)  # Create data.frame for plotting df_gpp_plot <- output |>   tidyr::unnest(data) |>   dplyr::select(date, gpp_mod = gpp) |>   dplyr::left_join(     p_model_validation |>       tidyr::unnest(data) |>       dplyr::select(date, gpp_obs = gpp),     by = \"date\"     ) |>     # Plot only first year   dplyr::slice(1:365)  # Plot GPP ggplot(data = df_gpp_plot) +   geom_point(     aes(       x = date,       y = gpp_obs,       color = \"Observations\"     ),   ) +   geom_line(     aes(       x = date,       y = gpp_mod,       color = \"P-model\"     )   ) +   theme_classic() +   theme(     panel.grid.major.y = element_line(),     legend.position = \"bottom\"     ) +   labs(     x = 'Date',     y = expression(paste(\"GPP (g C m\"^-2, \"s\"^-1, \")\"))   ) +   scale_color_manual(     NULL,     breaks = c(\"Observations\",                \"P-model\"),     values = c(\"black\", \"tomato\")) #> Warning: Removed 42 rows containing missing values or values outside the scale #> range (`geom_point()`)."},{"path":"https://fabern.github.io/rsofun/dev/articles/pmodel_use.html","id":"calibrating-model-parameters","dir":"Articles","previous_headings":"","what":"Calibrating model parameters","title":"P-model usage","text":"optimize new parameters based upon driver data validation dataset must first specify optimization strategy settings, well cost function parameter ranges. rsofun supports optimization using GenSA BayesianTools packages. statement provides settings GenSA optimization approach. example maximum number iterations kept artificially low. real scenario increase value orders magnitude. Keep mind optimization routines rely cost function, , depending structure influences parameter selection. limited set cost functions provided model structure transparent custom cost functions can easily written. details can found “Parameter calibration cost functions” vignette. addition starting values ranges provided free parameters model. Free parameters include: parameters quantum yield efficiency kphio, kphio_par_a kphio_par_b, soil moisture stress parameters soilm_thetastar soilm_betao, also beta_unitcostratio, rd_to_vcmax, tau_acclim kc_jmax (see ?runread_pmodel_f). mindful newer versions rsofun additional parameters might introduced, re-check vignettes function documentation updating existing code. settings defined optimization function calib_sofun() can called driver data observations specified. Extra arguments cost function (like variable used target compute root mean squared error (RMSE) previous values parameters aren’t calibrated, needed run P-model). successful optimized parameters can used run subsequent modelling efforts, case slightly improving model fit global parameter set.  details optimization settings refer manuals GenSA BayesianTools.","code":"settings <- list(   method = \"GenSA\",   metric = cost_rmse_pmodel,   control = list(maxit = 100),   par = list(     kphio = list(lower=0.02, upper=0.2, init = 0.05)     ) ) # calibrate the model and optimize free parameters pars <- calib_sofun(   drivers = p_model_drivers,     obs = p_model_validation,   settings = settings,   # extra arguments passed to the cost function:   targets = \"gpp\",             # define target variable GPP   par_fixed = params_modl[-1]  # fix non-calibrated parameters to previous                                 # values, removing kphio   ) # Update the parameter list with calibrated value params_modl$kphio <- pars$par[\"kphio\"]  # Run the model for these parameters output_new <- rsofun::runread_pmodel_f(   p_model_drivers,   par = params_modl   )  # Update data.frame for plotting df_gpp_plot <- df_gpp_plot |>    left_join(     output_new |>       unnest(data) |>       select(date, gpp_calib = gpp),     by = \"date\"   )  # Plot GPP ggplot(data = df_gpp_plot) +   geom_point(     aes(       x = date,       y = gpp_obs,       color = \"Observations\"     ),   ) +   geom_line(     aes(       x = date,       y = gpp_mod,       color = \"P-model (uncalibrated)\"     )   ) +   geom_line(     aes(       x = date,       y = gpp_calib,       color = \"P-model (calibrated)\"     )   ) +   theme_classic() +   theme(     panel.grid.major.y = element_line(),     legend.position = \"bottom\"     ) +   labs(     x = 'Date',     y = expression(paste(\"GPP (g C m\"^-2, \"s\"^-1, \")\"))   ) +   scale_color_manual(     NULL,     breaks = c(\"Observations\",                \"P-model (uncalibrated)\",                \"P-model (calibrated)\"),     values = c(\"black\", \"grey\", \"tomato\")) #> Warning: Removed 42 rows containing missing values or values outside the scale #> range (`geom_point()`)."},{"path":"https://fabern.github.io/rsofun/dev/articles/pmodel_use.html","id":"one-step-p-model-call","dir":"Articles","previous_headings":"","what":"One-step P-model call","title":"P-model usage","text":"certain applications, core theory P-model, predicting acclimation photosynthesis leaf-level, may ’s needed simulations. {rsofun} also provides stripped-version “one-step” P-model call. , without considering forcing (output) time series, delayed acclimation, ecosystem-level -scaled quantities, coupling water balance related water limitation photosynthesis. Applications stripped-version may include simulations leaf-level photosynthetic traits. function run_pmodel_onestep_f_bysite() provides functionality improves computational efficiency call run_pmodel_f_bysite(). particularly useful calibrating model photosynthetic traits data. run_pmodel_onestep_f_bysite() uses low-level code module run_pmodel_f_bysite() (photosynth_pmodel.mod.f90) therefore provides fully consistent outputs latter. Using run_pmodel_onestep_f_bysite() instead rpmodel::rpmodel() guarantees consistency implementation across time-series one-step model applications within package. Note unit transformations shown needed obtain identical outputs.","code":"run_pmodel_onestep_f_bysite(   lc4 = FALSE,   forcing = data.frame(     temp  = 20,           # temperature, deg C     vpd   = 1000,         # Pa,     ppfd  = 300/10^6,     # mol/m2/s     co2   = 400,          # ppm,     patm  = 101325        # Pa   ),   params_modl = list(     kphio              = 0.04998,    # setup ORG in Stocker et al. 2020 GMD     kphio_par_a        = 0.0,        # disable temperature-dependence of kphio     kphio_par_b        = 1.0,     beta_unitcostratio = 146.0,     rd_to_vcmax        = 0.014,      # from Atkin et al. 2015 for C3 herbaceous     kc_jmax            = 0.41   ),   makecheck = TRUE ) #> # A tibble: 1 × 9 #>       vcmax      jmax   vcmax25    jmax25 gs_accl   chi    iwue      rd #>       <dbl>     <dbl>     <dbl>     <dbl>   <dbl> <dbl>   <dbl>   <dbl> #> 1 0.0000177 0.0000400 0.0000275 0.0000518 0.00158 0.694 7.64e-5 3.11e-6 #> # ℹ 1 more variable: bigdelta <dbl> # # # make sure to check ?run_pmodel_onestep_f_bysite for units of output quantities. library(rpmodel) out_rpmodel <- rpmodel(   tc             = 20,           # temperature, deg C   vpd            = 1000,         # Pa,   co2            = 400,          # ppm,   fapar          = 1,            # fraction,   ppfd           = 300/10^6,     # ~~mol/m2/d~~ or mol/m2/s                                  # rpmodel docs state that units of ppfd define                                   # output units of: lue, gpp, vcmax, rd                                   # (as well as vcmax25, gs)   patm           = 101325,       # Pa   kphio          = 0.04998,      # quantum yield efficiency as calibrated                                   # for setup ORG by Stocker et al. 2020 GMD,   beta           = 146.0,        # unit cost ratio a/b,   c4             = FALSE,   method_jmaxlim = \"wang17\",   do_ftemp_kphio = FALSE,        # corresponding to setup ORG   do_soilmstress = FALSE,        # corresponding to setup ORG   verbose        = TRUE   )    # out_rpmodel tidyr::as_tibble(out_rpmodel) |>    dplyr::select(vcmax, jmax, vcmax25, jmax25, gs, chi, iwue, rd) |>   # bring units to same as output of run_pmodel_onestep_f_bysite()   dplyr::mutate(gs   = gs/1/(300/10^6), # divide by fapar (-) and by ppfd (mol/m2/s)                 iwue = iwue/101325,     # divide by patm (Pa)                 rd   = rd*12            # mutliply by c_molmass (gC/mol)   ) #> # A tibble: 1 × 8 #>       vcmax      jmax   vcmax25    jmax25      gs   chi    iwue      rd #>       <dbl>     <dbl>     <dbl>     <dbl>   <dbl> <dbl>   <dbl>   <dbl> #> 1 0.0000177 0.0000400 0.0000279 0.0000547 0.00160 0.694 7.64e-5 3.38e-6"},{"path":"https://fabern.github.io/rsofun/dev/articles/sensitivity_analysis.html","id":"morris-sensitivity-analysis","dir":"Articles","previous_headings":"","what":"Morris sensitivity analysis","title":"Sensitivity analysis and calibration interpretation","text":"Morris method global sensitivity analysis allows explore parameters biggest influence model fit. example, quantify different values calibratable model parameters lead variability match GPP predicted P-model GPP observations. wise repeat exercise various targets may simulated equations P-model involve different model parameters. P-model low sensitivity certain parameter, calibrating improve model substantially. ’s sensitive another parameter, calibrating second parameter improve P-model fit greatly. spend computational resources calibrating parameters model sensitive. First , let’s define function measures agreement GPP predictions P-model GPP observations, set values calibratable parameters. computes normal log-likelihood GPP predictions, given observed GPP uncertainty. want see sensitive function changes parameter values. parameters constrained physical interpretation (e.g. kphio > 0) ’s also necessary provide bounded parameter space Morris’ method sample parameter space. define parameter space lower upper bounds. use morris() function {sensitivity} package perform sensitivity analysis. target function, use posterior density (log-likelihood) parameters given GPP data obtain via function BayesianTools::createBayesianSetup(). Note , using uniform prior, posterior distribution proportional GPP log-likelihood (defined previously) wherever parameter values feasible zero outside parameter ranges. following chunk, run Morris sensitivity analysis, using grid r=1000 values parameter one---time design. Running sensitivity analysis may take minutes, even small example dataset, still computationally cheaper running parameter calibration. analysis evaluates variability target function, .e. log-likelihood, several points across parameter space. approximation derivatives log-likelihood respect model parameters. Statistics μ*\\mu * σ\\sigma can interpreted mean absolute derivative standard deviation derivative, respectively. higher value statistics given parameter, influential parameter .  outcome Morris sensitivity analysis depends strongly choice parameter ranges parameters interact underlying model. example, constrained parameters based physical meaning (e.g. soilm_betao [0,1]) site FR-Pue data coming (e.g. kphio_par_b around 25o^{o}C). observing figure , notice parameters kphio kc_jmax high impact model fit (big μ*\\mu *), also magnitude dependence GPP two parameters changes across parameter space (big σ\\sigma). happens parameters interact light use efficiency calculation calibration may harder require data several sites. log-likelihood sensitive err_gpp large variation magnitude dependence. makes sense higher values standard deviation normal likelihood flatter (similar log-likelihood values calculated, whether model predictions using rest parameters good bad) lower err_gpp values likelihood pointy (hence good model fits achieve big log-likelihood value poor model fits, small value). help interpret sensitivity analysis better understand parameter-model relationship, may wise run several times different parameter ranges validation data. Note rd_to_vcmax affect GPP, actually affect dark respiration predictions, trait data also added validation.","code":"# Define log-likelihood function ll_pmodel <- function(     par_v                 # a named vector of all calibratable parameters including errors ){   rsofun::cost_likelihood_pmodel(        # reuse likelihood cost function     par_v,     obs = rsofun::p_model_validation,     drivers = rsofun::p_model_drivers,     targets = \"gpp\"   ) }  # Compute log-likelihood for a given set of parameters ll_pmodel( par_v = c(   kphio              = 4.102119e-02,   kphio_par_a        =-2.289344e-03,   kphio_par_b        = 1.525094e+01,   soilm_thetastar    = 1.577507e+02,   soilm_betao        = 1.169702e-04,   beta_unitcostratio = 146.0,   rd_to_vcmax        = 0.014,   tau_acclim         = 20.0,   kc_jmax            = 0.41,   error_gpp          = 0.9         # value from previous simulations )) #> [1] -2758.147 # best parameter values (initial values, taken from Stocker et al., 2020 GMD) par_cal_best <- c(   kphio              = 0.09423773,   kphio_par_a        = -0.0025,   kphio_par_b        = 20,   soilm_thetastar    = 0.6*240,   soilm_betao        = 0.2,   beta_unitcostratio = 146.0,   rd_to_vcmax        = 0.014,   tau_acclim         = 30.0,   kc_jmax            = 0.41,   error_gpp          = 1 )  # lower bound par_cal_min <- c(   kphio              = 0.03,   kphio_par_a        = -0.004,   kphio_par_b        = 10,   soilm_thetastar    = 0,   soilm_betao        = 0,   beta_unitcostratio = 50.0,   rd_to_vcmax        = 0.01,   tau_acclim         = 7.0,   kc_jmax            = 0.2,   error_gpp          = 0.01 )  # upper bound par_cal_max <- c(   kphio              = 0.15,   kphio_par_a        = -0.001,   kphio_par_b        = 30,   soilm_thetastar    = 240,   soilm_betao        = 1,   beta_unitcostratio = 200.0,   rd_to_vcmax        = 0.1,   tau_acclim         = 60.0,   kc_jmax            = 0.8,   error_gpp          = 4 ) morris_setup <- BayesianTools::createBayesianSetup(   likelihood = ll_pmodel,   prior = BayesianTools::createUniformPrior(par_cal_min, par_cal_max, par_cal_best),   names = names(par_cal_best) ) set.seed(432) morrisOut <- sensitivity::morris(   model = morris_setup$posterior$density,   factors = names(par_cal_best),    r = 1000,    design = list(type = \"oat\", levels = 20, grid.jump = 3),    binf = par_cal_min,    bsup = par_cal_max,    scale = TRUE   ) # Summarise the morris output morrisOut.df <- data.frame(   parameter = names(par_cal_best),   mu.star = apply(abs(morrisOut$ee), 2, mean, na.rm = T),   sigma = apply(morrisOut$ee, 2, sd, na.rm = T) ) |>    arrange( mu.star )  morrisOut.df |>   tidyr::pivot_longer( -parameter, names_to = \"variable\", values_to = \"value\") |>   ggplot(aes(     reorder(parameter, value),     value,      fill = variable),     color = NA) +   geom_bar(position = position_dodge(), stat = 'identity') +   scale_fill_manual(\"\",                      labels = c('mu.star' = expression(mu * \"*\"),                                'sigma' = expression(sigma)),                     values = c('mu.star' = \"#29a274ff\",                                 'sigma' = \"#777055ff\")) +   theme_classic() +   theme(     axis.text = element_text(size = 6),     axis.title = element_blank(),     legend.position = c(0.9, 0.1), legend.justification = c(0.95, 0.05)   ) +   coord_flip()    # make horizontal #> Warning in fortify(data, ...): Arguments in `...` must be used. #> ✖ Problematic argument: #> • color = NA #> ℹ Did you misspell an argument name?"},{"path":"https://fabern.github.io/rsofun/dev/articles/sensitivity_analysis.html","id":"interpretation-of-bayesian-calibration-routine","dir":"Articles","previous_headings":"","what":"Interpretation of Bayesian calibration routine","title":"Sensitivity analysis and calibration interpretation","text":"always important check convergence MCMC algorithm used Bayesian calibration. show plots statistics may help assess whether parameter calibration converged. According previous sensitivity analysis, calibrating error parameter GPP quantum yield efficiency parameters high impact model fit. Let’s run calibration: BayesianTools makes easy produce trace plot MCMC chains posterior density plot parameters. Trace plots show time series sampled chains, reach stationary state. One can also choose burnin visually, discard early iterations keep samples stationary distribution converge. set previous runs, iterations shown following trace plot. samples burnin period used inference.  posterior density plots may lumpy. case ’s advisable run MCMC algorithm iterations, order get better estimate parameters’ posterior distributions. good posterior look gaussian (although can skewed). multimodal density indicates MCMC still exploring parameter space hasn’t converged yet. posteriors can plotted priors using BayesianTools::marginalPlot(). convergence reached, oscillation time series look like white noise. ’s normal consecutive MCMC samples correlated sampling algorithm’s nature, presence general trend indicates convergence hasn’t reached. Looking correlation chains different parameters also helpful parameter correlation may slow convergence, chains may oscillate multivariate posterior space. calibration expect parameter samples somewhat correlated, especially kphio_par_a kphio_par_b specify shape temperature dependence quantum yield efficiency, φo(T)\\varphi_o(T). can also see err_gpp correlated kphio (P-model sensitive), since error represents good model fits observed GPP.  addition visualizations, ’s helpful compute convergence diagnostics, like Gelman-Brooks-Rubin (GBR) potential scale factors. diagnostic compares variance within chains across chains progressively get closer 1. common literature (Gelman, ., Carlin, J.B., Stern, H.S., Rubin, D.B.: Bayesian Data Analysis, 2nd edn. Chapman & Hall, London (2004)) accept convergence GBR 1.05 1.1. Finally, parameter MAP estimates can derived chains (converged) removing burnin period. can seen, next statistics, using summary function BayesianTools library. details diagnosing MCMC convergence can found vignette BayesianTools blogpost.","code":"# Calibrates kphio, kphio_par_b, kc_jmax - top 3 model params set.seed(2025)  # Define calibration settings settings_calib <- list(   method = \"BayesianTools\",   metric = rsofun::cost_likelihood_pmodel,   control = list(     sampler = \"DEzs\",     settings = list(       burnin = 12000,       iterations = 24000,       nrChains = 3,       # number of independent chains       startValue = 3      # number of internal chains to be sampled     )),   par = list(     kphio = list(lower = 0.02, upper = 0.15, init = 0.05),     kphio_par_a =list(lower = -0.004, upper = -0.001, init = -0.0025),     kphio_par_b = list(lower = 10, upper = 30, init = 20),     soilm_thetastar = list(       lower = 0.01 * rsofun::p_model_drivers$site_info[[1]]$whc,       upper = 1.0  * rsofun::p_model_drivers$site_info[[1]]$whc,       init  = 0.6  * rsofun::p_model_drivers$site_info[[1]]$whc     ),     soilm_betao = list(lower = 0.0, upper = 1.0, init = 0.0),     err_gpp = list(lower = 0.1, upper = 3, init = 0.8)   ) )  par_fixed <- list(   beta_unitcostratio = 146.0,   kc_jmax            = 0.41,   rd_to_vcmax        = 0.014,   tau_acclim         = 20.0   )  # Calibrate kphio-related parameters and err_gpp par_calib <- calib_sofun(   drivers = p_model_drivers,   obs = p_model_validation,   settings = settings_calib,   par_fixed = par_fixed,   targets = \"gpp\" ) saveRDS(par_calib, \"files/sensitivity_analysis.Rmd__par_calib.RDS\", compress = \"xz\")  # This code takes 15 minutes to run plot(par_calib$mod) correlationPlot(par_calib$mod, thin = 1)   # use all samples, no thinning gelmanDiagnostics(par_calib$mod) #> Potential scale reduction factors: #>  #>                 Point est. Upper C.I. #> kphio                 1.01       1.02 #> kphio_par_a           1.01       1.01 #> kphio_par_b           1.00       1.01 #> soilm_thetastar       1.02       1.04 #> soilm_betao           1.02       1.04 #> err_gpp               1.02       1.03 #>  #> Multivariate psrf #>  #> 1.03 summary(par_calib$mod) #> # # # # # # # # # # # # # # # # # # # # # # # # #  #> ## MCMC chain summary ##  #> # # # # # # # # # # # # # # # # # # # # # # # # #  #>   #> # MCMC sampler:  DEzs  #> # Nr. Chains:  9  #> # Iterations per chain:  4001  #> # Rejection rate:  0.849  #> # Effective sample size:  3377  #> # Runtime:  1301.851  sec.  #>   #> # Parameters #>                   psf     MAP    2.5%  median   97.5% #> kphio           1.010   0.041   0.040   0.041   0.042 #> kphio_par_a     1.006  -0.002  -0.003  -0.002  -0.002 #> kphio_par_b     1.004  15.251  14.888  15.350  15.803 #> soilm_thetastar 1.021 157.751 151.926 160.060 168.101 #> soilm_betao     1.021   0.000   0.000   0.008   0.038 #> err_gpp         1.016   1.074   1.040   1.074   1.111 #>  #> ## DIC:  5561.961  #> ## Convergence  #>  Gelman Rubin multivariate psrf:  1.034  #>   #> ## Correlations  #>                  kphio kphio_par_a kphio_par_b soilm_thetastar #> kphio            1.000      -0.097       0.287           0.236 #> kphio_par_a     -0.097       1.000      -0.201           0.116 #> kphio_par_b      0.287      -0.201       1.000           0.301 #> soilm_thetastar  0.236       0.116       0.301           1.000 #> soilm_betao      0.236       0.000       0.189           0.128 #> err_gpp          0.229      -0.002       0.098           0.042 #>                 soilm_betao err_gpp #> kphio                 0.236   0.229 #> kphio_par_a           0.000  -0.002 #> kphio_par_b           0.189   0.098 #> soilm_thetastar       0.128   0.042 #> soilm_betao           1.000   0.147 #> err_gpp               0.147   1.000"},{"path":"https://fabern.github.io/rsofun/dev/articles/sensitivity_analysis.html","id":"plotting-p-model-output-after-calibration","dir":"Articles","previous_headings":"Interpretation of Bayesian calibration routine","what":"Plotting P-model output after calibration","title":"Sensitivity analysis and calibration interpretation","text":"run checked calibration, let’s see model performs. compute credible intervals GPP prediction, ran P-model 600 samples posterior distribution calibrated parameters. result, obtain posterior distribution modeled GPP time step also posterior distribution predicted GPP, incorporates Gaussian model error. plot first year observed GPP (black) predicted GPP (grey), computed median posterior distribution modeled GPP. information accompanied 90% credible interval predicted GPP (shaded blue, narrow) 90% predictive interval (shaded grey). can see parameter uncertainty captured credible interval quite small, comparison model uncertainty captured predictive interval.","code":"# Evaluation of the uncertainty coming from the model parameters' uncertainty  # Sample parameter values from the posterior distribution samples_par <- getSample(   par_calib$mod,   thin = 60   ) |>   as.data.frame() |>   dplyr::mutate(mcmc_id = 1:n()) |>   tidyr::nest(.by = mcmc_id, .key = \"pars\")  run_pmodel <- function(par){   # Function that runs the P-model for a sample of parameters   # and also adds the new observation error      out <- runread_pmodel_f(     drivers = p_model_drivers,     par =  list(       kphio              = par$kphio,       kphio_par_a        = par$kphio_par_a,       kphio_par_b        = par$kphio_par_b,       soilm_thetastar    = par$soilm_thetastar,       soilm_betao        = par$soilm_betao,       beta_unitcostratio = 146.0,       rd_to_vcmax        = 0.014,       tau_acclim         = 20.0,       kc_jmax            = 0.41       )   )      # return modelled GPP and prediction for a new GPP observation   gpp <- out$data[[1]][, \"gpp\"]   out <- data.frame(     gpp = gpp,      gpp_pred = rnorm(       n = length(gpp),        mean = gpp,       sd = par$err_gpp       ),     date = out$data[[1]][, \"date\"])   return(out) }  set.seed(2025)  # Run the P-model for each set of parameters pmodel_runs <- samples_par |>   dplyr::mutate(sim = purrr::map(pars, ~run_pmodel(.x))) |>   # format to obtain 90% credible intervals   dplyr::select(mcmc_id, sim) |>   tidyr::unnest(sim) |>   dplyr::group_by(date) |>   # compute quantiles for each day   dplyr::summarise(     gpp_q05 = quantile(gpp, 0.05, na.rm = TRUE),     gpp_q50 = quantile(gpp, 0.5, na.rm = TRUE),          # get median     gpp_q95 = quantile(gpp, 0.95, na.rm = TRUE),     gpp_pred_q05 = quantile(gpp_pred, 0.05, na.rm = TRUE),     gpp_pred_q95 = quantile(gpp_pred, 0.95, na.rm = TRUE)   )  # run model with maximum a posteriori parameter estimates pmodel_run_map <- run_pmodel(   MAP(par_calib$mod)$parametersMAP |>      t() |>      as_tibble() ) ## add transparency to color given as a name add_alpha <- function( col, alpha ){   col    <- col2rgb( col, alpha = TRUE )/255   col[4] <- alpha   col    <- rgb(col[1,],col[2,],col[3,],col[4,])   return( col ) }  # Plot the credible intervals computed above # for the first year only data_to_plot <- pmodel_runs |>   # Plot only first year   dplyr::slice(1:365) |>   dplyr::left_join(     # Merge GPP validation data (first year)     p_model_validation$data[[1]][1:365, ] |>       dplyr::rename(gpp_obs = gpp),     by = \"date\")  plot_gpp_error <- ggplot(data = data_to_plot) +   geom_ribbon(     aes(       ymin = gpp_pred_q05,       ymax = gpp_pred_q95,       x = date,       fill = \"Model uncertainty\"     )) +   geom_ribbon(     aes(       ymin = gpp_q05,        ymax = gpp_q95,       x = date,       fill = \"Parameter uncertainty\"     )) +   # Include observations in the plot   geom_point(     aes(       x = date,      y = gpp_obs,      color = \"Observations\"     ),   ) +   geom_line(     aes(       x = date,       y = gpp_q50,       color = \"Predictions\"     )   ) +   theme_classic() +   theme(panel.grid.major.y = element_line(),         legend.position = \"bottom\") +   labs(     x = 'Date',     y = expression(paste(\"GPP (g C m\"^-2, \"s\"^-1, \")\"))   ) +   scale_color_manual(NULL,                      breaks = c(\"Observations\",                                 \"Predictions\"),                      values = c(\"black\", \"tomato\")) +   scale_fill_manual(NULL,                     breaks = c(\"Model uncertainty\",                                \"Parameter uncertainty\"),                     values = c(add_alpha(\"tomato\", 0.5),                                \"#1b9e77\", 0)) plot_gpp_error #> Warning: Removed 42 rows containing missing values or values outside the scale #> range (`geom_point()`)."},{"path":"https://fabern.github.io/rsofun/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Benjamin Stocker. Author, maintainer. Koen Hufkens. Author. Josefa Arán Paredes. Author. Laura Marqués. Contributor. Mayeul Marcadella. Contributor. Ensheng Weng. Contributor. Fabian Bernhard. Author. Geocomputation Earth Observation, University Bern. Copyright holder, funder.","code":""},{"path":"https://fabern.github.io/rsofun/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Stocker, Hufkens, Arán Paredes, Bernhard & Marcadella (2025). rsofun: R package Simulating Optimal FUNctioning (rsofun).                  model site-scale simulations ecosystem processes. https://doi.org/10.5281/zenodo.3712928","code":"@Misc{,   title = {rsofun: An R package for Simulating Optimal FUNctioning (rsofun).          A model for site-scale simulations of ecosystem processes.},   author = {Benjamin Stocker and Koen Hufkens and Josefa Arán Paredes and Fabian Bernhard and Mayeul Marcadella},   year = {2025},   doi = {10.5281/zenodo.3712928},   url = {https://github.com/geco-bern/rsofun}, }"},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"rsofun","dir":"","previous_headings":"","what":"The P-Model and BiomeE Modelling Framework","title":"The P-Model and BiomeE Modelling Framework","text":"R Simulating Optimal FUNctioning (RSOFUN) framework site-scale simulations ecosystem processes. package contains following modules: P-model leaf-level acclimation photosynthesis Stocker et al. (2019). SPLASH bioclimatic variables, including surface radiation budget soil water balance Davis et al. (2017). BiomeE comprehensive simulations ecosystem carbon water cycling, tree growth, tree cohort-explicit forest dynamics following Perfect Plasticity Approximation, Weng et al., (2015).","code":""},{"path":[]},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"stable-release","dir":"","previous_headings":"Installation","what":"Stable release","title":"The P-Model and BiomeE Modelling Framework","text":"install current stable release use CRAN repository:","code":"install.packages(\"rsofun\") library(\"rsofun\")"},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"development-release","dir":"","previous_headings":"Installation","what":"Development release","title":"The P-Model and BiomeE Modelling Framework","text":"install latest development release package run following commands install rsofun directly GitHub: NOTE: Installing GitHub requires compilation Fortran C source code contained {rsofun}. enable compiling source code, install Rtools Windows, Xcode GNU Fortran compiler Mac (see also ‘Mandatory tools’ ). Linux, gfortran compiler usually installed already. Vignettes rendered default, want include additional documentation please use:","code":"if(!require(remotes)){install.packages(\"remotes\")} remotes::install_github(\"geco-bern/rsofun\") library(\"rsofun\") if(!require(remotes)){install.packages(\"remotes\")} remotes::install_github(\"geco-bern/rsofun\", build_vignettes = TRUE) library(\"rsofun\")"},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"from-source","dir":"","previous_headings":"Installation","what":"From source","title":"The P-Model and BiomeE Modelling Framework","text":"Assuming rsofun location source directory, can build R package (extension .tar.gz) command line using: package can installed : , star * can replaced name package produced previous step.","code":"R CMD build --no-manual --no-build-vignettes rsofun R CMD INSTALL -c --preclean  *.tar.gz"},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"use","dir":"","previous_headings":"","what":"Use","title":"The P-Model and BiomeE Modelling Framework","text":"sections show ease use package terms model parameter specification running single run optimizing parameters given site (multiple sites). depth discussion refer vignettes.","code":""},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"running-model","dir":"","previous_headings":"Use","what":"Running model","title":"The P-Model and BiomeE Modelling Framework","text":"data prepared can run P-model using runread_pmodel_f(). function takes nested data structure runs model site site, returning nested model output results matching input drivers.","code":"# define model parameter values from previous # work params_modl <- list(     kphio              = 0.04998,    # setup ORG in Stocker et al. 2020 GMD     kphio_par_a        = 0.0,        # set to zero to disable temperature-dependence of kphio     kphio_par_b        = 1.0,     soilm_thetastar    = 0.6 * 240,  # to recover old setup with soil moisture stress     soilm_betao        = 0.0,     beta_unitcostratio = 146.0,     rd_to_vcmax        = 0.014,      # value from Atkin et al. 2015 for C3 herbaceous     tau_acclim         = 30.0,     kc_jmax            = 0.41   )  # run the model for these parameters output <- rsofun::runread_pmodel_f(   p_model_drivers,   par = params_modl   )"},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"parameter-optimization","dir":"","previous_headings":"Use","what":"Parameter optimization","title":"The P-Model and BiomeE Modelling Framework","text":"optimize new parameters based upon driver data validation dataset must first specify optimization strategy settings, well cost function parameter ranges. rsofun supports optimization using GenSA BayesianTools packages. statement provides settings GenSA optimization approach. example maximum number iterations kept artificially low. real scenario increase value orders magnitude. Keep mind optimization routines rely cost function, , depending structure influences parameter selection. limited set cost functions provided model structure transparent custom cost functions can easily written. details can found “Parameter calibration cost functions” vignette. addition starting values ranges provided free parameters model. Free parameters include: parameters quantum yield efficiency kphio, kphio_par_a kphio_par_b, soil moisture stress parameters soilm_thetastar soilm_betao, also beta_unitcostratio, rd_to_vcmax, tau_acclim kc_jmax (see ?runread_pmodel_f). mindful newer versions rsofun additional parameters might introduced, re-check vignettes function documentation updating existing code. settings defined optimization function calib_sofun() can called driver data observations specified. Extra arguments cost function (like variable used target compute root mean squared error (RMSE) previous values parameters aren’t calibrated, needed run P-model).","code":"settings <- list(   method              = \"GenSA\",   metric              = cost_rmse_pmodel,   control = list(     maxit = 100),   par = list(     kphio = list(lower=0.02, upper=0.2, init = 0.05)     ) ) # calibrate the model and optimize free parameters pars <- calib_sofun(     drivers = p_model_drivers,       obs = p_model_validation,     settings = settings,     # extra arguments passed to the cost function:     targets = \"gpp\",             # define target variable GPP     par_fixed = params_modl[-1]  # fix non-calibrated parameters to previous                                   # values, removing kphio   )"},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"data-and-code-for-model-documentation-paper-paredes-et-al-in-rev","dir":"","previous_headings":"","what":"Data and code for model documentation paper (Paredes et al., in rev.)","title":"The P-Model and BiomeE Modelling Framework","text":"Versioned releases repository deposited Zenodo (see badge top README file). Code reproduce analysis plots presented contained repository (subdirectory analysis/) demonstrated model documentation website (https://geco-bern.github.io/rsofun/, article ‘Sensitivity analysis calibration interpretation’). model forcing evaluation data based publicly available FLUXNET2015 data site FR-Pue, prepared FluxDataKit v3.4.2 (10.5281/zenodo.14808331), taken subset originally published data years 2007-2012. accessible {rsofun} R package contained part repository (subdirectory data/) CSV files. Outputs analysis presented archived analysis/paper_results_files/ subfolder. model documentation paper currently review. preprint available : https://www.biorxiv.org/content/10.1101/2023.11.24.568574v3","code":""},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"The P-Model and BiomeE Modelling Framework","text":"Stocker, B. D., Wang, H., Smith, N. G., Harrison, S. P., Keenan, T. F., Sandoval, D., Davis, T., Prentice, . C.: P-model v1.0: optimality-based light use efficiency model simulating ecosystem gross primary production, Geosci. Model Dev., 13, 1545–1581, https://doi.org/10.5194/gmd-13-1545-2020, 2020. Davis, T. W., Prentice, . C., Stocker, B. D., Thomas, R. T., Whitley, R. J., Wang, H., Evans, B. J., Gallego-Sala, . V., Sykes, M. T., Cramer, W.: Simple process-led algorithms simulating habitats (SPLASH v.1.0): robust indices radiation, evapotranspiration plant-available moisture, Geoscientific Model Development, 10, 689–708, doi:10.5194/gmd-10-689-2017, URL http: //www.geosci-model-dev.net/10/689/2017/, 2017. Weng, E. S., Malyshev, S., Lichstein, J. W., Farrior, C. E., Dybzinski, R., Zhang, T., Shevliakova, E., Pacala, S. W.: Scaling individual trees forests Earth system modeling framework using mathematically tractable model height-structured competition, Biogeosciences, 12, 2655–2694, https://doi.org/10.5194/bg-12-2655-2015, 2015.","code":""},{"path":"https://fabern.github.io/rsofun/dev/index.html","id":"acknowledgements","dir":"","previous_headings":"","what":"Acknowledgements","title":"The P-Model and BiomeE Modelling Framework","text":"{rsofun} part LEMONTREE project funded Schmidt Futures umbrella Virtual Earth System Research Institute (VESRI).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_gs_leuning_drivers.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun BiomeE driver data (Leuning photosynthesis model) — biomee_gs_leuning_drivers","title":"rsofun BiomeE driver data (Leuning photosynthesis model) — biomee_gs_leuning_drivers","text":"Example driver run BiomeE-model CH-LAE site using Leuning photosynthesis specification (half-hourly time step) can also used together leaf trait data CH-LAE (biomee_validation) optimize model parameters.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_gs_leuning_drivers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun BiomeE driver data (Leuning photosynthesis model) — biomee_gs_leuning_drivers","text":"","code":"biomee_gs_leuning_drivers"},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_gs_leuning_drivers.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun BiomeE driver data (Leuning photosynthesis model) — biomee_gs_leuning_drivers","text":"tibble driver data. sitename Site name params_siml Simulation parameters data.frame, including   following data: spinup Flag indicating whether simulation spin-(deprecated). spinupyears Number spin-years. Set 0 spinup. recycle Number first N years forcing data.frame recycled spin-. firstyeartrend Year first transient year (AD) (optional). used set years output data frames. Defaults 0 provided. nyeartrend Number transient years (optional). Determines length simulation output spin-. Defaults number years contained forcing data. (longer forcing data, last year forcing repeated end (spin-).) steps_per_day Time resolution forcing (day-1). do_U_shaped_mortality Flag indicating whether U-shaped mortality used. do_closedN_run Flag indicating whether N closed runs recover N balance enforcing 0.2 kg N m-2 inorganic N pool. method_photosynth String specifying method photosynthesis used model, either \"pmodel\" \"gs_leuning\".document() method_mortality String indicating type mortality         model. One following: \"dbh\" size-dependent mortality, \"const_selfthin\"         constant self thinning (development), \"cstarvation\" carbon starvation,         \"growthrate\" growth rate dependent mortality. do_daily_diagnostics Whether output daily diagnostics ('output_daily_tile'). Default: True. site_info Site meta info data.frame. data structure can freely used documenting dataset, must include least following data: lon Longitude site location degrees east. lat Latitude site location degrees north. elv Elevation site location, meters sea level. forcing Forcing data.frame used input ppfd Photosynthetic photon flux density (mol m-2 s-1) tair Air temperature (deg C) vpd Vapor pressure deficit (Pa) rain Precipitation (kgH2O m-2 s-1 == mm s-1) wind Wind velocity (m s-1) pair Atmospheric pressure (Pa) co2 Atmospheric CO\\(_2\\) concentration ppm. params_tile Tile-level model parameters, single row data.frame, including following data: soiltype Integer indicating type soil: Sand = 1, LoamySand = 2, SandyLoam = 3, SiltLoam = 4, FrittedClay = 5, Loam = 6, Clay = 7. FLDCAP Field capacity (vol/vol). Water remaining soil thoroughly saturated allowed drain freely. WILTPT Wilting point (vol/vol). Water content soil plants wilt fail recover. K1 Fast soil C decomposition rate (yr\\(^{-1}\\)). K2 Slow soil C decomposition rate (yr\\(^{-1}\\)). K_nitrogen Mineral Nitrogen turnover rate (yr\\(^{-1}\\)). MLmixRatio Ratio C N returned litters microbes. etaN N loss rate runoff (organic mineral) (yr\\(^{-1}\\)). LMAmin Minimum LMA, leaf mass per unit area, kg C m\\(^{-2}\\). fsc_fine Fraction fast turnover carbon fine biomass. fsc_wood Fraction fast turnover carbon wood biomass. GR_factor Growth respiration factor. l_fract Fraction carbon retained leaf drop. retransN Retranslocation coefficient nitrogen. f_initialBSW Coefficient setting initial sapwood. f_N_add Re-fill N sapwood. tf_base Calibratable scalar respiration, used increase LUE levels. par_mort Canopy mortality parameter. par_mort_under Parameter understory mortality. params_species data.frame containing species-specific model parameters, one species per row, including following data: following columns pertaining plant type: lifeform Integer set 0 grasses 1 trees. phenotype Integer set 0 deciduous 1 evergreen. pt Integer indicating type plant according photosynthesis: 0 C3; 1 C4 following columns pertaining root parameters: alpha_FR Fine root turnover rate (yr\\(^{-1}\\)). rho_FR Material density fine roots (kg C m\\(^{-3}\\)). root_r Radius fine roots, m. root_zeta e-folding parameter root vertical distribution, m. Kw_root Fine root water conductivity (mol m\\(^{-2}\\) s\\(^{-1}\\) MPa\\(^{-1}\\)). leaf_size Characteristic leaf size. following columns pertaining photosynthesis parameters: Vmax Max RuBisCo rate, mol m\\(^{-2}\\) s\\(^{-1}\\). Vannual Annual productivity per unit area full sun (kg C m\\(^{-2}\\) year\\(^{-2}\\)). wet_leaf_dreg Wet leaf photosynthesis -regulation. m_cond Factor stomatal conductance. alpha_phot Photosynthesis efficiency. gamma_L Leaf respiration coefficient, yr\\(^{-1}\\). gamma_LN Leaf respiration coefficient per unit N. gamma_SW Sapwood respiration rate, kg C m\\(^{-2}\\) yr\\(^{-1}\\). gamma_FR Fine root respiration rate, kg C kg C\\(^{-1}\\) yr\\(^{-1}\\). tk_crit Critical temperature triggerng offset phenology, Kelvin. tk_crit_on Critical temperature triggerng onset phenology, Kelvin. gdd_crit Critical value GDD5 turning growth season. betaON Critical soil moisture phenology onset. betaOFF Critical soil moisture phenology offset. following columns pertaining allometry parameters: alphaHT Coefficient allometry (height = alphaHT * DBH_m ** thetaHT), m m\\(^{-thetaHT}\\). thetaHT Coefficient allometry (height = alphaHT * DBH_m ** thetaHT), m m\\(^{-thetaHT}\\). alphaCA Coefficient allometry (projected crown area = pi * (alphaCA * DBH_m) ** thetaCA), m\\(^{2/thetaCA-1}\\). thetaCA Coefficient allometry (projected crown area = pi * (alphaCA * DBH_m) ** thetaCA), unitless. Dybzinski (eq. G1) showed thetaCA = theatBM - 1. alphaBM Coefficient allometry (biomass = alphaBM * DBH ** thetaBM), kg C m\\(^{-thetaBM}\\). thetaBM Coefficient allometry (biomass = alphaBM * DBH ** thetaBM), unitless. Dybzinski (eq. G1) showed thetaCA = theatBM - 1. following columns pertaining reproduction parameters: seedlingsize Initial size seedlings, kg C per individual. maturalage Age trees can reproduce (years). v_seed Fraction G_SF G_F. following columns pertaining mortality parameters: mortrate_d_c Canopy tree mortality rate (yr\\(^{-1}\\)). mortrate_d_u Understory tree mortality rate (yr\\(^{-1}\\)). following columns pertaining leaf parameters: LMA Leaf mass per unit area (kg C m\\(^{-2}\\)). leafLS TODO LNbase Basal leaf N per unit area, kg N m\\(^{-2}\\). CNleafsupport TODO rho_wood Wood density (kg C m\\(^{-3}\\)). taperfactor TODO lAImax Maximum crown LAI (leaf area index). tauNSC TODO fNSmax Multiplier NSNmax sum potential bl br. phiCSA Ratio sapwood area leaf area. following columns pertaining C/N ratios plant pools: CNleaf0 TODO CNsw0 TODO CNwood0 TODO CNroot0 TODO CNseed0 TODO Nfixrate0 Reference N fixation rate (kg N kg C\\(^{-1}\\) root). NfixCost0 Carbon cost N fixation (kg C kg N\\(^{-1}\\)). internal_gap_frac TODO following columns pertaining calibratable parameters: kphio Quantum yield efficiency \\(\\varphi_0\\), mol mol\\(^{-1}\\). phiRL Ratio fine root leaf area. LAI_light Maximum LAI limited light. init_cohort data.frame initial cohort specifications, including   following data: init_cohort_species Index species described param_species. init_cohort_nindivs Initial individual density, individuals per m\\(^{2}\\). init_cohort_bl Initial biomass leaf, kg C per individual. init_cohort_br Initial biomass fine root, kg C per individual. init_cohort_bsw Initial biomass sapwood, kg C per individual. init_cohort_bHW Initial biomass heartwood, kg C per individual. init_cohort_seedC Initial biomass seed, kg C per individual. init_cohort_nsc Initial non-structural biomass, kg C per individual. lu_index Land use type cohorts belongs (given index init_lu aray).        Default: 0 (attach LU types except thoses accept vegetation – cf  init_lu.vegetated). init_soil data.frame initial soil pools, including   following data: init_fast_soil_C Initial fast soil carbon, kg C m\\(^{-2}\\). init_slow_soil_C Initial slow soil carbon, kg C m\\(^{-2}\\). init_Nmineral Mineral nitrogen pool, kg N m\\(^{-2}\\). N_input Annual nitrogen input soil N pool, kg N m\\(^{-2}\\) yr\\(^{-1}\\). init_lu data.frame initial land unit (LU) specifications, including     following data: fraction Initial grid cell fraction occupied LU, dimensionless (0 1) m\\(^{-2}\\) LU area per m\\(^{-2}\\) grid cell area.         sum fractions typically equal 1, may less case difference fraction grid cell occupied ice/water. preset Predefined land use type (optional). One : 'unmanaged', 'urban', 'cropland', 'pasture'. See meaning presets. Leave empty use preset. vegetated Whether LU accepts vegetation. Default preset 'urban': False, default presets: True. extra_N_input Additional inorg N supply (account N fertiliser application), kg m-2 yr-1. Default preset 'cropland': 0.01, default presets: 0. extra_turnover_rate Additional soil turnover rate (account soil management tillage), dimensionless. Default preset 'cropland': 0.2, default presets: 0. oxidized_litter_fraction Fraction -ground turnover directly oxidized (crop grass harvest), dimensionless.         Default preset 'cropland': 0.9, default preset 'pasture': 0.4, default presets: 0. luc_forcing Array land use change (LUC) used transient phase.      spinup, initial land unit fractions used (.e. transition).      transient years provided LUC data, last state maintained end transient phase (.e. transition).      array nxn square matrix, n number LU (.e. dimension init_lu).      entry f(, j) expresses grid cell fraction LU (row) transfered LU j (column).      .e. units init_lu$fraction.      Self transitions allowed, meaning part land unit clear cut, area remains land use.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_gs_leuning_output.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun BiomeE (gs_leuning) output data — biomee_gs_leuning_output","title":"rsofun BiomeE (gs_leuning) output data — biomee_gs_leuning_output","text":"Example output dataset BiomeE-model run using divers biomee_gs_leuning_drivers See runread_biomee_f run_biomee_f_bysite detailed description outputs.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_gs_leuning_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun BiomeE (gs_leuning) output data — biomee_gs_leuning_output","text":"","code":"biomee_gs_leuning_output"},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_gs_leuning_output.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun BiomeE (gs_leuning) output data — biomee_gs_leuning_output","text":"object class tbl_df (inherits tbl, data.frame) 1 rows 2 columns.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_drivers.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun BiomeE driver data (P-model photosynthesis model) — biomee_p_model_drivers","title":"rsofun BiomeE driver data (P-model photosynthesis model) — biomee_p_model_drivers","text":"Example driver data run BiomeE-model CH-LAE site using P-model photosynthesis specification (daily time step). can also used together leaf trait data CH-LAE (biomee_validation) optimize model parameters.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_drivers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun BiomeE driver data (P-model photosynthesis model) — biomee_p_model_drivers","text":"","code":"biomee_p_model_drivers"},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_drivers.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun BiomeE driver data (P-model photosynthesis model) — biomee_p_model_drivers","text":"See biomee_gs_leuning_drivers","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_luluc_drivers.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun BiomeE driver data (P-model photosynthesis model) with LULUC — biomee_p_model_luluc_drivers","title":"rsofun BiomeE driver data (P-model photosynthesis model) with LULUC — biomee_p_model_luluc_drivers","text":"Example driver data run BiomeE-model CH-LAE site using P-model photosynthesis specification (daily time step). provides example land use change (LUC).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_luluc_drivers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun BiomeE driver data (P-model photosynthesis model) with LULUC — biomee_p_model_luluc_drivers","text":"","code":"biomee_p_model_luluc_drivers"},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_luluc_drivers.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun BiomeE driver data (P-model photosynthesis model) with LULUC — biomee_p_model_luluc_drivers","text":"See biomee_gs_leuning_drivers","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_luluc_output.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun BiomeE (P-model) output data — biomee_p_model_luluc_output","title":"rsofun BiomeE (P-model) output data — biomee_p_model_luluc_output","text":"Example output dataset BiomeE-model run using divers biomee_p_model_luluc_drivers See runread_biomee_f run_biomee_f_bysite detailed description outputs.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_luluc_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun BiomeE (P-model) output data — biomee_p_model_luluc_output","text":"","code":"biomee_p_model_luluc_output"},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_luluc_output.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun BiomeE (P-model) output data — biomee_p_model_luluc_output","text":"object class tbl_df (inherits tbl, data.frame) 1 rows 4 columns.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_output.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun BiomeE (P-model) output data — biomee_p_model_output","title":"rsofun BiomeE (P-model) output data — biomee_p_model_output","text":"Example output dataset BiomeE-model run using divers biomee_p_model_drivers See runread_biomee_f run_biomee_f_bysite detailed description outputs.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun BiomeE (P-model) output data — biomee_p_model_output","text":"","code":"biomee_p_model_output"},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_p_model_output.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun BiomeE (P-model) output data — biomee_p_model_output","text":"object class tbl_df (inherits tbl, data.frame) 1 rows 2 columns.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun BiomeE targets validation data — biomee_validation","title":"rsofun BiomeE targets validation data — biomee_validation","text":"Small example dataset target observations (leaf trait data) CH-LAE site optimize model parameters function calib_sofun","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun BiomeE targets validation data — biomee_validation","text":"","code":"biomee_validation"},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_validation.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun BiomeE targets validation data — biomee_validation","text":"tibble validation data: sitename site name data validation data","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/biomee_validation.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"rsofun BiomeE targets validation data — biomee_validation","text":"Lukas Hörtnagl,  Werner Eugster,  Nina Buchmann,  Eugenie Paul-Limoges,  Sophia Etzold,  Matthias Haeni,  Peter Pluess,  Thomas Baur  (2004-2014) FLUXNET2015 CH-Lae Laegern, Dataset. https://doi.org/10.18140/FLX/1440134","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/build_luc_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Build LUC matrix — build_luc_matrix","title":"Build LUC matrix — build_luc_matrix","text":"Build land-use change (LUC) transition matrix patterns.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/build_luc_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build LUC matrix — build_luc_matrix","text":"","code":"build_luc_matrix(patterns, n_lu, n_years, out = vector())"},{"path":"https://fabern.github.io/rsofun/dev/reference/build_luc_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build LUC matrix — build_luc_matrix","text":"patterns list patterns. pattern must sequence transition values whose size multiple n_luxn_lu. n_lu first values transitions LU first LU, . sequence contains years n_years, truncated. n_lu Number land use types (LU). n_years Number years (.e. length 3rd dimension). internal use .","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/build_luc_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build LUC matrix — build_luc_matrix","text":"n_luxn_luxn_years transition matrix.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/build_luc_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build LUC matrix — build_luc_matrix","text":"","code":"# Example of building a 6 year-long transition matix consisting of 6 times 2x2 matrices  # A one time transfer of 0.5 of the total cell fraction from LU 2 to LU 1 pattern1 <- c(0, 0, 0.5, 0) # The null pattern (no transition) null_pattern <- rep(0, 4) # A repeated self-transition of 0.1 of the total cell fraction from LU 2 to LU 2 every other year pattern2 <- rep(c(c(0, 0, 0, 0.1), null_pattern), 3)  # Building the transition matrix build_luc_matrix(list(pattern1, pattern2), 2, 6) #> , , 1 #>  #>      [,1] [,2] #> [1,]    0  0.5 #> [2,]    0  0.1 #>  #> , , 2 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 3 #>  #>      [,1] [,2] #> [1,]    0  0.0 #> [2,]    0  0.1 #>  #> , , 4 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>  #> , , 5 #>  #>      [,1] [,2] #> [1,]    0  0.0 #> [2,]    0  0.1 #>  #> , , 6 #>  #>      [,1] [,2] #> [1,]    0    0 #> [2,]    0    0 #>"},{"path":"https://fabern.github.io/rsofun/dev/reference/calib_sofun.html","id":null,"dir":"Reference","previous_headings":"","what":"Calibrates SOFUN model parameters — calib_sofun","title":"Calibrates SOFUN model parameters — calib_sofun","text":"main function handles calibration SOFUN model parameters.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/calib_sofun.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calibrates SOFUN model parameters — calib_sofun","text":"","code":"calib_sofun(drivers, obs, settings, optim_out = TRUE, ...)"},{"path":"https://fabern.github.io/rsofun/dev/reference/calib_sofun.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calibrates SOFUN model parameters — calib_sofun","text":"drivers data frame driver data. See p_model_drivers description data structure. Additional columns can optionally provided drivers control e.g. processing within personalized cost function. obs data frame containing observational data used model calibration. See p_model_validation description data structure. Additional columns can optionally provided obs control e.g. processing within personalized cost function. settings list containing model calibration settings. See 'P-model usage' vignette information examples. method string indicating optimization method, either 'GenSA'  'BayesianTools'. par list model parameters. parameter, initial value  lower upper bounds provided. calibratable parameters  include model parameters 'kphio', 'kphio_par_a', 'kphio_par_b', 'soilm_thetastar',  'soilm_betao', 'beta_costunitratio', 'rd_to_vcmax', 'tau_acclim', 'kc_jmax'  'rootzone_whc' , ( Bayesian calibration) error parameters  target variable, named example 'err_gpp'. list must match  input parameters calibration metric parameters  given order . metric cost function. See 'Cost functions parameter  calibration' vignette examples. control list arguments passed optimization function.  method = 'GenSA', see GenSA. method = 'BayesianTools'  list include least settings sampler, see  BayesianTools::runMCMC. optim_out logical indicating whether function returns raw output optimization functions (defaults TRUE). ... Optional arguments, simply passed cost function.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/calib_sofun.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calibrates SOFUN model parameters — calib_sofun","text":"named list containing calibrated parameter vector `par` output object optimization `mod`. details output evaluate , see runMCMC (also post) GenSA.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/calib_sofun.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calibrates SOFUN model parameters — calib_sofun","text":"","code":"# Fix model parameters that won't be calibrated params_fix <- list(   kphio_par_a        = 0,   kphio_par_b        = 1.0,   soilm_thetastar    = 0.6*240,   soilm_betao        = 0.01,   beta_unitcostratio = 146,   rd_to_vcmax        = 0.014,   tau_acclim         = 30,   kc_jmax            = 0.41 )  # Define calibration settings settings <- list(   method = \"BayesianTools\",   par = list(     kphio = list(lower=0.04, upper=0.09, init=0.05),     err_gpp = list(lower = 0.01, upper = 4, init = 2)   ),   metric = rsofun::cost_likelihood_pmodel,   control = list(     sampler = \"DEzs\",     settings = list(       nrChains = 1,       burnin = 0,               iterations = 50     # kept artificially low     )   )  )    # Run the calibration for GPP data  calib_output <- rsofun::calib_sofun(    drivers = rsofun::p_model_drivers,    obs = rsofun::p_model_validation,    settings = settings,    # extra arguments for the cost function    par_fixed = params_fix,    targets = c(\"gpp\")  ) #>   Running DEzs-MCMC, chain  1 iteration 51 of 51 . Current logp  -3669.919 -3238.148 -3965.871 . Please wait!  #> runMCMC terminated after 1.587seconds"},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_biomee.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-likelihood cost function for BiomeE with different targets — cost_likelihood_biomee","title":"Log-likelihood cost function for BiomeE with different targets — cost_likelihood_biomee","text":"Cost function parameter calibration, computes log-likelihood biomee model fitting several target variables given set parameters.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_biomee.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-likelihood cost function for BiomeE with different targets — cost_likelihood_biomee","text":"","code":"cost_likelihood_biomee(par, obs, drivers, targets)"},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_biomee.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-likelihood cost function for BiomeE with different targets — cost_likelihood_biomee","text":"par named vector containing parameter values 'phiRL', 'LAI_light', 'tf_base', 'par_mort' order, error terms corresponding target variables, e.g. 'err_GPP' GPP target. Make sure order error terms par coincides order provided targets argument. obs nested data frame observations, following structure biomee_validation, example. drivers nested data frame driver data, example biomee_gs_leuning_drivers. targets character vector indicating target variables optimization done. subset c(\"GPP\", \"LAI\", \"Density\", \"Biomass\").","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_biomee.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-likelihood cost function for BiomeE with different targets — cost_likelihood_biomee","text":"log-likelihood simulated targets biomee model versus observed targets.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_biomee.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Log-likelihood cost function for BiomeE with different targets — cost_likelihood_biomee","text":"cost function performs BiomeE model run value par given argument. likelihood calculated assuming predicted targets independent, normally distributed centered observations. optimization run using BayesianTools, likelihood maximized.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_biomee.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-likelihood cost function for BiomeE with different targets — cost_likelihood_biomee","text":"","code":"# do not run long-running simulations # Compute the likelihood for a set of # BiomeE model parameter values # and the example data cost_likelihood_biomee(  par = c(phiRL = 3.5,           LAI_light = 3.5,           tf_base = 1,           par_mort = 1,    # model params          err_GPP = 0.5),  # err_GPP  obs = biomee_validation,  drivers = biomee_p_model_drivers,  targets = c(\"GPP\") ) #> [1] -0.4226299"},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_pmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Cost function computing a log-likelihood for calibration of P-model parameters — cost_likelihood_pmodel","title":"Cost function computing a log-likelihood for calibration of P-model parameters — cost_likelihood_pmodel","text":"cost function performs P-model run input drivers model parameter values, computes outcome's normal log-likelihood centered input observed values standard deviation given input parameter (calibratable).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_pmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cost function computing a log-likelihood for calibration of P-model parameters — cost_likelihood_pmodel","text":"","code":"cost_likelihood_pmodel(   par,   obs,   drivers,   targets,   par_fixed = NULL,   parallel = FALSE,   ncores = 2 )"},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_pmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cost function computing a log-likelihood for calibration of P-model parameters — cost_likelihood_pmodel","text":"par named vector values parameters calibrated, including subset model parameters (described runread_pmodel_f), order, error terms target variable (example 'gpp_err'), order targets appear targets. obs nested data.frame observations, columns 'sitename' 'data' (see p_model_validation p_model_validation_vcmax25 check structure). drivers nested data.frame driver data. See p_model_drivers description data structure. targets character vector indicating target variables optimization done RMSE computed. string must column name data data.frame belonging validation nested data.frame (example 'gpp'). par_fixed named list model parameter values keep fixed calibration. complement input par model parameters passed runread_pmodel_f. parallel logical specifying whether simulations parallelised (sending data certain number sites core). Defaults FALSE. ncores integer specifying number cores used parallel computing. Defaults 2.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_pmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cost function computing a log-likelihood for calibration of P-model parameters — cost_likelihood_pmodel","text":"log-likelihood observed target values, assuming independent, normally distributed centered predictions made P-model run standard deviation given input (via `par` error terms estimated calibration `BayesianTools`, shown \"Parameter calibration cost functions\" vignette).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_pmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cost function computing a log-likelihood for calibration of P-model parameters — cost_likelihood_pmodel","text":"run P-model, model parameters must given. cost function uses arguments par par_fixed , calibration routine, par can updated optimizer par_fixed kept unchanged throughout calibration. validation data contains \"date\" column (fluxes), simulated target time series compared observed values dates (e.g. GPP). Otherwise, one observed value per site (leaf traits), outputs (averaged growing season, weighted predicted GPP) compared single value representative site (e.g. Vcmax25). exception, date trait measurement available, compared trait value predicted date.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_likelihood_pmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cost function computing a log-likelihood for calibration of P-model parameters — cost_likelihood_pmodel","text":"","code":"# Compute the likelihood for a set of  # model parameter values involved in the # temperature dependence of kphio  # and example data cost_likelihood_pmodel( par = c(kphio       = 0.05,          kphio_par_a = -0.01,          kphio_par_b = 1,     # model parameters         err_gpp     = 2),    # err_gpp  obs = p_model_validation,  drivers = p_model_drivers,  targets = c('gpp'),  par_fixed = list(   soilm_thetastar    = 0.6 * 240,  # old setup with soil moisture stress   soilm_betao        = 0.0,   beta_unitcostratio = 146.0,   rd_to_vcmax        = 0.014,      # from Atkin et al. 2015 for C3 herbaceous   tau_acclim         = 30.0,   kc_jmax            = 0.41  ) ) #> [1] -6208.172"},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_biomee.html","id":null,"dir":"Reference","previous_headings":"","what":"RMSE cost function for BiomeE — cost_rmse_biomee","title":"RMSE cost function for BiomeE — cost_rmse_biomee","text":"Cost function parameter calibration, computes root mean squared error (RMSE) BiomeE simulations (using input set parameters) observed target variables. Cost function parameter calibration, computes RMSE biomee model fitting target variables 'GPP','LAI','Density' 'Biomass' given set parameters.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_biomee.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"RMSE cost function for BiomeE — cost_rmse_biomee","text":"","code":"cost_rmse_biomee(par, obs, drivers)"},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_biomee.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"RMSE cost function for BiomeE — cost_rmse_biomee","text":"par vector containing parameter values 'phiRL', 'LAI_light', 'tf_base', 'par_mort' order. obs nested data frame observations, following structure biomee_validation, example. drivers nested data frame driver data, example biomee_gs_leuning_drivers.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_biomee.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"RMSE cost function for BiomeE — cost_rmse_biomee","text":"root mean squared error (RMSE) observed simulated values 'GPP','LAI','Density' 'Biomass' (variables weight). Relative errors (difference divided observed values) used instead absolute errors. cost function performs BiomeE model run parameter values par model drivers drivers given arguments, producing simulated values used compute RMSE.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_biomee.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"RMSE cost function for BiomeE — cost_rmse_biomee","text":"","code":"# do not run long-running simulations # Compute RMSE for a set of # model parameter values # and example data cost_rmse_biomee(  par = c(3.5, 3.5, 1, 1),  obs = biomee_validation,  drivers = biomee_p_model_drivers ) #> [1] 0.2008596"},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_pmodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Cost function computing RMSE for calibration of P-model parameters — cost_rmse_pmodel","title":"Cost function computing RMSE for calibration of P-model parameters — cost_rmse_pmodel","text":"cost function performs P-model run input drivers parameter values, compares output observations various targets computing root mean squared error (RMSE).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_pmodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cost function computing RMSE for calibration of P-model parameters — cost_rmse_pmodel","text":"","code":"cost_rmse_pmodel(   par,   obs,   drivers,   targets,   par_fixed = NULL,   target_weights = NULL,   parallel = FALSE,   ncores = 2 )"},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_pmodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cost function computing RMSE for calibration of P-model parameters — cost_rmse_pmodel","text":"par vector values parameters calibrated (subset described runread_pmodel_f, order). obs nested data.frame observations, columns 'sitename' 'data' (see p_model_validation p_model_validation_vcmax25 check structure). drivers nested data.frame driver data. See p_model_drivers description data structure. targets character vector indicating target variables optimization done RMSE computed. string must column name data data.frame belonging validation nested data.frame (example 'gpp'). par_fixed named list model parameter values keep fixed calibration. complement input par model parameters passed runread_pmodel_f. target_weights vector weights used computation RMSE using several targets. default (target_weights = NULL) RMSE computed separately target averaged. provided weights used compute weighted average RMSE across targets. parallel logical specifying whether simulations parallelised (sending data certain number sites core). Defaults FALSE. ncores integer specifying number cores used parallel computing. Defaults 2.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_pmodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cost function computing RMSE for calibration of P-model parameters — cost_rmse_pmodel","text":"root mean squared error (RMSE) observed values P-model predictions. RMSE computed target separately aggregated (mean weighted average).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_pmodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cost function computing RMSE for calibration of P-model parameters — cost_rmse_pmodel","text":"run P-model, model parameters must given. cost function uses arguments par par_fixed , calibration routine, par can updated optimizer par_fixed kept unchanged throughout calibration. validation data contains \"date\" column (fluxes), simulated target time series compared observed values dates (e.g. GPP). Otherwise, one observed value per site (leaf traits), outputs (averaged growing season, weighted predicted GPP) compared single value representative site (e.g. Vcmax25). exception, date trait measurement available, compared trait value predicted date.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/cost_rmse_pmodel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cost function computing RMSE for calibration of P-model parameters — cost_rmse_pmodel","text":"","code":"# Compute RMSE for a set # of model parameter values # and example data cost_rmse_pmodel(  par = c(0.05, -0.01, 0.5),  # kphio related parameters  obs = p_model_validation,  drivers = p_model_drivers,  targets = c('gpp'),  par_fixed = list(   soilm_thetastar    = 0.6 * 240,  # old setup with soil moisture stress   soilm_betao        = 0.0,   beta_unitcostratio = 146.0,   rd_to_vcmax        = 0.014,      # from Atkin et al. 2015 for C3 herbaceous   tau_acclim         = 30.0,   kc_jmax            = 0.41  ) ) #> [1] 3.837109"},{"path":"https://fabern.github.io/rsofun/dev/reference/init_dates_dataframe.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialises a tibble with dates — init_dates_dataframe","title":"Initialises a tibble with dates — init_dates_dataframe","text":"Creates tibble rows date 'yrstart' 'yrend' 'yyyy-mm-dd' format. Intervals dates specified argument 'freq'.  ddf <- init_dates_dataframe(2000, 2003, startmoy=1, startdoy=1,                              freq=\"days\", endmoy=12, enddom=31, noleap=FALSE)","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/init_dates_dataframe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialises a tibble with dates — init_dates_dataframe","text":"","code":"init_dates_dataframe(   yrstart,   yrend,   startmoy = 1,   startdoy = 1,   freq = \"days\",   endmoy = 12,   enddom = 31,   noleap = FALSE )"},{"path":"https://fabern.github.io/rsofun/dev/reference/init_dates_dataframe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialises a tibble with dates — init_dates_dataframe","text":"yrstart integer defining start year dates covered dataframe. yrend integer defining end year dates covered dataframe. startmoy integer defining start month--year dates covered dataframe. Defaults 1. startdoy integer defining start day--year dates covered dataframe. Defaults 1. freq character string specifying time steps dates (rows). Defaults \"days\". \"days\", \"months\", \"years\". freq = \"months\" 15\\(^{th}\\) day months used date, freq = \"years\" 1\\(^{st}\\) January year returned. endmoy integer defining end month--year dates covered dataframe. Defaults 12. enddom integer defining end day--year dates covered dataframe. Defaults 31. noleap Whether leap years ignored, , whether 29\\(^{th}\\) February removed. Defaults FALSE.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/init_dates_dataframe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialises a tibble with dates — init_dates_dataframe","text":"tibble dates.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_drivers.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun P-model driver data — p_model_drivers","title":"rsofun P-model driver data — p_model_drivers","text":"Small dataset representing driver run P-model FR-Pue site. can also used together daily GPP flux time series data CH-LAE (p_model_validation) optimize model parameters. optimize model parameters leaf traits data use datasets p_model_drivers_vcmax25 p_model_validation_vcmax25.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_drivers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun P-model driver data — p_model_drivers","text":"","code":"p_model_drivers"},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_drivers.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun P-model driver data — p_model_drivers","text":"tibble driver data: sitename character string containing site name. forcing tibble time series forcing climate data, including   following data: date Date observation YYYY-MM-DD format. temp Daytime average air temperature \\(^\\circ\\)C. vpd Daytime average vapour pressure deficit Pa. ppfd Photosynthetic photon flux density (PPFD)       mol m\\(^{-2}\\) s\\(^{-1}\\). values NA, indicates       PPFD calculated SPLASH model column ccov. netrad Net radiation W m\\(^{-2}\\). WARNING: currently       ignored model forcing. patm Atmospheric pressure Pa. snow Snow water equivalents mm s\\(^{-1}\\). rain Rain precipitation liquid form mm s\\(^{-1}\\). tmin Daily minimum air temperature \\(^\\circ\\)C. tmax Daily maximum air temperature \\(^\\circ\\)C. fapar Fraction photosynthetic active radiation (fAPAR), taking      values 0 1. co2 Atmospheric CO\\(_2\\) concentration ppm. ccov Cloud coverage %. used either PPFD       net radiation prescribed.  params_siml tibble simulation parameters, including   following data: spinup logical value indicating whether simulation spin-. spinupyears Number spin-years. recycle Number first N years forcing data.frame recycled spin-. outdt integer indicating output periodicity. ltre logical value, TRUE evergreen tree. ltne logical value, TRUE evergreen tree N-fixing. ltrd logical value, TRUE deciduous tree. ltnd logical value, TRUE deciduous tree N-fixing. lgr3 logical value, TRUE grass C3 photosynthetic pathway. lgn3 logical value, TRUE grass C3 photosynthetic       pathway N-fixing. lgr4 logical value, TRUE grass C4 photosynthetic pathway.  site_info tibble containing site meta information. data structure can freely used documenting dataset, must include least following data: lon Longitude site location degrees east. lat Latitude site location degrees north. elv Elevation site location, meters sea level. whc numeric value rooting zone water holding capacity (mm)","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_drivers.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"rsofun P-model driver data — p_model_drivers","text":"Pastorello, G., Trotta, C., Canfora, E. et al. FLUXNET2015 dataset ONEFlux processing pipeline eddy covariance data. Sci Data 7, 225 (2020). https://doi.org/10.1038/s41597-020-0534-3 University East Anglia Climatic Research Unit; Harris, .C.; Jones, P.D.; Osborn, T. (2021): CRU TS4.05: Climatic Research Unit (CRU) Time-Series (TS) version 4.05 high-resolution gridded data month--month variation climate (Jan. 1901- Dec. 2020). NERC EDS Centre Environmental Data Analysis, date citation. https://catalogue.ceda.ac.uk/uuid/c26a65020a5e4b80b20018f148556681 Weedon, G. P., G. Balsamo, N. Bellouin,S. Gomes, M. J. Best, P. Viterbo(2014), WFDEI meteorologicalforcing data set: WATCH Forcing Datamethodology applied ERA-Interimreanalysis data, Water Resour. Res.,50,7505–7514, doi:10.1002/2014WR015638. Fick, S.E. R.J. Hijmans, 2017. WorldClim 2: new 1km spatial resolution climate surfaces global land areas. International Journal Climatology 37 (12): 4302-4315.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_drivers_vcmax25.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun P-model driver data (for leaf traits) — p_model_drivers_vcmax25","title":"rsofun P-model driver data (for leaf traits) — p_model_drivers_vcmax25","text":"Small dataset representing driver run P-model four separate sites. can also used together leaf traits data four sites (p_model_validation_vcmax25) optimize model parameters. optimize model parameters GPP flux data use datasets p_model_drivers p_model_validation.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_drivers_vcmax25.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun P-model driver data (for leaf traits) — p_model_drivers_vcmax25","text":"","code":"p_model_drivers_vcmax25"},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_drivers_vcmax25.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun P-model driver data (for leaf traits) — p_model_drivers_vcmax25","text":"See p_model_drivers","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_drivers_vcmax25.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"rsofun P-model driver data (for leaf traits) — p_model_drivers_vcmax25","text":"Atkin, O. K., Bloomfield, K. J., Reich, P. B., Tjoelker, M. G., Asner, G. P., Bonal, D., et al. (2015). Global variability leaf respiration relation climate, plant functional types leaf traits. New Phytol. 206 (2), 614–636. doi:10.1111/nph.13253 University East Anglia Climatic Research Unit; Harris, .C.; Jones, P.D.; Osborn, T. (2021): CRU TS4.05: Climatic Research Unit (CRU) Time-Series (TS) version 4.05 high-resolution gridded data month--month variation climate (Jan. 1901- Dec. 2020). NERC EDS Centre Environmental Data Analysis, date citation. https://catalogue.ceda.ac.uk/uuid/c26a65020a5e4b80b20018f148556681 Weedon, G. P., G. Balsamo, N. Bellouin,S. Gomes, M. J. Best, P. Viterbo(2014), WFDEI meteorologicalforcing data set: WATCH Forcing Datamethodology applied ERA-Interimreanalysis data, Water Resour. Res.,50,7505–7514, doi:10.1002/2014WR015638. Fick, S.E. R.J. Hijmans, 2017. WorldClim 2: new 1km spatial resolution climate surfaces global land areas. International Journal Climatology 37 (12): 4302-4315. C.D. Keeling, R.B. Bacastow, .E. Bainbridge, C.. Ekdahl, P.R. Guenther, L.S. Waterman, (1976), Atmospheric carbon dioxide variations Mauna Loa Observatory, Hawaii, Tellus, vol. 28, 538-551","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_output.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun P-model output data — p_model_output","title":"rsofun P-model output data — p_model_output","text":"Example output dataset p-model run using p_model_drivers See run_pmodel_f_bysite detailed description outputs.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun P-model output data — p_model_output","text":"","code":"p_model_output"},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_output.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun P-model output data — p_model_output","text":"object class tbl_df (inherits tbl, data.frame) 1 rows 3 columns.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_output_vcmax25.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun P-model output data (using vcmax25 drivers) — p_model_output_vcmax25","title":"rsofun P-model output data (using vcmax25 drivers) — p_model_output_vcmax25","text":"Example output dataset p-model run using p_model_drivers_vcmax25 See run_pmodel_f_bysite detailed description outputs.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_output_vcmax25.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun P-model output data (using vcmax25 drivers) — p_model_output_vcmax25","text":"","code":"p_model_output_vcmax25"},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_output_vcmax25.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun P-model output data (using vcmax25 drivers) — p_model_output_vcmax25","text":"object class tbl_df (inherits tbl, data.frame) 4 rows 3 columns.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun P-model GPP validation data — p_model_validation","title":"rsofun P-model GPP validation data — p_model_validation","text":"Small example dataset target observations (daily GPP flux data) optimize model parameters function calib_sofun","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun P-model GPP validation data — p_model_validation","text":"","code":"p_model_validation"},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun P-model GPP validation data — p_model_validation","text":"tibble validation data: sitename character string containing site name (e.g. 'FR-Pue'). data tibble [ 2,920 x 3 ] time series following variables: date Date vector format YYYY-MM-DD. gpp observed Gross Primary Productivity (GPP) time stamp       (gC m\\(^{-2}\\) d\\(^{-1}\\)). gpp_unc uncertainty GPP (gC m\\(^{-2}\\) d\\(^{-1}\\)).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"rsofun P-model GPP validation data — p_model_validation","text":"Pastorello, G., Trotta, C., Canfora, E. et al. FLUXNET2015 dataset ONEFlux processing pipeline eddy covariance data. Sci Data 7, 225 (2020). https://doi.org/10.1038/s41597-020-0534-3","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"rsofun P-model GPP validation data — p_model_validation","text":"","code":"require(ggplot2); require(tidyr) #> Loading required package: ggplot2 #> Loading required package: tidyr p_model_validation %>% tidyr::unnest(data)  #> # A tibble: 2,190 × 4 #>    sitename date         gpp gpp_unc #>    <chr>    <date>     <dbl>   <dbl> #>  1 FR-Pue   2007-01-01 2.21  0.0108  #>  2 FR-Pue   2007-01-02 2.23  0.00475 #>  3 FR-Pue   2007-01-03 2.48  0.00727 #>  4 FR-Pue   2007-01-04 1.71  0.00516 #>  5 FR-Pue   2007-01-05 2.61  0.00764 #>  6 FR-Pue   2007-01-06 2.85  0.00610 #>  7 FR-Pue   2007-01-07 2.80  0.0164  #>  8 FR-Pue   2007-01-08 1.90  0.0116  #>  9 FR-Pue   2007-01-09 3.42  0.0147  #> 10 FR-Pue   2007-01-10 0.651 0.0151  #> # ℹ 2,180 more rows"},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation_vcmax25.html","id":null,"dir":"Reference","previous_headings":"","what":"rsofun P-model Vcmax25 validation data — p_model_validation_vcmax25","title":"rsofun P-model Vcmax25 validation data — p_model_validation_vcmax25","text":"Small example dataset target observations (leaf trait data) optimize model parameters function calib_sofun","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation_vcmax25.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rsofun P-model Vcmax25 validation data — p_model_validation_vcmax25","text":"","code":"p_model_validation_vcmax25"},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation_vcmax25.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"rsofun P-model Vcmax25 validation data — p_model_validation_vcmax25","text":"tibble validation data: sitename character string containing site names (e.g. 'Reichetal_Colorado'). data tibble [ 1 x 2 ] observations following variables: vcmax25 observed maximum rate carboxylation (Vcmax), normalised     25\\(^o\\) C (mol C m\\(^{-2}\\) d\\(^{-1}\\)), aggregated different plant species     site. vcmax25_unc uncertainty Vcmax25 (mol C m\\(^{-2}\\) d\\(^{-1}\\)),       calculated standard deviation among Vcmax25 observations       several species per site total standard deviation across sites       single-plant-species sites.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation_vcmax25.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"rsofun P-model Vcmax25 validation data — p_model_validation_vcmax25","text":"Atkin, O. K., Bloomfield, K. J., Reich, P. B., Tjoelker, M. G., Asner, G. P., Bonal, D., et al. (2015). Global variability leaf respiration relation climate, plant functional types leaf traits. New Phytol. 206 (2), 614–636. doi:10.1111/nph.13253","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/p_model_validation_vcmax25.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"rsofun P-model Vcmax25 validation data — p_model_validation_vcmax25","text":"","code":"require(ggplot2); require(tidyr) p_model_validation_vcmax25 %>% tidyr::unnest(data)  #> # A tibble: 4 × 3 #> # Groups:   sitename [4] #>   sitename               vcmax25 vcmax25_unc #>   <chr>                    <dbl>       <dbl> #> 1 Reichetal_Colorado   0.0000339   0.0000136 #> 2 Reichetal_New_Mexico 0.0000757   0.0000163 #> 3 Reichetal_Venezuela  0.0000472   0.0000164 #> 4 Reichetal_Wisconsin  0.0000502   0.0000147"},{"path":"https://fabern.github.io/rsofun/dev/reference/run_biomee_f_bysite.html","id":null,"dir":"Reference","previous_headings":"","what":"Run BiomeE (R wrapper) — run_biomee_f_bysite","title":"Run BiomeE (R wrapper) — run_biomee_f_bysite","text":"Run BiomeE Fortran model single site.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_biomee_f_bysite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run BiomeE (R wrapper) — run_biomee_f_bysite","text":"","code":"run_biomee_f_bysite(   sitename,   params_siml,   site_info,   forcing,   params_tile,   params_species,   init_cohort,   init_soil,   init_lu = NULL,   luc_forcing = NULL,   makecheck = TRUE )"},{"path":"https://fabern.github.io/rsofun/dev/reference/run_biomee_f_bysite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run BiomeE (R wrapper) — run_biomee_f_bysite","text":"sitename Site name. params_siml Simulation parameters. site_info Site meta info data.frame. forcing data.frame forcing climate data, used input. params_tile Tile-level model parameters, single row data.frame. params_species data.frame containing species-specific model parameters, one species per row. See examples biomee_gs_leuning_drivers biomee_p_model_drivers init_cohort data.frame initial cohort specifications. init_soil data.frame initial soil pools. init_lu data.frame initial land unit (LU) specifications. luc_forcing array land use change (LUC) used transient phase. specifications inputs examples see biomee_gs_leuning_drivers, biomee_p_model_drivers, biomee_p_model_luluc_drivers. makecheck logical specifying whether checks performed verify forcings model parameters. TRUE default.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_biomee_f_bysite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run BiomeE (R wrapper) — run_biomee_f_bysite","text":"data.frame columns containing model output land unit (LU). See examples biomee_gs_leuning_output, biomee_p_model_output, biomee_p_model_luluc_output. one land unit (LU) simulated, column named 'data'. multiple land units (LU) simulated, columns named according LU names. multiple land units (LU) simulated, additional column 'aggregated' contains output aggregating tiles well product pools. Model output land unit (LU) provided list. list elements: output_daily_tile, output_annual_tile, output_annual_cohorts. Model output aggregated land units (LU) provided list containing output_daily_cell. output_daily_tile data.frame daily outputs tile level. year Year simulation. doy Day year. Tk Air temperature (Kelvin). Prcp Precipitation (mm m\\(^{-2}\\) day\\(^{-1}\\)). SoilWater Soil water content root zone (kg m\\(^{-2}\\)). Transp Transpiration (mm m\\(^{2-}\\) day\\(^{-1}\\)). Evap Evaporation (mm m\\(^{-2}\\) day\\(^{-1}\\)). Runoff Water runoff (mm m\\(^{-2}\\) day\\(^{-1}\\)). ws1 Volumetric soil water content layer 1. ws2 Volumetric soil water content layer 2. ws3 Volumetric soil water content layer 3. LAI Leaf area index (m\\(^2\\)/m\\(^2\\)). NPP Net primary productivity (kg C m\\(^{-2}\\) day\\(^{-1}\\)). GPP Gross primary production (kg C m\\(^{-2}\\) day\\(^{-1}\\)). Rauto Plant autotrophic respiration (kg C m\\(^{-2}\\) day\\(^{-1}\\)). Rh Heterotrophic respiration (kg C m\\(^{-2}\\) day\\(^{-1}\\)). NSC Non-structural carbon (kg C m\\(^{-2}\\)). seedC Biomass seeds (kg C m\\(^{-2}\\)). leafC Biomass leaves (kg C m\\(^{-2}\\)). rootC Biomass fine roots (kg C m\\(^{-2}\\)). sapwoodC Biomass sapwood (kg C m\\(^{-2}\\)). heartwoodC Biomass heartwood (kg C m\\(^{-2}\\)). NSN Non-structural N pool (kg N m\\(^{-2}\\)). seedN Nitrogen seeds (kg N m\\(^{-2}\\)). leafN Nitrogen leaves (kg N m\\(^{-2}\\)). rootN Nitrogen roots (kg N m\\(^{-2}\\)). sapwoodN Nitrogen sapwood (kg N m\\(^{-2}\\)). heartwoodN Nitrogen heartwood (kg N m\\(^{-2}\\)). mcrbC Microbial carbon (kg C m\\(^{-2}\\)). fastSOM Fast soil carbon pool (kg C m\\(^{-2}\\)). slowSOM Slow soil carbon pool (kg C m\\(^{-2}\\)). mcrbN Microbial nitrogen (kg N m\\(^{-2}\\)). fastSoilN Fast soil nitrogen pool (kg N m\\(^{-2}\\)). slowSoilN Slow soil nitrogen pool (kg N m\\(^{-2}\\)). mineralN Mineral nitrogen pool (kg N m\\(^{-2}\\)). N_uptk Nitrogen uptake (kg N m\\(^{-2}\\) day\\(^{-1}\\)). output_annual_tile data.frame annual outputs tile level. year Year simulation. CAI Crown area index (m\\(^2\\)/m\\(^2\\)). LAI Leaf area index (m\\(^2\\)/m\\(^2\\)). Density Number trees per area (trees ha\\(^{-1}\\)). DBH Diameter tile level (cm). Density12 Tree density trees DBH > 12 cm (individuals ha\\(^{-1}\\)). DBH12 Diameter tile level considering trees DBH > 12 cm(cm). QMD12 Quadratic mean diameter tile level considering trees withDBH > 12 cm (cm). NPP Net primary productivity (kg C m\\(^{-2}\\) yr\\(^{-1}\\)). GPP Gross primary productivity (kg C m\\(^{-2}\\) yr\\(^{-1}\\)). Rauto Plant autotrophic respiration (kg C m\\(^{-2}\\) yr\\(^{-1}\\)). Rh Heterotrophic respiration (kg C m\\(^{-2}\\) yr\\(^{-1}\\)). Prcp Annual precipitation (mm m\\(^{-2}\\) yr\\(^{-1}\\)). SoilWater Soil water content root zone (kg m\\(^{-2}\\)). Transp Transpiration (mm m\\(^{-2}\\) yr\\(^{-1}\\)). Evap Evaporation (mm m\\(^{-2}\\) yr\\(^{-1}\\)). Runoff Water runoff (mm m\\(^{-2}\\) yr\\(^{-1}\\)). plantC Plant biomass (kg C m\\(^{-2}\\)). soilC Soil carbon (kg C m\\(^{-2}\\)). totC Total carbon plant soil (kg C m\\(^{-2}\\)). plantN Plant nitrogen (kg N m\\(^{-2}\\)). soilN Soil nitrogen (kg N m\\(^{-2}\\)). totN Total nitrogen plant soil (kg N m\\(^{-2}\\)). NSC Nonstructural carbohydrates (kg C m\\(^{-2}\\)). seedC Seed biomass (kg C m\\(^{-2}\\)). leafC Leaf biomass (kg C m\\(^{-2}\\)). rootC Fine root biomass (kg C m\\(^{-2}\\)). sapwoodC Sapwood biomass (kg C m\\(^{-2}\\)). heartwoodC Heartwood biomass (kg C m\\(^{-2}\\)). NSN Nonstructural nitrogen (kg N m\\(^{-2}\\)). seedN Seed nitrogen (kg N m\\(^{-2}\\)). leafN Leaf nitrogen (kg N m\\(^{-2}\\)). rootN Fine root nitrogen (kg N m\\(^{-2}\\)). sapwoodN Sapwood nitrogen (kg N m\\(^{-2}\\)). heartwoodN Heartwood nitrogen (kg N m\\(^{-2}\\)). mcrbC Microbial carbon (kg C m\\(^{-2}\\)). fastSOM Fast soil carbon pool (kg C m\\(^{-2}\\)). slowSOM Slow soil carbon pool (kg C m\\(^{-2}\\)). mcrbN Microbial nitrogen (kg N m\\(^{-2}\\)). fastSoilN Fast soil nitrogen pool (kg N m\\(^{-2}\\)). slowsoilN Slow soil nitrogen pool (kg N m\\(^{-2}\\)). mineralN Mineral nitrogen pool (kg N m\\(^{-2}\\)). N_fxed Nitrogen fixation (kg N m\\(^{-2}\\)). N_uptk Nitrogen uptake (kg N m\\(^{-2}\\)). N_yrMin Annual available nitrogen (kg N m\\(^{-2}\\)). N_P2S Annual nitrogen plants soil (kg N m\\(^{-2}\\)). N_loss Annual nitrogen loss (kg N m\\(^{-2}\\)). totseedC Total seed carbon (kg C m\\(^{-2}\\)). totseedN Total seed nitrogen (kg N m\\(^{-2}\\)). Seedling_C Total carbon compartments seeds (kg C m\\(^{-2}\\)). Seedling_N Total nitrogen compartments seeds(kg N m\\(^{-2}\\)). MaxAge Age oldest tree tile (years). MaxVolume Maximum volume tree tile (m\\(^3\\)). MaxDBH Maximum DBH tree tile (m). NPPL Growth tree, including carbon allocated leaves(kg C m\\(^{-2}\\) yr\\(^{-1}\\)). NPPW Growth tree, including carbon allocated sapwood(kg C m\\(^{-2}\\) yr\\(^{-1}\\)). n_deadtrees Number trees died (trees m\\(^{-2}\\) yr\\(^{-1}\\)). c_deadtrees Carbon biomass trees died (kg C m\\(^{-2}\\) yr\\(^{-1}\\)). m_turnover Continuous biomass turnover (kg C m\\(^{-2}\\) yr\\(^{-1}\\)). c_turnover_time Carbon turnover rate, calculated ratio plant biomass NPP (yr\\(^{-1}\\)). lu_fraction Fraction BiomeE grid cell occupied land unit (LU tile) tile (unitless, m\\(^{-2}\\) LU area per m\\(^{-2}\\) grid cell area). output_annual_cohorts data.frame annual outputs cohort level. year Year simulation. cID integer indicating cohort identity. PFT integer indicating Plant Functional Type. layer integer indicating crown layer, numbered top bottom. density Number trees per area (trees ha\\(^{-1}\\)). flayer Fraction layer area occupied cohort. DBH Tree diameter (cm). dDBH Diameter growth tree cohort (cm yr\\(^{-1}\\)). height Tree height (m). age Age cohort (years). BA Basal area tree cohort (m\\(^2\\) tree\\(^{-1}\\)). dBA Basal area increment tree cohort (m\\(^2\\) tree\\(^{-1}\\) yr\\(^{-1}\\)). Acrown Crown area tree cohort (m\\(^2\\) tree\\(^{-1}\\)). Aleaf Total area leaves (m\\(^2\\) tree\\(^{-1}\\)). wood Sum sapwood heartwood biomass tree cohort (kg C tree\\(^{-1}\\)). NSC Non-structural carbon tree cohort (kg C tree\\(^{-1}\\)). seedC Biomass seeds tree cohort (kg C tree\\(^{-1}\\)). leafC Biomass leaves tree cohort (kg C tree\\(^{-1}\\)). rootC Biomass fine roots tree cohort (kg C tree\\(^{-1}\\)). sapwoodC Biomass sapwood tree cohort (kg C tree\\(^{-1}\\)). heartwoodC Biomass heartwood tree cohort (kg C tree\\(^{-1}\\)). NSN Non-structural nitrogen tree cohort (kg N tree\\(^{-1}\\)). treeG Total growth tree, including carbon allocated seeds, leaves, fine roots, sapwood (kg C tree\\(^{-1}\\) yr\\(^{-1}\\)). fseed Fraction carbon allocated seeds total growth. fleaf Fraction carbon allocated leaves total growth. froot Fraction carbon allocated fine roots total growth. fwood Fraction carbon allocated sapwood total growth. NPP Net primary productivity tree (kg C tree\\(^{-1}\\) yr\\(^{-1}\\)). GPP Gross primary productivity tree (kg C tree\\(^{-1}\\) yr\\(^{-1}\\)). Rauto Plant autotrophic respiration (kg C tree\\(^{-1}\\) yr\\(^{-1}\\)). N_uptk Nitrogen uptake (kg N tree\\(^{-1}\\) yr\\(^{-1}\\)). N_fxed Nitrogen fixation (kg N tree\\(^{-1}\\) yr\\(^{-1}\\)). deathrate Mortality rate cohort, including natural mortality, starvation processes causing loss individuals general (yr\\(^{-1}\\)). n_deadtrees Plant soil N flux due mortality, including natural mortality, starvation processes causing loss individuals general  (kg N yr\\(^{-1}\\) m\\(^{-2}\\)). c_deadtrees Plant soil C flux due mortality, including natural mortality, starvation processes causing loss individuals general  (kg C yr\\(^{-1}\\) m\\(^{-2}\\)). multiple land units (LU) also column named `aggregated` containing data.frame column `output_annual_cell` annual outputs aggregating tiles present simulation cell. Note quantities per m2 refer m2 grid cell area, .e. full area BiomeE simulation. 'lu_fraction' refers sum tiles, must remain constant represents fraction cell area water/ice. cases, close 1. contains columns: output_annual_cell data.frame annual outputs aggregating tiles present simulation cell. Note quantities per m\\(^{2}\\) refer m\\(^{2}\\) grid cell                                    area, .e. full area BiomeE simulation. 'lu_fraction' refers sum tiles, must remain constant represents                                    fraction cell area water/ice. cases, close 1. columns 'output_yearly_tile' See output_yearly_tile, now expressed per unit area BiomeE grid cell. lu_fraction Fraction BiomeE grid cell occupied land unit (LU tile) tile (unitless, m\\(^{2}\\) LU area per m\\(^{2}\\) grid cell area). prod_pool_1_C Carbon product pool 1 (kg C m\\(^{-2}\\) grid cell). prod_pool_1_N Nitrogen product pool 1 (kg N m\\(^{-2}\\) grid cell). prod_pool_2_C Carbon product pool 2 (kg C m\\(^{-2}\\) grid cell). prod_pool_2_N Nitrogen product pool 2 (kg N m\\(^{-2}\\) grid cell). Rprod_0_C Carbon loss rate directly land use change (LUC) (kg C m\\(^{-2}\\) grid cell yr\\(^{-1}\\)). Rprod_0_N Nitrogen loss rate directly land use change (LUC) (kg C m\\(^{-2}\\) grid cell yr\\(^{-1}\\)). Rprod_1_C Carbon loss rate product pool 1 (kg C m\\(^{-2}\\) grid cell yr\\(^{-1}\\)). Rprod_1_N Nitrogen loss rate product pool 1 (kg N m\\(^{-2}\\) grid cell yr\\(^{-1}\\)). Rprod_2_C Carbon loss rate product pool 2 (kg C m\\(^{-2}\\) grid cell yr\\(^{-1}\\)). Rprod_2_N Nitrogen loss rate product pool 2 (kg N m\\(^{-2}\\) grid cell yr\\(^{-1}\\)).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_biomee_f_bysite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run BiomeE (R wrapper) — run_biomee_f_bysite","text":"","code":"# do not run long-running simulations # Example BiomeE model run  # Use example drivers data drivers <- biomee_p_model_drivers  # Run BiomeE for the first site mod_output <- run_biomee_f_bysite(  sitename = drivers$sitename[1],  params_siml = drivers$params_siml[[1]],  site_info = drivers$site_info[[1]],  forcing = drivers$forcing[[1]],  params_tile = drivers$params_tile[[1]],  params_species = drivers$params_species[[1]],  init_cohort = drivers$init_cohort[[1]],  init_soil = drivers$init_soil[[1]] )"},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_f_bysite.html","id":null,"dir":"Reference","previous_headings":"","what":"Run P-model (time series) — run_pmodel_f_bysite","title":"Run P-model (time series) — run_pmodel_f_bysite","text":"Run P-model single site forcing time series.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_f_bysite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run P-model (time series) — run_pmodel_f_bysite","text":"","code":"run_pmodel_f_bysite(   sitename,   params_siml,   site_info,   forcing,   params_modl,   makecheck = TRUE,   verbose = TRUE )"},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_f_bysite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run P-model (time series) — run_pmodel_f_bysite","text":"sitename Site name. params_siml Simulation parameters. site_info Site meta info data.frame. forcing data frame forcing climate data, used input. params_modl named list free (calibratable) model parameters. See runread_pmodel_f makecheck logical specifying whether checks performed verify forcings model parameters. TRUE default. verbose logical specifying whether print warnings. Defaults TRUE. specifications inputs examples see p_model_drivers p_model_drivers_vcmax25","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_f_bysite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run P-model (time series) — run_pmodel_f_bysite","text":"Model output provided tidy dataframe, columns: date Date observation YYYY-MM-DD format. year_dec Decimal representation year day year      (example, 2007.000 corresponds 2007-01-01 2007.003 2007-01-02. fapar Fraction photosynthetic active radiation (fAPAR), taking      values 0 1. gpp Gross Primary Productivity (GPP) time stamp       (gC m\\(^{-2}\\) d\\(^{-1}\\)). aet Actual evapotranspiration (AET), calculated SPLASH following Priestly-Taylor (mm d\\(^{-1}\\)). le Latent heat flux (J m\\(^{-2}\\) d\\(^{-1}\\)). pet Potential evapotranspiration (PET), calculated SPLASH following Priestly-Taylor (mm d\\(^{-1}\\)). vcmax Maximum rate RuBisCO carboxylation       (Vcmax) (mol C m\\(^{-2}\\) s\\(^{-1}\\)). jmax Maximum rate electron transport RuBP regeneration       (mol CO\\(_2\\) m\\(^{-2}\\) s\\(^{-1}\\)). vcmax25 Maximum rate carboxylation (Vcmax),       normalised 25\\(^o\\)C (mol C m\\(^{-2}\\) s\\(^{-1}\\)). jmax25 Maximum rate electron transport, normalised       25\\(^o\\)C (mol C m\\(^{-2}\\) s\\(^{-1}\\)). gs_accl Acclimated stomatal conductance (      mol C (mol photons)\\(^{-1}\\) Pa\\(^{-1}\\). (Multiply       ppfd (mol photons m\\(^{-2}\\) d\\(^{-1}\\)) fapar       express per unit ground area time.) wscal Relative soil water content, 0 (permanent wilting       point, PWP) 1 (field capacity, FC). chi Ratio leaf-internal ambient CO\\(_{2}\\), ci:ca (unitless). iwue Intrinsic water use efficiency (iWUE) (unitless,       multiply patm (Pa) get iWUE Pa). rd Dark respiration (Rd) gC m\\(^{-2}\\) s\\(^{-1}\\).       (Multiply 1/12 (mol C / gC) convert mol C m\\(^{-2}\\) s\\(^{-1}\\).) tsoil Soil temperature, \\(^{o}\\)C. netrad Net radiation, W m\\(^{-2}\\). WARNING: currently ignored model forcing. Instead, net radiation internally calculated SPLASH. wcont Soil water content, mm. snow Snow water equivalents, mm. cond Water input condensation, mm d\\(^{-1}\\) cleaf C mass virtual leaf carbon pool keep track isotopic composition, gC m\\(^{-2}\\) cleafd13c 13C isotopic signature (delta) cleaf, permil.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_f_bysite.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run P-model (time series) — run_pmodel_f_bysite","text":"Depending input model parameters, possible run different P-model setups presented Stocker et al. 2020 GMD. P-model version implemented package allows flexibility one presented paper, following functions: temperature dependence quantum yield efficiency given :  \\(\\varphi_0 (T) = c (1 + (T - b)^2 ) \\) \\(0 < c (1 + (T - b)^2 ) < 1\\),  \\(\\varphi_0 (T) = 0 \\) \\( c (1 + (T - b)^2 ) \\leq 0\\),   \\(\\varphi_0 (T) = 1 \\) \\( c (1 + (T - b)^2 ) \\geq 1\\).  ORG setup can reproduced setting kphio_par_a = 0 calibrating kphio parameter . BRC setup (calibrates \\(c_L = \\frac{a_L b_L}{4}\\) Eq. 18) difficult reproduce, since temperature-dependency reformulated custom cost function necessary calibration. new parameters related \\(c_L\\) follows:  \\(= -0.0004919819\\)  \\(b = 32.35294\\)  \\(c = 0.6910823 c_L\\) soil moisture stress implemented  \\(\\beta(\\theta) = \\frac{\\beta_0 - 1}{{\\theta^{*}}^2}    (\\theta - \\theta^{*})^2 + 1 \\)    \\( 0 \\leq \\theta \\leq \\theta^{*}\\)  \\(\\beta(\\theta) = 1\\) \\( \\theta > \\theta^{*}\\).  Stocker et al. 2020 GMD, threshold plant-available soil water set \\(\\theta^{*}\\) = 0.6 * whc whc site's water holding capacity. Also, \\(\\beta\\) reduction low soil moisture (\\(\\beta_0 = \\beta(0)\\)) parameterized linear function mean aridity (Eq. 20 Stocker et al. 2020 GMD) considered constant model parameter package. Hence, FULL calibration setup exactly replicated.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_f_bysite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run P-model (time series) — run_pmodel_f_bysite","text":"","code":"# Define model parameter values from previous work params_modl <- list(   kphio              = 0.04998,    # setup ORG in Stocker et al. 2020 GMD   kphio_par_a        = 0.0,        # disable temperature-dependence of kphio   kphio_par_b        = 1.0,   soilm_thetastar    = 0.6 * 240,  # old setup with soil moisture stress   soilm_betao        = 0.0,   beta_unitcostratio = 146.0,   rd_to_vcmax        = 0.014,      # from Atkin et al. 2015 for C3 herbaceous   tau_acclim         = 30.0,   kc_jmax            = 0.41 )  # Run the Fortran P-model  mod_output <- run_pmodel_f_bysite(   # unnest drivers example data   sitename = p_model_drivers$sitename[1],   params_siml = p_model_drivers$params_siml[[1]],   site_info = p_model_drivers$site_info[[1]],   forcing = p_model_drivers$forcing[[1]],   params_modl = params_modl  )"},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_onestep_f_bysite.html","id":null,"dir":"Reference","previous_headings":"","what":"Run P-model (single time step) — run_pmodel_onestep_f_bysite","title":"Run P-model (single time step) — run_pmodel_onestep_f_bysite","text":"Run P-model single site single time step. include simulation ecosystem-level quantities, water limitation, simulation water fluxes. Instead, corresponds leaf-level representation acclimation photosynthesis.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_onestep_f_bysite.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run P-model (single time step) — run_pmodel_onestep_f_bysite","text":"","code":"run_pmodel_onestep_f_bysite(lc4, forcing, params_modl, makecheck = TRUE)"},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_onestep_f_bysite.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run P-model (single time step) — run_pmodel_onestep_f_bysite","text":"lc4 Locigical specifying whether P-model simulation C4 (opposed C3). Defaults FALSE. forcing data frame forcing climate data, used input (single row). params_modl named list free (calibratable) model parameters. See runread_pmodel_f makecheck logical specifying whether checks performed  verify forcings model parameters. TRUE default. specifications inputs examples see p_model_drivers p_model_drivers_vcmax25","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_onestep_f_bysite.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run P-model (single time step) — run_pmodel_onestep_f_bysite","text":"Model output provided tidy dataframe, columns: vcmax Maximum rate RuBisCO carboxylation       (Vcmax) (mol C m\\(^{-2}\\) s\\(^{-1}\\)). jmax Maximum rate electron transport RuBP regeneration       (mol CO\\(_2\\) m\\(^{-2}\\) s\\(^{-1}\\)). vcmax25 Maximum rate carboxylation (Vcmax),       normalised 25\\(^o\\)C (mol C m\\(^{-2}\\) s\\(^{-1}\\)). jmax25 Maximum rate electron transport, normalised       25\\(^o\\)C (mol C m\\(^{-2}\\) s\\(^{-1}\\)). gs_accl Acclimated stomatal conductance (      mol C (mol photons)\\(^{-1}\\) Pa\\(^{-1}\\). (Multiply       ppfd (mol photons m\\(^{-2}\\) d\\(^{-1}\\)) fapar       express per unit ground area time.) chi Ratio leaf-internal ambient CO\\(_{2}\\), ci:ca (unitless). iwue Intrinsic water use efficiency (iWUE) (unitless,       multiply patm (Pa) get iWUE Pa). rd Dark respiration (Rd) gC m\\(^{-2}\\) s\\(^{-1}\\).       (Multiply 1/12 (mol C / gC) convert mol C m\\(^{-2}\\) s\\(^{-1}\\).) bigdelta 13C isotope discrimination leaf assimilates        atmospheric signature (permil).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_onestep_f_bysite.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run P-model (single time step) — run_pmodel_onestep_f_bysite","text":"TBC","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/run_pmodel_onestep_f_bysite.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run P-model (single time step) — run_pmodel_onestep_f_bysite","text":"","code":"# Define model parameter values from previous work params_modl <- list(   kphio              = 0.04998,    # setup ORG in Stocker et al. 2020 GMD   kphio_par_a        = 0.0,        # disable temperature-dependence of kphio   kphio_par_b        = 1.0,   beta_unitcostratio = 146.0,   rd_to_vcmax        = 0.014,      # from Atkin et al. 2015 for C3 herbaceous   kc_jmax            = 0.41 )  # Run the Fortran P-model  run_pmodel_onestep_f_bysite(   lc4 = FALSE,   forcing = data.frame(     temp  = 20,           # temperature, deg C     vpd   = 1000,         # Pa,     ppfd  = 300/10^6,     # mol/m2/s     co2   = 400,          # ppm,     patm  = 101325        # Pa   ),   params_modl = list(     kphio              = 0.04998,    # setup ORG in Stocker et al. 2020 GMD     kphio_par_a        = 0.0,        # disable temperature-dependence of kphio     kphio_par_b        = 1.0,     beta_unitcostratio = 146.0,     rd_to_vcmax        = 0.014,      # from Atkin et al. 2015 for C3 herbaceous     kc_jmax            = 0.41   ),   makecheck = TRUE ) #> # A tibble: 1 × 9 #>       vcmax      jmax   vcmax25    jmax25 gs_accl   chi    iwue      rd #>       <dbl>     <dbl>     <dbl>     <dbl>   <dbl> <dbl>   <dbl>   <dbl> #> 1 0.0000177 0.0000400 0.0000275 0.0000518 0.00158 0.694 7.64e-5 3.11e-6 #> # ℹ 1 more variable: bigdelta <dbl>"},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_biomee_f.html","id":null,"dir":"Reference","previous_headings":"","what":"Run BiomeE — runread_biomee_f","title":"Run BiomeE — runread_biomee_f","text":"Runs BiomeE model multiple sites.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_biomee_f.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run BiomeE — runread_biomee_f","text":"","code":"runread_biomee_f(drivers, makecheck = TRUE, parallel = FALSE, ncores = 1)"},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_biomee_f.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run BiomeE — runread_biomee_f","text":"drivers nested data frame one row site columns named according arguments function run_biomee_f_bysite. Namely sitename, params_siml, site_info, forcing, params_tile, params_species, init_cohort init_soil. makecheck logical specifying whether checks performed verify forcings model parameters. TRUE default. parallel Deprecated. Use ncores instead. ncores integer specifying number cores used parallel computing (sites processed parallel). Default: 1 (parallel execution).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_biomee_f.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run BiomeE — runread_biomee_f","text":"data frame (tibble) one row site. columns site information site_info one column per land unit (LU) addition aggregated output aggregated. default, LU named data aggregated present since aggregating one LU useful. multiple LU configured (using init_lu), columns named using LU name provided init_lu. See run_biomee_f_bysite detailed description outputs. Example outputs provided biomee_p_model_output biomee_p_model_luluc_output.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_biomee_f.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run BiomeE — runread_biomee_f","text":"","code":"# Example BiomeE model run  # do not run long-running simulations runread_biomee_f(   drivers = biomee_p_model_drivers ) #> # A tibble: 1 × 2 #>   sitename data             #>   <chr>    <list>           #> 1 CH-Lae   <named list [3]> if (FALSE)  # do not run this long-running example at all, only *show* example runread_biomee_f(   drivers = biomee_gs_leuning_drivers )  # \\dontrun{}"},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_pmodel_f.html","id":null,"dir":"Reference","previous_headings":"","what":"Run P-model — runread_pmodel_f","title":"Run P-model — runread_pmodel_f","text":"Runs P-model multiple sites.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_pmodel_f.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run P-model — runread_pmodel_f","text":"","code":"runread_pmodel_f(drivers, par, makecheck = TRUE, parallel = FALSE, ncores = 1)"},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_pmodel_f.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run P-model — runread_pmodel_f","text":"drivers nested data frame one row site columns named according arguments function runread_pmodel_f. Namely sitename, params_siml, site_info forcing. par named list free (calibratable) model parameters. kphio quantum yield efficiency optimal temperature \\(\\varphi_0\\),    mol mol\\(^{-1}\\).    temperature dependence used, corresponds multiplicative    parameter \\(c\\) (see Details). kphio_par_a shape parameter \\(\\) temperature-dependency    quantum yield efficiency (see Details).    disable temperature dependence, set kphio_par_a = 0. kphio_par_b optimal temperature parameter \\(b\\) temperature    dependent quantum yield efficiency (see Details), \\(^o\\)C. soilm_thetastar threshold parameter \\(\\theta^{*}\\)    soil moisture stress function (see Details), given mm.    turn soil moisture stress, set soilm_thetastar = 0. soilm_betao intercept parameter \\(\\beta_{0}\\)    soil moisture stress function (see Details). parameter calibrated    Stocker et al. 2020 GMD. beta_unitcostratio unit cost carboxylation, corresponding    \\(\\beta = b / '\\) Eq. 3 Stocker et al. 2020 GMD. rd_to_vcmax Ratio Rdark (dark respiration) Vcmax25. tau_acclim Acclimation time scale photosynthesis, days. kc_jmax Parameter Jmax cost ratio (corresponding c\\(^*\\)   Stocker et al. 2020 GMD). makecheck logical specifying whether checks performed verify forcings model parameters. TRUE default. parallel logical specifying whether simulations parallelised (sending data certain number sites core). Defaults FALSE. ncores integer specifying number cores used parallel computing (default ncores = 2).","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_pmodel_f.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run P-model — runread_pmodel_f","text":"data frame (tibble) one row site, site information stored nested column site_info outputs stored nested column data. See run_pmodel_f_bysite detailed description outputs. Example outputs provided biomee_p_model_output biomee_gs_leuning_output.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_pmodel_f.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run P-model — runread_pmodel_f","text":"Depending input model parameters, possible run different P-model setups presented Stocker et al. 2020 GMD. P-model version implemented package allows flexibility one presented paper, following functions: temperature dependence quantum yield efficiency given :  \\(\\varphi_0 (T) = c (1 + (T - b)^2 ) \\) \\(0 < c (1 + (T - b)^2 ) < 1\\),  \\(\\varphi_0 (T) = 0 \\) \\( c (1 + (T - b)^2 ) \\leq 0\\),   \\(\\varphi_0 (T) = 1 \\) \\( c (1 + (T - b)^2 ) \\geq 1\\).  ORG setup can reproduced setting kphio_par_a = 0 calibrating kphio parameter . BRC setup (calibrates \\(c_L = \\frac{a_L b_L}{4}\\) Eq. 18) difficult reproduce, since temperature-dependency reformulated custom cost function necessary calibration. new parameters related \\(c_L\\) follows:  \\(= -0.0004919819\\)  \\(b = 32.35294\\)  \\(c = 0.6910823 c_L\\) soil moisture stress implemented  \\(\\beta(\\theta) = \\frac{\\beta_0 - 1}{{\\theta^{*}}^2}    (\\theta - \\theta^{*})^2 + 1 \\)    \\( 0 \\leq \\theta \\leq \\theta^{*}\\)  \\(\\beta(\\theta) = 1\\) \\( \\theta > \\theta^{*}\\).  Stocker et al. 2020 GMD, threshold plant-available soil water set \\(\\theta^{*}\\) = 0.6 * whc whc site's water holding capacity. Also, \\(\\beta\\) reduction low soil moisture (\\(\\beta_0 = \\beta(0)\\)) parameterized linear function mean aridity (Eq. 20 Stocker et al. 2020 GMD) considered constant model parameter package. Hence, FULL calibration setup exactly replicated.","code":""},{"path":"https://fabern.github.io/rsofun/dev/reference/runread_pmodel_f.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run P-model — runread_pmodel_f","text":"","code":"# Define model parameter values from previous work params_modl <- list(   kphio              = 0.04998,    # setup ORG in Stocker et al. 2020 GMD   kphio_par_a        = 0.0,        # disable temperature-dependence of kphio   kphio_par_b        = 1.0,   soilm_thetastar    = 0.6 * 240,  # old setup with soil moisture stress   soilm_betao        = 0.0,   beta_unitcostratio = 146.0,   rd_to_vcmax        = 0.014,      # from Atkin et al. 2015 for C3 herbaceous   tau_acclim         = 30.0,   kc_jmax            = 0.41 )  # Run the model for these parameters and the example drivers output <- rsofun::runread_pmodel_f(   drivers = rsofun::p_model_drivers,   par = params_modl) output_vcmax25 <- rsofun::runread_pmodel_f(   drivers = rsofun::p_model_drivers_vcmax25,   par = params_modl)"},{"path":[]},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-510","dir":"Changelog","previous_headings":"","what":"rsofun 5.1.0","title":"rsofun 5.1.0","text":"CRAN release: 2025-10-09","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"new-features-5-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"rsofun 5.1.0","text":"New run_pmodel_onestep_f_bysite() adds single-step leaf-level simulations P-model Changed temperature dependencies Vcmax Jmax (see breaking changes ) run_pmodel_onestep_f_bysite() returns bigdelta, .e. carbon fractionation fresh assimilate cleafd13c relative d13c_atm, thereby avoiding assumptions d13c_atm. run_pmodel_f_bysite() runread_pmodel() newly return cleaf cleafd13c, assuming constant atmospheric signature d13c_atm = -8.4 permil. future version daily values d13c_atm /included input forcing. Added support LULUC (land use, land-use change) BiomeE. See vignette biome_luluc details. New BiomeE behavior recycle last year forcing requested simulation time span (nyeartrend) longer available forcing data. run_biomee_f_bysite() runread_biomee() track carbon isotopes internally, currently without output. Note method_photosynth == \"gs_leuning\", bigdelta = 20, whereas method_photosynth == \"pmodel\" bigdelta computed based pmodel-derived chi. calib_sofun() now passes parameters named vector cost-functions easier processing within cost-functions. Default cost-functions updated, currently ignore names. fully backward compatible, allows use names user-created cost functions.","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"breaking-changes-5-1-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"rsofun 5.1.0","text":"P-model now computes temperature dependencies jmax vcmax Kumarathunge et al. (2019) instead Kattge & Knorr (2007), effectively using dampened signal tc_growth long-term averages tc_home. alters simulation results. Formatting inputs remains unchanged. Breaking changes BiomeE drivers: init_cohort$init_n_cohorts column phased must present drivers protect data corruption. LAImax takes value max(LAI_light, 0.5) underLAImax takes value min(LAImax, 1.2) do_closedN_run flag now uses initial inorganic N setting rather arbitrary value false default. Species 1 now C4 crop N_input set 0.01 limit N starvation. Breaking changes BiomeE output totWs=>SoilWater Trsp=>Transp SW_C=>sapwoodC SW_N=>sapwoodN HW_C=>heartwoodC HW_N=>heartwoodN McrbC=>mcrbC McrbN=>mcrbN added NPP rain=>Prcp SeedC=>seedC (N) SapwoodC=>sapwoodC (N) WoodC=>heartwoodC (N) SlowSOM=>slowSOM McrbC=>mcrbC McrbN=>mcrbN added totC nsc=>NSC nsn=>NSN sapwC=>sapwoodC woodC=>heartwoodC Nupt=>N_uptk Nfix=>N_fxed switched column positions NPP GPP","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-v501","dir":"Changelog","previous_headings":"","what":"rsofun v5.0.1","title":"rsofun v5.0.1","text":"model version behaves exactly version . Update necessary include description scripts data used model documentation paper archive Zenodo","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-v500","dir":"Changelog","previous_headings":"","what":"rsofun v5.0.0","title":"rsofun v5.0.0","text":"CRAN release: 2024-11-28 prec now called rain rh now provided vpd See biomee_gs_leuning_drivers example fix Fortran modules leading segmentation faults using BiomeE model improved documentation","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-v441","dir":"Changelog","previous_headings":"","what":"rsofun v4.4.1","title":"rsofun v4.4.1","text":"bugfix Fortran modules derived types compilation flags different platforms","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-v44","dir":"Changelog","previous_headings":"","what":"rsofun v4.4","title":"rsofun v4.4","text":"CRAN release: 2023-10-30 bugfix input data type P-model LM3-PPA BiomeE renaming cost function rewrite update output format (consistency) add water balance variables P-model output new p-model calibratable parameters rewrite temperature soil moisture stress functions update simulation parameters take netrad, ppfd ccov input forcing documentation parameter sensitivity analysis documentation data format document calibration diagnostic model uncertainty calculation transparent licensing copyright statements COPYING file","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-v43","dir":"Changelog","previous_headings":"","what":"rsofun v4.3","title":"rsofun v4.3","text":"Consistent variable names p-model / biomee optimization stability BayesianTools documentation Bugfixes","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-v42","dir":"Changelog","previous_headings":"","what":"rsofun v4.2","title":"rsofun v4.2","text":"Canopy transfer solved BiomeE P-model Bugfixes","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-v41","dir":"Changelog","previous_headings":"","what":"rsofun v4.1","title":"rsofun v4.1","text":"Catching aborting FORTRAN part avoid R session crashes","code":""},{"path":"https://fabern.github.io/rsofun/dev/news/index.html","id":"rsofun-v40","dir":"Changelog","previous_headings":"","what":"rsofun v4.0","title":"rsofun v4.0","text":"Public release refactored code","code":""}]
